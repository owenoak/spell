{"version":3,"sources":["webpack:///webpack/bootstrap 30df8cce0d96c9561174","webpack:///./~/chevrotain/lib/src/utils/utils.js","webpack:///./~/chevrotain/lib/src/parse/grammar/gast_public.js","webpack:///./~/chevrotain/lib/src/scan/tokens_public.js","webpack:///./~/chevrotain/lib/src/lang/lang_extensions.js","webpack:///./~/chevrotain/lib/src/scan/tokens.js","webpack:///./~/chevrotain/lib/src/parse/grammar/first.js","webpack:///./~/chevrotain/lib/src/parse/grammar/gast.js","webpack:///./~/chevrotain/lib/src/parse/grammar/interpreter.js","webpack:///./~/chevrotain/lib/src/parse/grammar/rest.js","webpack:///./~/chevrotain/lib/src/parse/parser_public.js","webpack:///./~/chevrotain/lib/src/scan/lexer_public.js","webpack:///./~/chevrotain/lib/src/api.js","webpack:///./~/chevrotain/lib/src/parse/cache.js","webpack:///./~/chevrotain/lib/src/parse/constants.js","webpack:///./~/chevrotain/lib/src/parse/exceptions_public.js","webpack:///./~/chevrotain/lib/src/parse/grammar/lookahead.js","webpack:///./~/chevrotain/lib/src/version.js","webpack:///./calculator.js","webpack:///./tokens.js","webpack:///./~/chevrotain/lib/src/parse/cache_public.js","webpack:///./~/chevrotain/lib/src/parse/gast_builder.js","webpack:///./~/chevrotain/lib/src/parse/grammar/checks.js","webpack:///./~/chevrotain/lib/src/parse/grammar/follow.js","webpack:///./~/chevrotain/lib/src/parse/grammar/resolver.js","webpack:///./~/chevrotain/lib/src/scan/lexer.js","webpack:///./~/chevrotain/lib/src/text/range.js","webpack:///./app.js"],"names":["require","allTokens","WhiteSpace","Plus","Minus","Multi","Div","LParen","RParen","NumberLiteral","AdditionOperator","MultiplicationOperator","CalculatorLexer","Calculator","input","console","time","$","RULE","SUBRULE","additionExpression","value","op","rhsVal","multiplicationExpression","MANY","CONSUME","SUBRULE2","atomicExpression","OR","ALT","parenthesisExpression","parseInt","image","expValue","expression","Parser","performSelfAnalysis","timeEnd","tokClass","parser","calculator","text","group","lex","tokenize","errors","length","error","groupEnd","info","tokens","name","message","window","lexer","PATTERN","Lexer","NA","GROUP","SKIPPED","log"],"mappings":";AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA,mDAA2C,cAAc;;AAEzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;;AChEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,sBAAsB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kBAAkB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kBAAkB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,uBAAuB;AAC9C;AACA;AACA;AACA;AACA;AACA,uBAAuB,oBAAoB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,yBAAyB,EAAE;AACnE;AACA;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,0BAA0B,EAAE;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gBAAgB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gBAAgB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,4CAA4C,EAAE;AACtF;AACA;AACA;AACA,8BAA8B,6BAA6B,aAAa,GAAG;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gBAAgB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,+BAA+B,EAAE;AACzE;AACA;AACA;AACA,mBAAmB,gBAAgB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gBAAgB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,oCAAoC,EAAE;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA,mBAAmB,oBAAoB;AACvC;AACA;AACA,uBAAuB,2BAA2B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA,mBAAmB,oBAAoB;AACvC;AACA;AACA,uBAAuB,2BAA2B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kBAAkB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;ACvWA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,4CAA4C,4BAA4B;AACxE,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,qCAAqC,cAAc;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE;AAClE,2DAA2D;AAC3D,6DAA6D;AAC7D,iEAAiE;AACjE,0EAA0E;AAC1E,uFAAuF;AACvF,8EAA8E;AAC9E,kEAAkE;AAClE,+DAA+D;AAC/D,2DAA2D;AAC3D;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2CAA2C;AAC5C,uC;;;;;;;AC/RA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,SAAS;AACpB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,aAAa;AACxB,aAAa,iBAAiB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,iBAAiB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,uBAAuB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,6BAA6B;AAClE,uCAAuC,+BAA+B;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,6BAA6B;AAClE,uCAAuC,qCAAqC;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,yCAAyC;AACpD,WAAW,SAAS;AACpB,aAAa,SAAS;AACtB;AACA;AACA,qCAAqC,6BAA6B;AAClE,uCAAuC,2BAA2B;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,+DAA+D;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,OAAO;AACtB,eAAe,OAAO;AACtB,eAAe,OAAO;AACtB,eAAe,OAAO;AACtB,eAAe,OAAO;AACtB,eAAe,OAAO;AACtB;AACA;AACA,iCAAiC,qBAAqB;AACtD,mCAAmC,4CAA4C;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,oBAAoB;AACpB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;ACjcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,MAAM;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,2C;;;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,+BAA+B;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;ACzQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;AC5DA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,qBAAqB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,gCAAgC,EAAE;AAC/G;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;ACjJA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E;AAC3E,uFAAuF;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,eAAe;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA,8BAA8B,eAAe;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,+DAA+D;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,QAAQ;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uC;;;;;;;AC/dA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,eAAe;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,iFAAiF;AACjF,+EAA+E;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0GAA0G;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,CAAC;AACD;AACA,oCAAoC,kBAAkB,EAAE;AACxD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,UAAU;AACV,SAAS;AACT;AACA;AACA,UAAU;AACV,SAAS,YAAY;AACrB;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,UAAU;AACV,SAAS;AACT;AACA;AACA,UAAU;AACV,SAAS,sBAAsB;AAC/B;AACA;AACA;AACA;AACA,2BAA2B,mBAAmB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gCAAgC;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,IAAI;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,0EAA0E;AAC1E;AACA;AACA;AACA;AACA,gFAAgF;AAChF;AACA;AACA,mFAAmF,yBAAyB,EAAE;AAC9G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8GAA8G,yBAAyB,EAAE;AACzI;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,8BAA8B,uBAAuB;AACrD,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,qDAAqD,EAAE;AAC7H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mBAAmB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC,WAAW,EAAE;AACb;AACA;AACA;AACA,eAAe,SAAS;AACxB;AACA,iBAAiB,MAAM;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB,eAAe,IAAI;AACnB,iBAAiB,EAAE;AACnB;AACA;AACA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,WAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,oBAAoB;AACrD,+CAA+C,oBAAoB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB;AACA,eAAe,SAAS;AACxB;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,SAAS,mBAAmB;AAC9C,kBAAkB,SAAS,mBAAmB;AAC9C,kBAAkB,SAAS,qBAAqB;AAChD;AACA;AACA;AACA,kBAAkB,+BAA+B,mBAAmB;AACpE,kBAAkB,+BAA+B,mBAAmB;AACpE,kBAAkB,+BAA+B,qBAAqB;AACtE;AACA;AACA;AACA;AACA,kBAAkB,+BAA+B,mBAAmB;AACpE,kBAAkB,SAAS,mBAAmB;AAC9C,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa,MAAM,4BAA4B,GAAG;AAClE;AACA,eAAe,OAAO;AACtB;AACA;AACA;AACA,iBAAiB,EAAE;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,IAAI;AAClD;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB;AACA,eAAe,SAAS;AACxB;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iBAAiB;AAChC,eAAe,SAAS;AACxB;AACA,gBAAgB;AAChB;AACA;AACA,gEAAgE,6BAA6B;AAC7F;AACA;AACA;AACA;AACA;AACA,gEAAgE,6BAA6B;AAC7F;AACA;AACA;AACA;AACA;AACA,gEAAgE,6BAA6B;AAC7F;AACA;AACA;AACA;AACA;AACA,gEAAgE,6BAA6B;AAC7F;AACA;AACA;AACA;AACA;AACA,gEAAgE,6BAA6B;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB;AACA,eAAe,SAAS;AACxB,eAAe,OAAO;AACtB;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iBAAiB;AAChC,eAAe,SAAS;AACxB,eAAe,OAAO;AACtB;AACA,gBAAgB;AAChB;AACA;AACA,8EAA8E,6BAA6B;AAC3G;AACA;AACA;AACA;AACA;AACA,8EAA8E,6BAA6B;AAC3G;AACA;AACA;AACA;AACA;AACA,8EAA8E,6BAA6B;AAC3G;AACA;AACA;AACA;AACA;AACA,8EAA8E,6BAA6B;AAC3G;AACA;AACA;AACA;AACA;AACA,8EAA8E,6BAA6B;AAC3G;AACA;AACA;AACA,eAAe,OAAO;AACtB,eAAe,SAAS;AACxB,eAAe,YAAY;AAC3B;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA,gCAAgC,8BAA8B;AAC9D;AACA;AACA;AACA,4EAA4E;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,8BAA8B;AAC9D;AACA;AACA,4EAA4E;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,MAAM;AACrB,eAAe,SAAS;AACxB,iBAAiB,OAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,MAAM;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,OAAO;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,sBAAsB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,mDAAmD;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,mDAAmD;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,yCAAyC,EAAE;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kHAAkH,oCAAoC,EAAE;AACxJ;AACA,8EAA8E,mDAAmD,EAAE;AACnI,aAAa;AACb,uGAAuG,0CAA0C,EAAE;AACnJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,mDAAmD,EAAE;AACnI,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;AC9mDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uGAAuG;AACxG;AACA;AACA,eAAe,sDAAsD;AACrE;AACA;AACA,wBAAwB,0BAA0B;AAClD,wBAAwB,0BAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,qBAAqB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,4BAA4B;AAChF;AACA;AACA;AACA,oDAAoD,sBAAsB;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD;AACA;AACA;AACA;AACA,8CAA8C;AAC9C,iDAAiD;AACjD,kDAAkD;AAClD;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,uCAAuC;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,UAAU;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0GAA0G,0CAA0C,EAAE;AACtJ,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,8GAA8G,mBAAmB,EAAE;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,OAAO;AACtB,eAAe,OAAO;AACtB;AACA;AACA,iBAAiB;AACjB;AACA;AACA,qCAAqC,gCAAgC;AACrE;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,4BAA4B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,6BAA6B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,wEAAwE;AACrG;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,4BAA4B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,6BAA6B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,wEAAwE;AACrG;AACA;AACA,gBAAgB;AAChB;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,wC;;;;;;;AC1hBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+B;;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6FAA6F,6DAA6D,EAAE;AAC5J,yDAAyD,8BAA8B,EAAE;AACzF;AACA;AACA,iC;;;;;;;ACpDA;AACA;AACA;AACA,qC;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6DAA6D;AAC9D,6C;;;;;;;ACxDA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0DAA0D;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA,qBAAqB,OAAO;AAC5B;AACA;AACA;AACA;AACA;AACA,qEAAqE,qBAAqB,EAAE;AAC5F,2BAA2B,eAAe;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,oBAAoB;AAC7D;AACA;AACA,mCAAmC,oBAAoB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,SAAS,IAAI;AACb;AACA,qBAAqB,OAAO;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,OAAO;AAC5B;AACA;AACA,2BAA2B,eAAe;AAC1C;AACA;AACA,yCAAyC,oBAAoB;AAC7D;AACA;AACA,mCAAmC,oBAAoB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa,IAAI;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,gBAAgB;AACrD;AACA;AACA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,yGAAyG,wCAAwC,EAAE;AACnJ;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA,uBAAuB,UAAU;AACjC;AACA;AACA;AACA;AACA,gEAAgE,sDAAsD,EAAE;AACxH;AACA;AACA;AACA,4BAA4B,iBAAiB;AAC7C;AACA;AACA;AACA,+BAA+B,gCAAgC;AAC/D;AACA;AACA;AACA,qCAAqC,8CAA8C;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,KAAK;AACL;AACA;AACA;AACA,qC;;;;;;;ACnYA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;;ACLA;;eASI,mBAAAA,CAAQ,EAAR,C;IANAC,S,YAAAA,S;IACAC,U,YAAAA,U;IACAC,I,YAAAA,I;IAAMC,K,YAAAA,K;IAAOC,K,YAAAA,K;IAAOC,G,YAAAA,G;IACpBC,M,YAAAA,M;IAAQC,M,YAAAA,M;IACRC,a,YAAAA,a;IACAC,gB,YAAAA,gB;IAAkBC,sB,YAAAA,sB;;AAGtB,IAAMC,kBAAkB,IAAI,iDAAJ,CAAUX,SAAV,CAAxB;;AAEA;;IACMY,U;;;AACL,qBAAYC,KAAZ,EAAmB;AAAA;;AAClBC,UAAQC,IAAR,CAAa,qBAAb;;AADkB,sHAEZF,KAFY,EAELb,SAFK;;AAIlB,MAAIgB,SAAJ;;AAEAA,IAAEC,IAAF,CAAO,YAAP,EAAqB,YAAW;AAC/B,UAAOD,EAAEE,OAAF,CAAUF,EAAEG,kBAAZ,CAAP;AACA,GAFD;;AAIA;AACA;AACA;AACAH,IAAEC,IAAF,CAAO,oBAAP,EAA6B,YAAW;AACvC,OAAIG,KAAJ,EAAWC,EAAX,EAAeC,MAAf;;AAEA;AACAF,WAAQJ,EAAEE,OAAF,CAAUF,EAAEO,wBAAZ,CAAR;AACAP,KAAEQ,IAAF,CAAO,YAAW;AACjB;AACAH,SAAKL,EAAES,OAAF,CAAUhB,gBAAV,CAAL;AACA;AACAa,aAASN,EAAEU,QAAF,CAAWV,EAAEO,wBAAb,CAAT;;AAEA;AACA,QAAIF,cAAcnB,IAAlB,EAAwB;AACvBkB,cAASE,MAAT;AACA,KAFD,MAEO;AAAE;AACRF,cAASE,MAAT;AACA;AACD,IAZD;;AAcA,UAAOF,KAAP;AACA,GApBD;;AAuBAJ,IAAEC,IAAF,CAAO,0BAAP,EAAmC,YAAW;AAC7C,OAAIG,KAAJ,EAAWC,EAAX,EAAeC,MAAf;;AAEA;AACAF,WAAQJ,EAAEE,OAAF,CAAUF,EAAEW,gBAAZ,CAAR;AACAX,KAAEQ,IAAF,CAAO,YAAW;AACjBH,SAAKL,EAAES,OAAF,CAAUf,sBAAV,CAAL;AACA;AACAY,aAASN,EAAEU,QAAF,CAAWV,EAAEW,gBAAb,CAAT;;AAEA;AACA,QAAIN,cAAcjB,KAAlB,EAAyB;AACxBgB,cAASE,MAAT;AACA,KAFD,MAEO;AAAE;AACRF,cAASE,MAAT;AACA;AACD,IAXD;;AAaA,UAAOF,KAAP;AACA,GAnBD;;AAsBAJ,IAAEC,IAAF,CAAO,kBAAP,EAA2B,YAAW;AACrC;AACC,UAAOD,EAAEY,EAAF,CAAK;AACX;AACA;AACA,KAACC,KAAK,eAAU;AAAE,YAAOb,EAAEE,OAAF,CAAUF,EAAEc,qBAAZ,CAAP;AAA0C,KAA5D,EAHW,EAIX,EAACD,KAAK,eAAU;AAAE,YAAOE,SAASf,EAAES,OAAF,CAAUjB,aAAV,EAAyBwB,KAAlC,EAAyC,EAAzC,CAAP;AAAoD,KAAtE,EAJW,CAAL,EAKJ,oCALI,CAAP;AAMA;AACD,GATD;;AAWAhB,IAAEC,IAAF,CAAO,uBAAP,EAAgC,YAAW;AAC1C,OAAIgB,QAAJ;;AAEAjB,KAAES,OAAF,CAAUnB,MAAV;AACA2B,cAAWjB,EAAEE,OAAF,CAAUF,EAAEkB,UAAZ,CAAX;AACAlB,KAAES,OAAF,CAAUlB,MAAV;;AAEA,UAAO0B,QAAP;AACA,GARD;;AAUA;AACA;AACA;AACAE,EAAA,kDAAAA,CAAOC,mBAAP;AACAtB,UAAQuB,OAAR,CAAgB,qBAAhB;AAnFkB;AAoFlB;;AAED;AACA;;;;;mDACiCC,Q,EAAU;AAC1C,UAAOA,aAAa9B,aAApB;AACA;;;;EA3FuB,kD;;AA+FzB;AACA;;;AACA,IAAI+B,SAAS,IAAI3B,UAAJ,CAAe,EAAf,CAAb;;AAGe,SAAS4B,UAAT,CAAoBC,IAApB,EAA0B;AACxC3B,SAAQ4B,KAAR,CAAc,eAAcD,IAAd,GAAqB,GAAnC;;AAEA;AACG,KAAIE,MAAMhC,gBAAgBiC,QAAhB,CAAyBH,IAAzB,CAAV;;AAEH;AACG,KAAIE,IAAIE,MAAJ,CAAWC,MAAf,EAAuB;AACtBhC,UAAQ4B,KAAR,CAAc,cAAd;AADsB;AAAA;AAAA;;AAAA;AAEtB,wBAAkBC,IAAIE,MAAtB,8HAA8B;AAAA,QAArBE,KAAqB;;AAC7BjC,YAAQiC,KAAR,CAAcA,KAAd;AACA;AAJqB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAKtBjC,UAAQkC,QAAR;AACA,EAND,MAOK;AACJlC,UAAQmC,IAAR,CAAa,2BAAb,EAA0CN,IAAIO,MAA9C;AACA;;AAED;AACAX,QAAO1B,KAAP,GAAe8B,IAAIO,MAAnB;;AAEA;AACA;AACA,KAAI9B,QAAQmB,OAAOL,UAAP,EAAZ;;AAEH;AACG,KAAIK,OAAOM,MAAP,CAAcC,MAAlB,EAA0B;AACzBhC,UAAQ4B,KAAR,CAAc,eAAd;AADyB;AAAA;AAAA;;AAAA;AAEzB,yBAAkBH,OAAOM,MAAzB,mIAAiC;AAAA,QAAxBE,MAAwB;;AAChCjC,YAAQiC,KAAR,CAAcA,OAAMI,IAAN,GAAa,IAAb,GAAoBJ,OAAMK,OAA1B,GAAoC,IAAlD,EAAwDL,MAAxD;AACA;AAJwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAKzBjC,UAAQkC,QAAR;AACA,EAND,MAOE;AACJlC,UAAQmC,IAAR,CAAa,wBAAb,EAAuC7B,KAAvC;AACA;;AAEDN,SAAQkC,QAAR;;AAEA,QAAO,EAAE5B,YAAF,EAASuB,QAAT,EAAcE,QAAQN,OAAOM,MAA7B,EAAP;AACA;;AAED;AACAQ,OAAOC,KAAP,GAAe3C,eAAf;AACA0C,OAAOb,UAAP,GAAoBA,UAApB;AACAa,OAAOd,MAAP,GAAgBA,MAAhB,C;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/JA;;AAEA;AACA;AACA;AACA,IAAa9B,gBAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAAsC,iDAAtC;AAAaA,gB,CACL8C,O,GAAU,iDAAAC,CAAMC,E;AAExB,IAAavD,IAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAA0BO,gBAA1B;AAAaP,I,CACLqD,O,GAAU,I;AAElB,IAAapD,KAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAA2BM,gBAA3B;;AAAaN,K,CACLoD,O,GAAU,G;AAGlB,IAAa7C,sBAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAA4C,iDAA5C;AAAaA,sB,CACL6C,O,GAAU,iDAAAC,CAAMC,E;AAExB,IAAarD,KAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAA2BM,sBAA3B;AAAaN,K,CACLmD,O,GAAU,I;AAElB,IAAalD,GAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAAyBK,sBAAzB;;AAAaL,G,CACLkD,O,GAAU,I;AAGlB,IAAajD,MAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAA4B,iDAA5B;AAAaA,M,CACLiD,O,GAAU,I;AAElB,IAAahD,MAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAA4B,iDAA5B;AAAaA,M,CACLgD,O,GAAU,I;AAElB,IAAa/C,aAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAAmC,iDAAnC;AAGA;AAHaA,a,CACL+C,O,GAAU,e;AAGlB,IAAatD,UAAb;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,EAAgC,iDAAhC;;AAAaA,U,CACLsD,O,GAAU,K;AADLtD,U,CAELyD,K,GAAQ,iDAAAF,CAAMG,O;AAGf,IAAM3D,YAAY,CAACC,UAAD,EAAa;AAClCC,IADqB,EACfC,KADe,EACRC,KADQ,EACDC,GADC,EACIC,MADJ,EACYC,MADZ,EACoBC,aADpB,EACmCC,gBADnC,EACqDC,sBADrD,CAAlB,C;;;;;;;ACxCP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uDAAuD;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kFAAkF,4BAA4B,EAAE;AAChH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,4EAA4E,EAAE;AAC9E,4EAA4E,EAAE;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,KAAK;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,mDAAmD;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mDAAmD;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;AC5SA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,0DAA0D,EAAE;AACvI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wZAAwZ,YAAY;AACpa;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,sBAAsB,EAAE;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sFAAsF,oDAAoD,EAAE;AAC5I,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,qGAAqG,EAAE;AAC5J;AACA;AACA;AACA;AACA;AACA;AACA,yFAAyF,uBAAuB,EAAE;AAClH,kFAAkF,4CAA4C,EAAE;AAChI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA,kC;;;;;;;AClVA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;AC1DA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,oC;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,kFAAkF,wBAAwB,EAAE;AAC5G,iFAAiF,uCAAuC,EAAE;AAC1H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF,gDAAgD,EAAE;AACrI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,yCAAyC,yBAAyB,iCAAiC,eAAe;AAClH;AACA;AACA;AACA,KAAK;AACL;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,+EAA+E,+CAA+C,EAAE;AAChI,6EAA6E,8CAA8C,EAAE;AAC7H;AACA,gFAAgF,+CAA+C,EAAE;AACjI;AACA,kFAAkF,8CAA8C,EAAE;AAClI;AACA;AACA,qFAAqF,+CAA+C,EAAE;AACtI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+EAA+E,+CAA+C,EAAE;AAChI,+EAA+E,gDAAgD,EAAE;AACjI;AACA,kFAAkF,iDAAiD,EAAE;AACrI;AACA,oFAAoF,gDAAgD,EAAE;AACtI;AACA;AACA,uFAAuF,iDAAiD,EAAE;AAC1I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,iC;;;;;;;AC5XA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;AC/BA;;AAEAI,QAAQ8C,GAAR,CAAY,mFAAApB,CAAW,OAAX,CAAZ,E","file":"app.bundle.js?30df8cce0d96c9561174","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// identity function for calling harmony imports with the correct context\n \t__webpack_require__.i = function(value) { return value; };\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 26);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 30df8cce0d96c9561174","\"use strict\";\n/*\n Utils using lodash style API. (not necessarily 100% compliant) for functional and other utils.\n These utils should replace usage of lodash in the production code base. not because they are any better...\n but for the purpose of being a dependency free library.\n\n The hotspots in the code are already written in imperative style for performance reasons.\n so writing several dozen utils which may be slower than the original lodash, does not matter as much\n considering they will not be invoked in hotspots...\n */\nfunction isEmpty(arr) {\n    return arr && arr.length === 0;\n}\nexports.isEmpty = isEmpty;\nfunction keys(obj) {\n    return Object.keys(obj);\n}\nexports.keys = keys;\nfunction values(obj) {\n    var vals = [];\n    var keys = Object.keys(obj);\n    for (var i = 0; i < keys.length; i++) {\n        vals.push(obj[keys[i]]);\n    }\n    return vals;\n}\nexports.values = values;\nfunction mapValues(obj, callback) {\n    var result = [];\n    var objKeys = keys(obj);\n    for (var idx = 0; idx < objKeys.length; idx++) {\n        var currKey = objKeys[idx];\n        result.push(callback.call(null, obj[currKey], currKey));\n    }\n    return result;\n}\nexports.mapValues = mapValues;\nfunction map(arr, callback) {\n    var result = [];\n    for (var idx = 0; idx < arr.length; idx++) {\n        result.push(callback.call(null, arr[idx], idx));\n    }\n    return result;\n}\nexports.map = map;\nfunction flatten(arr) {\n    var result = [];\n    for (var idx = 0; idx < arr.length; idx++) {\n        var currItem = arr[idx];\n        if (Array.isArray(currItem)) {\n            result = result.concat(flatten(currItem));\n        }\n        else {\n            result.push(currItem);\n        }\n    }\n    return result;\n}\nexports.flatten = flatten;\nfunction first(arr) {\n    return isEmpty(arr) ? undefined : arr[0];\n}\nexports.first = first;\nfunction last(arr) {\n    var len = arr && arr.length;\n    return len ? arr[len - 1] : undefined;\n}\nexports.last = last;\nfunction forEach(collection, iteratorCallback) {\n    if (Array.isArray(collection)) {\n        for (var i = 0; i < collection.length; i++) {\n            iteratorCallback.call(null, collection[i], i);\n        }\n    }\n    else if (isObject(collection)) {\n        var colKeys = keys(collection);\n        for (var i = 0; i < colKeys.length; i++) {\n            var key = colKeys[i];\n            var value = collection[key];\n            iteratorCallback.call(null, value, key);\n        }\n    }\n    else {\n        /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n    }\n}\nexports.forEach = forEach;\nfunction isString(item) {\n    return typeof item === \"string\";\n}\nexports.isString = isString;\nfunction isUndefined(item) {\n    return item === undefined;\n}\nexports.isUndefined = isUndefined;\nfunction isFunction(item) {\n    return item instanceof Function;\n}\nexports.isFunction = isFunction;\nfunction drop(arr, howMuch) {\n    if (howMuch === void 0) { howMuch = 1; }\n    return arr.slice(howMuch, arr.length);\n}\nexports.drop = drop;\nfunction dropRight(arr, howMuch) {\n    if (howMuch === void 0) { howMuch = 1; }\n    return arr.slice(0, arr.length - howMuch);\n}\nexports.dropRight = dropRight;\nfunction filter(arr, predicate) {\n    var result = [];\n    if (Array.isArray(arr)) {\n        for (var i = 0; i < arr.length; i++) {\n            var item = arr[i];\n            if (predicate.call(null, item)) {\n                result.push(item);\n            }\n        }\n    }\n    return result;\n}\nexports.filter = filter;\nfunction reject(arr, predicate) {\n    return filter(arr, function (item) { return !predicate(item); });\n}\nexports.reject = reject;\nfunction pick(obj, predicate) {\n    var keys = Object.keys(obj);\n    var result = {};\n    for (var i = 0; i < keys.length; i++) {\n        var currKey = keys[i];\n        var currItem = obj[currKey];\n        if (predicate(currItem)) {\n            result[currKey] = currItem;\n        }\n    }\n    return result;\n}\nexports.pick = pick;\nfunction has(obj, prop) {\n    if (isObject(obj)) {\n        return obj.hasOwnProperty(prop);\n    }\n    return false;\n}\nexports.has = has;\nfunction contains(arr, item) {\n    return find(arr, function (currItem) { return currItem === item; }) !== undefined ? true : false;\n}\nexports.contains = contains;\n/**\n * shallow clone\n */\nfunction cloneArr(arr) {\n    var newArr = [];\n    for (var i = 0; i < arr.length; i++) {\n        newArr.push(arr[i]);\n    }\n    return newArr;\n}\nexports.cloneArr = cloneArr;\n/**\n * shallow clone\n */\nfunction cloneObj(obj) {\n    var clonedObj = {};\n    for (var key in obj) {\n        /* istanbul ignore else */\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\n            clonedObj[key] = obj[key];\n        }\n    }\n    return clonedObj;\n}\nexports.cloneObj = cloneObj;\nfunction find(arr, predicate) {\n    for (var i = 0; i < arr.length; i++) {\n        var item = arr[i];\n        if (predicate.call(null, item)) {\n            return item;\n        }\n    }\n    return undefined;\n}\nexports.find = find;\nfunction reduce(arrOrObj, iterator, initial) {\n    var vals = Array.isArray(arrOrObj) ? arrOrObj : values(arrOrObj);\n    var accumulator = initial;\n    for (var i = 0; i < vals.length; i++) {\n        accumulator = iterator.call(null, accumulator, vals[i], i);\n    }\n    return accumulator;\n}\nexports.reduce = reduce;\nfunction compact(arr) {\n    return reject(arr, function (item) { return item === null || item === undefined; });\n}\nexports.compact = compact;\nfunction uniq(arr, identity) {\n    if (identity === void 0) { identity = function (item) { return item; }; }\n    var identities = [];\n    return reduce(arr, function (result, currItem) {\n        var currIdentity = identity(currItem);\n        if (contains(identities, currIdentity)) {\n            return result;\n        }\n        else {\n            identities.push(currIdentity);\n            return result.concat(currItem);\n        }\n    }, []);\n}\nexports.uniq = uniq;\nfunction partial(func) {\n    var restArgs = [];\n    for (var _i = 1; _i < arguments.length; _i++) {\n        restArgs[_i - 1] = arguments[_i];\n    }\n    var firstArg = [null];\n    var allArgs = firstArg.concat(restArgs);\n    return Function.bind.apply(func, allArgs);\n}\nexports.partial = partial;\nfunction isArray(obj) {\n    return Array.isArray(obj);\n}\nexports.isArray = isArray;\nfunction isRegExp(obj) {\n    return obj instanceof RegExp;\n}\nexports.isRegExp = isRegExp;\nfunction isObject(obj) {\n    return obj instanceof Object;\n}\nexports.isObject = isObject;\nfunction every(arr, predicate) {\n    for (var i = 0; i < arr.length; i++) {\n        if (!predicate(arr[i], i)) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.every = every;\nfunction difference(arr, values) {\n    return reject(arr, function (item) { return contains(values, item); });\n}\nexports.difference = difference;\nfunction some(arr, predicate) {\n    for (var i = 0; i < arr.length; i++) {\n        if (predicate(arr[i])) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.some = some;\nfunction indexOf(arr, value) {\n    for (var i = 0; i < arr.length; i++) {\n        if (arr[i] === value) {\n            return i;\n        }\n    }\n    return -1;\n}\nexports.indexOf = indexOf;\nfunction sortBy(arr, orderFunc) {\n    var result = cloneArr(arr);\n    result.sort(function (a, b) { return orderFunc(a) - orderFunc(b); });\n    return result;\n}\nexports.sortBy = sortBy;\nfunction zipObject(keys, values) {\n    if (keys.length !== values.length) {\n        throw Error(\"can't zipObject with different number of keys and values!\");\n    }\n    var result = {};\n    for (var i = 0; i < keys.length; i++) {\n        result[keys[i]] = values[i];\n    }\n    return result;\n}\nexports.zipObject = zipObject;\n/**\n * mutates! (and returns) target\n */\nfunction assign(target) {\n    var sources = [];\n    for (var _i = 1; _i < arguments.length; _i++) {\n        sources[_i - 1] = arguments[_i];\n    }\n    for (var i = 0; i < sources.length; i++) {\n        var curSource = sources[i];\n        var currSourceKeys = keys(curSource);\n        for (var j = 0; j < currSourceKeys.length; j++) {\n            var currKey = currSourceKeys[j];\n            target[currKey] = curSource[currKey];\n        }\n    }\n    return target;\n}\nexports.assign = assign;\n/**\n * mutates! (and returns) target\n */\nfunction assignNoOverwrite(target) {\n    var sources = [];\n    for (var _i = 1; _i < arguments.length; _i++) {\n        sources[_i - 1] = arguments[_i];\n    }\n    for (var i = 0; i < sources.length; i++) {\n        var curSource = sources[i];\n        var currSourceKeys = keys(curSource);\n        for (var j = 0; j < currSourceKeys.length; j++) {\n            var currKey = currSourceKeys[j];\n            if (!has(target, currKey)) {\n                target[currKey] = curSource[currKey];\n            }\n        }\n    }\n    return target;\n}\nexports.assignNoOverwrite = assignNoOverwrite;\nfunction groupBy(arr, groupKeyFunc) {\n    var result = {};\n    forEach(arr, function (item) {\n        var currGroupKey = groupKeyFunc(item);\n        var currGroupArr = result[currGroupKey];\n        if (currGroupArr) {\n            currGroupArr.push(item);\n        }\n        else {\n            result[currGroupKey] = [item];\n        }\n    });\n    return result;\n}\nexports.groupBy = groupBy;\n/**\n * Merge obj2 into obj1.\n * Will overwrite existing properties with the same name\n */\nfunction merge(obj1, obj2) {\n    var result = cloneObj(obj1);\n    var keys2 = keys(obj2);\n    for (var i = 0; i < keys2.length; i++) {\n        var key = keys2[i];\n        var value = obj2[key];\n        result[key] = value;\n    }\n    return result;\n}\nexports.merge = merge;\nfunction NOOP() { }\nexports.NOOP = NOOP;\nfunction getSuperClass(clazz) {\n    return Object.getPrototypeOf(clazz.prototype).constructor;\n}\nexports.getSuperClass = getSuperClass;\n//# sourceMappingURL=utils.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/utils/utils.js\n// module id = 0\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\nvar utils_1 = require(\"../../utils/utils\");\nvar tokens_public_1 = require(\"../../scan/tokens_public\");\nvar gast;\n(function (gast) {\n    var AbstractProduction = (function () {\n        function AbstractProduction(definition) {\n            this.definition = definition;\n            this.implicitOccurrenceIndex = false;\n        }\n        AbstractProduction.prototype.accept = function (visitor) {\n            visitor.visit(this);\n            utils_1.forEach(this.definition, function (prod) {\n                prod.accept(visitor);\n            });\n        };\n        return AbstractProduction;\n    }());\n    gast.AbstractProduction = AbstractProduction;\n    var NonTerminal = (function (_super) {\n        __extends(NonTerminal, _super);\n        function NonTerminal(nonTerminalName, referencedRule, occurrenceInParent) {\n            if (referencedRule === void 0) { referencedRule = undefined; }\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            var _this = _super.call(this, []) /* istanbul ignore next */ || this;\n            _this.nonTerminalName = nonTerminalName;\n            _this.referencedRule = referencedRule;\n            _this.occurrenceInParent = occurrenceInParent;\n            return _this;\n        }\n        Object.defineProperty(NonTerminal.prototype, \"definition\", {\n            get: function () {\n                if (this.referencedRule !== undefined) {\n                    return this.referencedRule.definition;\n                }\n                return [];\n            },\n            set: function (definition) {\n                // immutable\n            },\n            enumerable: true,\n            configurable: true\n        });\n        NonTerminal.prototype.accept = function (visitor) {\n            visitor.visit(this);\n            // don't visit children of a reference, we will get cyclic infinite loops if we do so\n        };\n        return NonTerminal;\n    }(AbstractProduction));\n    gast.NonTerminal = NonTerminal;\n    var Rule = (function (_super) {\n        __extends(Rule, _super);\n        function Rule(name, definition, orgText) {\n            if (orgText === void 0) { orgText = \"\"; }\n            var _this = _super.call(this, definition) /* istanbul ignore next */ || this;\n            _this.name = name;\n            _this.orgText = orgText;\n            return _this;\n        }\n        return Rule;\n    }(AbstractProduction));\n    gast.Rule = Rule;\n    var Flat = (function (_super) {\n        __extends(Flat, _super);\n        function Flat(definition) {\n            return _super.call(this, definition) /* istanbul ignore next */ || this;\n        }\n        return Flat;\n    }(AbstractProduction));\n    gast.Flat = Flat;\n    var Option = (function (_super) {\n        __extends(Option, _super);\n        function Option(definition, occurrenceInParent) {\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            var _this = _super.call(this, definition) /* istanbul ignore next */ || this;\n            _this.occurrenceInParent = occurrenceInParent;\n            return _this;\n        }\n        return Option;\n    }(AbstractProduction));\n    gast.Option = Option;\n    var RepetitionMandatory = (function (_super) {\n        __extends(RepetitionMandatory, _super);\n        function RepetitionMandatory(definition, occurrenceInParent) {\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            var _this = _super.call(this, definition) /* istanbul ignore next */ || this;\n            _this.occurrenceInParent = occurrenceInParent;\n            return _this;\n        }\n        return RepetitionMandatory;\n    }(AbstractProduction));\n    gast.RepetitionMandatory = RepetitionMandatory;\n    var RepetitionMandatoryWithSeparator = (function (_super) {\n        __extends(RepetitionMandatoryWithSeparator, _super);\n        function RepetitionMandatoryWithSeparator(definition, separator, occurrenceInParent) {\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            var _this = _super.call(this, definition) /* istanbul ignore next */ || this;\n            _this.separator = separator;\n            _this.occurrenceInParent = occurrenceInParent;\n            return _this;\n        }\n        return RepetitionMandatoryWithSeparator;\n    }(AbstractProduction));\n    gast.RepetitionMandatoryWithSeparator = RepetitionMandatoryWithSeparator;\n    var Repetition = (function (_super) {\n        __extends(Repetition, _super);\n        function Repetition(definition, occurrenceInParent) {\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            var _this = _super.call(this, definition) /* istanbul ignore next */ || this;\n            _this.occurrenceInParent = occurrenceInParent;\n            return _this;\n        }\n        return Repetition;\n    }(AbstractProduction));\n    gast.Repetition = Repetition;\n    var RepetitionWithSeparator = (function (_super) {\n        __extends(RepetitionWithSeparator, _super);\n        function RepetitionWithSeparator(definition, separator, occurrenceInParent) {\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            var _this = _super.call(this, definition) /* istanbul ignore next */ || this;\n            _this.separator = separator;\n            _this.occurrenceInParent = occurrenceInParent;\n            return _this;\n        }\n        return RepetitionWithSeparator;\n    }(AbstractProduction));\n    gast.RepetitionWithSeparator = RepetitionWithSeparator;\n    var Alternation = (function (_super) {\n        __extends(Alternation, _super);\n        function Alternation(definition, occurrenceInParent) {\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            var _this = _super.call(this, definition) /* istanbul ignore next */ || this;\n            _this.occurrenceInParent = occurrenceInParent;\n            return _this;\n        }\n        return Alternation;\n    }(AbstractProduction));\n    gast.Alternation = Alternation;\n    var Terminal = (function () {\n        function Terminal(terminalType, occurrenceInParent) {\n            if (occurrenceInParent === void 0) { occurrenceInParent = 1; }\n            this.terminalType = terminalType;\n            this.occurrenceInParent = occurrenceInParent;\n            this.implicitOccurrenceIndex = false;\n        }\n        Terminal.prototype.accept = function (visitor) {\n            visitor.visit(this);\n        };\n        return Terminal;\n    }());\n    gast.Terminal = Terminal;\n    var GAstVisitor = (function () {\n        function GAstVisitor() {\n        }\n        GAstVisitor.prototype.visit = function (node) {\n            if (node instanceof NonTerminal) {\n                return this.visitNonTerminal(node);\n            }\n            else if (node instanceof Flat) {\n                return this.visitFlat(node);\n            }\n            else if (node instanceof Option) {\n                return this.visitOption(node);\n            }\n            else if (node instanceof RepetitionMandatory) {\n                return this.visitRepetitionMandatory(node);\n            }\n            else if (node instanceof RepetitionMandatoryWithSeparator) {\n                return this.visitRepetitionMandatoryWithSeparator(node);\n            }\n            else if (node instanceof RepetitionWithSeparator) {\n                return this.visitRepetitionWithSeparator(node);\n            }\n            else if (node instanceof Repetition) {\n                return this.visitRepetition(node);\n            }\n            else if (node instanceof Alternation) {\n                return this.visitAlternation(node);\n            }\n            else if (node instanceof Terminal) {\n                return this.visitTerminal(node);\n            }/* istanbul ignore else */ \n            else if (node instanceof Rule) {\n                return this.visitRule(node);\n            }\n            else {\n                /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n            }\n        };\n        GAstVisitor.prototype.visitNonTerminal = function (node) { };\n        GAstVisitor.prototype.visitFlat = function (node) { };\n        GAstVisitor.prototype.visitOption = function (node) { };\n        GAstVisitor.prototype.visitRepetition = function (node) { };\n        GAstVisitor.prototype.visitRepetitionMandatory = function (node) { };\n        GAstVisitor.prototype.visitRepetitionMandatoryWithSeparator = function (node) { };\n        GAstVisitor.prototype.visitRepetitionWithSeparator = function (node) { };\n        GAstVisitor.prototype.visitAlternation = function (node) { };\n        GAstVisitor.prototype.visitTerminal = function (node) { };\n        GAstVisitor.prototype.visitRule = function (node) { };\n        return GAstVisitor;\n    }());\n    gast.GAstVisitor = GAstVisitor;\n    function serializeGrammar(topRules) {\n        return utils_1.map(topRules, serializeProduction);\n    }\n    gast.serializeGrammar = serializeGrammar;\n    function serializeProduction(node) {\n        function convertDefinition(definition) {\n            return utils_1.map(definition, serializeProduction);\n        }\n        if (node instanceof NonTerminal) {\n            return {\n                type: \"NonTerminal\",\n                name: node.nonTerminalName,\n                occurrenceInParent: node.occurrenceInParent\n            };\n        }\n        else if (node instanceof Flat) {\n            return {\n                type: \"Flat\",\n                definition: convertDefinition(node.definition)\n            };\n        }\n        else if (node instanceof Option) {\n            return {\n                type: \"Option\",\n                definition: convertDefinition(node.definition)\n            };\n        }\n        else if (node instanceof RepetitionMandatory) {\n            return {\n                type: \"RepetitionMandatory\",\n                definition: convertDefinition(node.definition)\n            };\n        }\n        else if (node instanceof RepetitionMandatoryWithSeparator) {\n            return {\n                type: \"RepetitionMandatoryWithSeparator\",\n                separator: serializeProduction(new Terminal(node.separator)),\n                definition: convertDefinition(node.definition)\n            };\n        }\n        else if (node instanceof RepetitionWithSeparator) {\n            return {\n                type: \"RepetitionWithSeparator\",\n                separator: serializeProduction(new Terminal(node.separator)),\n                definition: convertDefinition(node.definition)\n            };\n        }\n        else if (node instanceof Repetition) {\n            return {\n                type: \"Repetition\",\n                definition: convertDefinition(node.definition)\n            };\n        }\n        else if (node instanceof Alternation) {\n            return {\n                type: \"Alternation\",\n                definition: convertDefinition(node.definition)\n            };\n        }\n        else if (node instanceof Terminal) {\n            var serializedTerminal = {\n                type: \"Terminal\",\n                name: tokens_public_1.tokenName(node.terminalType),\n                label: tokens_public_1.tokenLabel(node.terminalType),\n                occurrenceInParent: node.occurrenceInParent\n            };\n            if (node.terminalType.PATTERN) {\n                serializedTerminal.pattern = node.terminalType.PATTERN.source;\n            }\n            return serializedTerminal;\n        }/* istanbul ignore else */ \n        else if (node instanceof Rule) {\n            return { type: \"Rule\", name: node.name, definition: convertDefinition(node.definition) };\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n    }\n    gast.serializeProduction = serializeProduction;\n})(gast = exports.gast || (exports.gast = {}));\n//# sourceMappingURL=gast_public.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/gast_public.js\n// module id = 1\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\nvar utils_1 = require(\"../utils/utils\");\nvar lang_extensions_1 = require(\"../lang/lang_extensions\");\nvar lexer_public_1 = require(\"./lexer_public\");\nvar tokens_1 = require(\"./tokens\");\n/**\n *  This can be used to improve the quality/readability of error messages or syntax diagrams.\n *\n * @param {Function} clazz - A constructor for a Token subclass\n * @returns {string} - The Human readable label for a Token if it exists.\n */\nfunction tokenLabel(clazz) {\n    if (hasTokenLabel(clazz)) {\n        return clazz.LABEL;\n    }\n    else {\n        return tokenName(clazz);\n    }\n}\nexports.tokenLabel = tokenLabel;\nfunction hasTokenLabel(clazz) {\n    return utils_1.isString(clazz.LABEL) && clazz.LABEL !== \"\";\n}\nexports.hasTokenLabel = hasTokenLabel;\nfunction tokenName(clazz) {\n    // The tokenName property is needed under some old versions of node.js (0.10/0.12)\n    // where the Function.prototype.name property is not defined as a 'configurable' property\n    // enable producing readable error messages.\n    /* istanbul ignore if -> will only run in old versions of node.js */\n    if (utils_1.isString(clazz.tokenName)) {\n        return clazz.tokenName;\n    }\n    else {\n        return lang_extensions_1.functionName(clazz);\n    }\n}\nexports.tokenName = tokenName;\nvar PARENT = \"parent\";\nvar LABEL = \"label\";\nvar GROUP = \"group\";\nvar PUSH_MODE = \"push_mode\";\nvar POP_MODE = \"pop_mode\";\nvar LONGER_ALT = \"longer_alt\";\n/**\n * @param {ITokenConfig} config - The configuration for\n * @returns {TokenConstructor} - A constructor for the new Token subclass\n */\nfunction createToken(config) {\n    if (!utils_1.has(config, PARENT)) {\n        config.parent = Token;\n    }\n    return createTokenInternal(config);\n}\nexports.createToken = createToken;\n/**\n * Convenience method equivalent to: createToken({parent:LazyToken})\n * @see createToken\n */\nfunction createLazyToken(config) {\n    if (!utils_1.has(config, PARENT)) {\n        config.parent = LazyToken;\n    }\n    return createTokenInternal(config);\n}\nexports.createLazyToken = createLazyToken;\n/**\n * Convenience method equivalent to: createToken({parent:SimpleLazyToken})\n * @see createToken\n */\nfunction createSimpleLazyToken(config) {\n    if (!utils_1.has(config, PARENT)) {\n        config.parent = SimpleLazyToken;\n    }\n    return createTokenInternal(config);\n}\nexports.createSimpleLazyToken = createSimpleLazyToken;\n/**\n * @deprecated - - Use the new CreateSimpleLazyToken API\n */\nfunction extendLazyToken(tokenName, patternOrParent, parentConstructor) {\n    if (patternOrParent === void 0) { patternOrParent = undefined; }\n    if (parentConstructor === void 0) { parentConstructor = LazyToken; }\n    return extendToken(tokenName, patternOrParent, parentConstructor);\n}\nexports.extendLazyToken = extendLazyToken;\n/**\n * @deprecated - Use the new CreateSimpleLazyToken API\n */\nfunction extendSimpleLazyToken(tokenName, patternOrParent, parentConstructor) {\n    if (patternOrParent === void 0) { patternOrParent = undefined; }\n    if (parentConstructor === void 0) { parentConstructor = SimpleLazyToken; }\n    return extendToken(tokenName, patternOrParent, parentConstructor);\n}\nexports.extendSimpleLazyToken = extendSimpleLazyToken;\n/**\n *\n * @deprecated - Use the new CreateToken API\n *\n * utility to help the poor souls who are still stuck writing pure javascript 5.1\n * extend and create Token subclasses in a less verbose manner\n *\n * @param {string} tokenName - The name of the new TokenClass\n * @param {RegExp|CustomPatternMatcherFunc|Function} patternOrParent - RegExp Pattern or Parent Token Constructor\n * @param {Function} parentConstructor - The Token class to be extended\n * @returns {Function} - A constructor for the new extended Token subclass\n */\nfunction extendToken(tokenName, patternOrParent, parentConstructor) {\n    if (patternOrParent === void 0) { patternOrParent = undefined; }\n    if (parentConstructor === void 0) { parentConstructor = Token; }\n    var pattern;\n    if (utils_1.isRegExp(patternOrParent) ||\n        patternOrParent === lexer_public_1.Lexer.SKIPPED ||\n        patternOrParent === lexer_public_1.Lexer.NA) {\n        pattern = patternOrParent;\n    }\n    else if (utils_1.isFunction(patternOrParent)) {\n        parentConstructor = patternOrParent;\n        pattern = undefined;\n    }\n    return createTokenInternal({ name: tokenName, parent: parentConstructor, pattern: pattern });\n}\nexports.extendToken = extendToken;\nfunction createTokenInternal(config) {\n    var tokenName = config.name;\n    var parentConstructor = config.parent;\n    var pattern = config.pattern;\n    var derivedConstructor = function () {\n        parentConstructor.apply(this, arguments);\n    };\n    // can be overwritten according to:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n    // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n    /* istanbul ignore if -> will only run in old versions of node.js */\n    if (!lang_extensions_1.defineNameProp(derivedConstructor, tokenName)) {\n        // hack to save the tokenName in situations where the constructor's name property cannot be reconfigured\n        derivedConstructor.tokenName = tokenName;\n    }\n    derivedConstructor.prototype = Object.create(parentConstructor.prototype);\n    derivedConstructor.prototype.constructor = derivedConstructor;\n    if (!utils_1.isUndefined(pattern)) {\n        derivedConstructor.PATTERN = pattern;\n    }\n    tokens_1.augmentTokenClasses([derivedConstructor]);\n    // static properties mixing\n    derivedConstructor = utils_1.assignNoOverwrite(derivedConstructor, parentConstructor);\n    if (utils_1.has(config, LABEL)) {\n        derivedConstructor.LABEL = config[LABEL];\n    }\n    if (utils_1.has(config, GROUP)) {\n        derivedConstructor.GROUP = config[GROUP];\n    }\n    if (utils_1.has(config, POP_MODE)) {\n        derivedConstructor.POP_MODE = config[POP_MODE];\n    }\n    if (utils_1.has(config, PUSH_MODE)) {\n        derivedConstructor.PUSH_MODE = config[PUSH_MODE];\n    }\n    if (utils_1.has(config, LONGER_ALT)) {\n        derivedConstructor.LONGER_ALT = config[LONGER_ALT];\n    }\n    return derivedConstructor;\n}\nvar Token = (function () {\n    /**\n     * @param {string} image - The textual representation of the Token as it appeared in the text.\n     * @param {number} startOffset - Offset of the first character of the Token.\n     * @param {number} startLine - Line of the first character of the Token.\n     * @param {number} startColumn - Column of the first character of the Token.\n     * @param {number} endLine - Line of the last character of the Token.\n     * @param {number} endColumn - Column of the last character of the Token.\n     */\n    function Token(image, startOffset, startLine, startColumn, endLine, endColumn) {\n        if (endLine === void 0) { endLine = startLine; }\n        if (endColumn === void 0) { endColumn = startColumn + image.length - 1; }\n        this.image = image;\n        this.startOffset = startOffset;\n        this.startLine = startLine;\n        this.startColumn = startColumn;\n        this.endLine = endLine;\n        this.endColumn = endColumn;\n        // this marks if a Token does not really exist and has been inserted \"artificially\" during parsing in rule error recovery\n        this.isInsertedInRecovery = false;\n    }\n    Object.defineProperty(Token.prototype, \"endOffset\", {\n        get: function () {\n            return this.startOffset + this.image.length - 1;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Token.prototype, \"offset\", {\n        /**\n         * @deprecated\n         * An Alias for getting the startOffset. this is deprecated and remains only to be backwards compatiable.\n         * This API will be removed in future version of Chevrotain.\n         */\n        get: function () {\n            return this.startOffset;\n        },\n        /**\n         * @deprecated\n         * An Alias for setting the startOffset. this is deprecated and remains only to be backwards compatiable.\n         * This API will be removed in future version of Chevrotain.\n         */\n        set: function (newOffset) {\n            this.startOffset = newOffset;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    return Token;\n}());\n/**\n * A \"human readable\" Label for a Token.\n * Subclasses of Token may define their own static LABEL property.\n * This label will be used in error messages and drawing syntax diagrams.\n *\n * For example a Token constructor may be called LCurly, which is short for LeftCurlyBrackets, These names are either too short\n * or too unwieldy to be used in error messages.\n *\n * Imagine : \"expecting LCurly but found ')'\" or \"expecting LeftCurlyBrackets but found ')'\"\n *\n * However if a static property LABEL with the value '{' exists on LCurly class, that error message will be:\n * \"expecting '{' but found ')'\"\n */\nToken.LABEL = undefined;\nexports.Token = Token;\n/**\n * @see IToken\n * @see Token\n *\n * Same API as a IToken, using a Lazy implementation, with most properties being immutable.\n * See related doc in: https://github.com/SAP/chevrotain/blob/startO/docs/faq.md#-how-do-i-maximize-my-parsers-performance\n * (\"Use Lazy Tokens\" section)\n */\nvar LazyToken = (function () {\n    function LazyToken(startOffset, endOffset, cacheData) {\n        this.startOffset = startOffset;\n        this.endOffset = endOffset;\n        this.cacheData = cacheData;\n    }\n    Object.defineProperty(LazyToken.prototype, \"image\", {\n        get: function () {\n            return tokens_1.getImageFromLazyToken(this);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LazyToken.prototype, \"startLine\", {\n        get: function () {\n            return tokens_1.getStartLineFromLazyToken(this);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LazyToken.prototype, \"startColumn\", {\n        get: function () {\n            return tokens_1.getStartColumnFromLazyToken(this);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LazyToken.prototype, \"endLine\", {\n        get: function () {\n            return tokens_1.getEndLineFromLazyToken(this);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LazyToken.prototype, \"endColumn\", {\n        get: function () {\n            return tokens_1.getEndColumnFromLazyToken(this);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    return LazyToken;\n}());\n/**\n * A \"human readable\" Label for a Token.\n * Subclasses of Token may define their own static LABEL property.\n * This label will be used in error messages and drawing syntax diagrams.\n *\n * For example a Token constructor may be called LCurly, which is short for LeftCurlyBrackets, These names are either too short\n * or too unwieldy to be used in error messages.\n *\n * Imagine : \"expecting LCurly but found ')'\" or \"expecting LeftCurlyBrackets but found ')'\"\n *\n * However if a static property LABEL with the value '{' exists on LCurly class, that error message will be:\n * \"expecting '{' but found ')'\"\n */\nLazyToken.LABEL = undefined;\nexports.LazyToken = LazyToken;\n/**\n * @see IToken\n * @see LazyToken\n *\n * A Less complex LazyToken used to increase performance.\n * Instances of SimpleLazyToken will not actually inherit from it using prototype inheritance.\n * Instead they will be simple JS Objects (Simple Structures)\n * {\n *    startOffset : 10,\n *    endOffset   : 16,\n *    tokenType   : 66,\n *    cacheData   : cacheData\n * }\n *\n * The additional computed properties (startLine/StartColumn/...) of the IToken interface can be computed using\n * The provided Utility methods (getImage, getStartColumn, getEndLine, ...)\n *\n * This makes SimpleLazyTokens slightly less convenient, however this can produce a substantial increase in performance\n * which may be relevant in certain use cases where performance is of paramount concern.\n */\nvar SimpleLazyToken = (function () {\n    // This constructor is never actually called as simpleLazyToken are just a Structure.\n    // However this class must still exist as the definition and hierarchy of the SimpleLazyTokens\n    // still uses the standard prototype chain.\n    /* istanbul ignore next */\n    function SimpleLazyToken(startOffset, endOffset, tokenType, cacheData) {\n        this.startOffset = startOffset;\n        this.endOffset = endOffset;\n        this.tokenType = tokenType;\n        this.cacheData = cacheData;\n    }\n    return SimpleLazyToken;\n}());\n/**\n * A \"human readable\" Label for a Token.\n * Subclasses of Token may define their own static LABEL property.\n * This label will be used in error messages and drawing syntax diagrams.\n *\n * For example a Token constructor may be called LCurly, which is short for LeftCurlyBrackets, These names are either too short\n * or too unwieldy to be used in error messages.\n *\n * Imagine : \"expecting LCurly but found ')'\" or \"expecting LeftCurlyBrackets but found ')'\"\n *\n * However if a static property LABEL with the value '{' exists on LCurly class, that error message will be:\n * \"expecting '{' but found ')'\"\n */\nSimpleLazyToken.LABEL = undefined;\nexports.SimpleLazyToken = SimpleLazyToken;\n/**\n * A special kind of Token which does not really exist in the input\n * (hence the 'Virtual' prefix). These type of Tokens can be used as special markers:\n * for example, EOF (end-of-file).\n */\nvar VirtualToken = (function (_super) {\n    __extends(VirtualToken, _super);\n    function VirtualToken() {\n        return _super.call(this, \"\", NaN, NaN, NaN, NaN, NaN) /* istanbul ignore next */ || this;\n    }\n    return VirtualToken;\n}(Token));\nexports.VirtualToken = VirtualToken;\nvar EOF = (function (_super) {\n    __extends(EOF, _super);\n    function EOF() {\n        return _super.apply(this, arguments) /* istanbul ignore next */ || this;\n    }\n    return EOF;\n}(VirtualToken));\nexports.EOF = EOF;\ntokens_1.augmentTokenClasses([EOF]);\n// Token Getter Utilities\nfunction getImage(token) {\n    return tokens_1.isInheritanceBasedToken(token) ?\n        token.image :\n        tokens_1.getImageFromLazyToken(token);\n}\nexports.getImage = getImage;\nfunction getStartOffset(token) {\n    return token.startOffset;\n}\nexports.getStartOffset = getStartOffset;\nfunction getStartLine(token) {\n    return tokens_1.isInheritanceBasedToken(token) ?\n        token.startLine :\n        tokens_1.getStartLineFromLazyToken(token);\n}\nexports.getStartLine = getStartLine;\nfunction getStartColumn(token) {\n    return tokens_1.isInheritanceBasedToken(token) ?\n        token.startColumn :\n        tokens_1.getStartColumnFromLazyToken(token);\n}\nexports.getStartColumn = getStartColumn;\nfunction getEndOffset(token) {\n    return token.endOffset;\n}\nexports.getEndOffset = getEndOffset;\nfunction getEndLine(token) {\n    return tokens_1.isInheritanceBasedToken(token) ?\n        token.endLine :\n        tokens_1.getEndLineFromLazyToken(token);\n}\nexports.getEndLine = getEndLine;\nfunction getEndColumn(token) {\n    return tokens_1.isInheritanceBasedToken(token) ?\n        token.endColumn :\n        tokens_1.getEndColumnFromLazyToken(token);\n}\nexports.getEndColumn = getEndColumn;\n/**\n * Given a Token instance, will return the Token Constructor.\n * Note that this function is not just for convenience, Because a SimpleLazyToken \"instance'\n * Does not use standard prototype inheritance and thus it's constructor cannot be accessed\n * by traversing the prototype chain.\n *\n * @param tokenInstance {ISimpleTokenOrIToken}\n * @returns {TokenConstructor}\n */\nfunction getTokenConstructor(tokenInstance) {\n    var tokenIdx;\n    if (tokens_1.isInheritanceBasedToken(tokenInstance)) {\n        tokenIdx = tokenInstance.constructor.tokenType;\n    }\n    else {\n        tokenIdx = tokenInstance.tokenType;\n    }\n    return tokens_1.tokenIdxToClass.get(tokenIdx);\n}\nexports.getTokenConstructor = getTokenConstructor;\n/**\n * A Utility method to check if a token instance of of the type of a specific Token class.\n * Simply using instanceof is not enough because SimpleLazyToken Implementation does not use\n * ECMAScript's built-in prototype inheritance.\n *\n * @param tokInstance {ISimpleTokenOrIToken}\n * @param tokClass {TokenConstructor}\n * @returns {boolean}\n */\nfunction tokenMatcher(tokInstance, tokClass) {\n    if (LazyToken.prototype.isPrototypeOf(tokClass.prototype) ||\n        Token.prototype.isPrototypeOf(tokClass.prototype)) {\n        return tokens_1.tokenInstanceofMatcher(tokInstance, tokClass);\n    }/* istanbul ignore else */ \n    else if (SimpleLazyToken.prototype.isPrototypeOf(tokClass.prototype)) {\n        return tokens_1.tokenStructuredMatcher(tokInstance, tokClass);\n    }\n    else {\n        /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n    }\n}\nexports.tokenMatcher = tokenMatcher;\n//# sourceMappingURL=tokens_public.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/scan/tokens_public.js\n// module id = 2\n// module chunks = 0","\"use strict\";\nvar utils = require(\"../utils/utils\");\nvar utils_1 = require(\"../utils/utils\");\nfunction classNameFromInstance(instance) {\n    return functionName(instance.constructor);\n}\nexports.classNameFromInstance = classNameFromInstance;\nvar FUNC_NAME_REGEXP = /^\\s*function\\s*(\\S*)\\s*\\(/;\nvar NAME = \"name\";\nexports.SPECIAL_NAME_CACHE_KEY = \"CHEV_FUNC_NAME_CACHE666\";\n/**\n * Will Modify the func argument and define a 'name' property if none exists.\n */\n/* istanbul ignore next too many hacks for IE/old versions of node.js here*/\nfunction functionName(func) {\n    // Engines that support Function.prototype.name OR the nth (n>1) time after\n    // the name has been computed in the following else block.\n    var existingNameProp = func.name;\n    if (existingNameProp) {\n        return existingNameProp;\n    }\n    // hack for IE and engines that do not support Object.defineProperty on function.name (Node.js 0.10 && 0.12)\n    var existingSpecialCacheNameProp = func[exports.SPECIAL_NAME_CACHE_KEY];\n    if (existingSpecialCacheNameProp) {\n        return existingSpecialCacheNameProp;\n    }\n    var computedName = func.toString().match(FUNC_NAME_REGEXP)[1];\n    if (!defineNameProp(func, computedName)) {\n        func[exports.SPECIAL_NAME_CACHE_KEY] = computedName;\n    }\n    return computedName;\n}\nexports.functionName = functionName;\n/**\n * @returns {boolean} - has the property been successfully defined\n */\nfunction defineNameProp(obj, nameValue) {\n    var namePropDescriptor = Object.getOwnPropertyDescriptor(obj, NAME);\n    /* istanbul ignore else -> will only run in old versions of node.js */\n    if (utils_1.isUndefined(namePropDescriptor) ||\n        namePropDescriptor.configurable) {\n        Object.defineProperty(obj, NAME, {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: nameValue\n        });\n        return true;\n    }\n    /* istanbul ignore next -> will only run in old versions of node.js */\n    return false;\n}\nexports.defineNameProp = defineNameProp;\n/**\n * simple Hashtable between a string and some generic value\n * this should be removed once typescript supports ES6 style Hashtable\n */\nvar HashTable = (function () {\n    function HashTable() {\n        this._state = {};\n    }\n    HashTable.prototype.keys = function () {\n        return utils.keys(this._state);\n    };\n    HashTable.prototype.values = function () {\n        return utils.values(this._state);\n    };\n    HashTable.prototype.put = function (key, value) {\n        this._state[key] = value;\n    };\n    HashTable.prototype.putAll = function (other) {\n        this._state = utils.assign(this._state, other._state);\n    };\n    HashTable.prototype.get = function (key) {\n        // To avoid edge case with a key called \"hasOwnProperty\" we need to perform the commented out check below\n        // -> if (Object.prototype.hasOwnProperty.call(this._state, key)) { ... } <-\n        // however this costs nearly 25% of the parser's runtime.\n        // if someone decides to name their Parser class \"hasOwnProperty\" they deserve what they will get :)\n        return this._state[key];\n    };\n    HashTable.prototype.containsKey = function (key) {\n        return utils.has(this._state, key);\n    };\n    HashTable.prototype.clear = function () {\n        this._state = {};\n    };\n    return HashTable;\n}());\nexports.HashTable = HashTable;\n//# sourceMappingURL=lang_extensions.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/lang/lang_extensions.js\n// module id = 3\n// module chunks = 0","\"use strict\";\nvar utils_1 = require(\"../utils/utils\");\nvar tokens_public_1 = require(\"./tokens_public\");\nvar lang_extensions_1 = require(\"../lang/lang_extensions\");\nfunction fillUpLineToOffset(lineToOffset, text) {\n    var currLine = 0;\n    var currOffset = 0;\n    // line 1 (idx 0 in the array) always starts at offset 0\n    lineToOffset.push(0);\n    while (currOffset < text.length) {\n        var c = text.charCodeAt(currOffset);\n        if (c === 10) {\n            currLine++;\n            // +1 because the next line starts only AFTER the \"\\n\"\n            lineToOffset.push(currOffset + 1);\n        }\n        else if (c === 13) {\n            if (currOffset !== text.length - 1 &&\n                text.charCodeAt(currOffset + 1) === 10) {\n                // +2 because the next line starts only AFTER the \"\\r\\n\"\n                lineToOffset.push(currOffset + 2);\n                // \"consume\" two chars\n                currOffset++;\n            }\n            else {\n                currLine++;\n                // +1 because the next line starts only AFTER the \"\\r\"\n                lineToOffset.push(currOffset + 1);\n            }\n        }\n        currOffset++;\n    }\n    // to make the data structure consistent\n    lineToOffset.push(Infinity);\n}\nexports.fillUpLineToOffset = fillUpLineToOffset;\nfunction getStartLineFromLineToOffset(startOffset, lineToOffset) {\n    return findLineOfOffset(startOffset, lineToOffset);\n}\nexports.getStartLineFromLineToOffset = getStartLineFromLineToOffset;\nfunction getEndLineFromLineToOffset(endOffset, lineToOffset) {\n    return findLineOfOffset(endOffset, lineToOffset);\n}\nexports.getEndLineFromLineToOffset = getEndLineFromLineToOffset;\nfunction getStartColumnFromLineToOffset(startOffset, lineToOffset) {\n    return findColumnOfOffset(startOffset, lineToOffset);\n}\nexports.getStartColumnFromLineToOffset = getStartColumnFromLineToOffset;\nfunction getEndColumnFromLineToOffset(endOffset, lineToOffset) {\n    // none inclusive\n    return findColumnOfOffset(endOffset, lineToOffset);\n}\nexports.getEndColumnFromLineToOffset = getEndColumnFromLineToOffset;\n/**\n *  Modification of a binary search to seek\n */\nfunction findLineOfOffset(targetOffset, lineToOffset) {\n    var lowIdx = 0;\n    var highIdx = lineToOffset.length - 1;\n    var found = false;\n    var line = -1;\n    while (!found) {\n        var middleIdx = Math.floor((highIdx + lowIdx) / 2);\n        var middleOffset = lineToOffset[middleIdx];\n        var middleNextOffset = lineToOffset[middleIdx + 1];\n        if (middleOffset <= targetOffset &&\n            middleNextOffset > targetOffset) {\n            found = true;\n            line = middleIdx;\n        }\n        else if (middleOffset > targetOffset) {\n            highIdx = middleIdx;\n        }\n        else if (middleNextOffset < targetOffset) {\n            lowIdx = middleIdx;\n        }/* istanbul ignore else */ \n        else if (middleNextOffset === targetOffset) {\n            found = true;\n            line = middleIdx + 1;\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n    }\n    // +1 because lines are counted from 1 while array indices are zero based.\n    return line + 1;\n}\nfunction findColumnOfOffset(offset, lineToOffset) {\n    var line = findLineOfOffset(offset, lineToOffset);\n    // +1 because columns always start at 1\n    return offset - lineToOffset[line - 1] + 1;\n}\nfunction tokenStructuredMatcher(tokInstance, tokConstructor) {\n    if (tokInstance.tokenType === tokConstructor.tokenType) {\n        return true;\n    }\n    else if (tokConstructor.extendingTokenTypes.length > 0) {\n        var extendingTokenTypes = tokConstructor.extendingTokenTypes;\n        var extendingTokenTypesLength = extendingTokenTypes.length;\n        for (var i = 0; i < extendingTokenTypesLength; i++) {\n            if (extendingTokenTypes[i] === tokInstance.tokenType) {\n                return true;\n            }\n        }\n        return false;\n    }\n    else {\n        return false;\n    }\n}\nexports.tokenStructuredMatcher = tokenStructuredMatcher;\nfunction tokenInstanceofMatcher(tokInstance, tokConstructor) {\n    return tokInstance instanceof tokConstructor;\n}\nexports.tokenInstanceofMatcher = tokenInstanceofMatcher;\nfunction tokenClassIdentity(tokenConstructor) {\n    // return tokenName(tokenConstructor)\n    return tokenConstructor.tokenType;\n}\nexports.tokenClassIdentity = tokenClassIdentity;\nfunction tokenInstanceIdentity(tokenInstance) {\n    return tokenInstance.constructor.tokenType;\n}\nexports.tokenInstanceIdentity = tokenInstanceIdentity;\nfunction tokenStructuredIdentity(token) {\n    return token.tokenType;\n}\nexports.tokenStructuredIdentity = tokenStructuredIdentity;\nfunction isBaseTokenOrObject(tokClass) {\n    return isBaseTokenClass(tokClass) || tokClass === Object;\n}\nexports.isBaseTokenOrObject = isBaseTokenOrObject;\nfunction isBaseTokenClass(tokClass) {\n    return tokClass === tokens_public_1.Token || tokClass === tokens_public_1.LazyToken || tokClass === tokens_public_1.SimpleLazyToken;\n}\nexports.isBaseTokenClass = isBaseTokenClass;\nexports.tokenShortNameIdx = 1;\nexports.tokenIdxToClass = new lang_extensions_1.HashTable();\nfunction augmentTokenClasses(tokenClasses) {\n    // 1. collect the parent Token classes as well.\n    var tokenClassesAndParents = expandTokenHierarchy(tokenClasses);\n    // 2. add required tokenType and extendingTokenTypes properties\n    assignTokenDefaultProps(tokenClassesAndParents);\n    // 3. fill up the extendingTokenTypes\n    assignExtendingTokensProp(tokenClassesAndParents);\n}\nexports.augmentTokenClasses = augmentTokenClasses;\nfunction expandTokenHierarchy(tokenClasses) {\n    var tokenClassesAndParents = utils_1.cloneArr(tokenClasses);\n    utils_1.forEach(tokenClasses, function (currTokClass) {\n        var currParentClass = utils_1.getSuperClass(currTokClass);\n        while (!isBaseTokenOrObject(currParentClass)) {\n            if (!utils_1.contains(tokenClassesAndParents, currParentClass)) {\n                tokenClassesAndParents.push(currParentClass);\n            }\n            currParentClass = utils_1.getSuperClass(currParentClass);\n        }\n    });\n    return tokenClassesAndParents;\n}\nexports.expandTokenHierarchy = expandTokenHierarchy;\nfunction assignTokenDefaultProps(tokenClasses) {\n    utils_1.forEach(tokenClasses, function (currTokClass) {\n        if (!hasShortKeyProperty(currTokClass)) {\n            exports.tokenIdxToClass.put(exports.tokenShortNameIdx, currTokClass);\n            currTokClass.tokenType = exports.tokenShortNameIdx++;\n        }\n        if (!hasExtendingTokensTypesProperty(currTokClass)) {\n            currTokClass.extendingTokenTypes = [];\n        }\n    });\n}\nexports.assignTokenDefaultProps = assignTokenDefaultProps;\nfunction assignExtendingTokensProp(tokenClasses) {\n    utils_1.forEach(tokenClasses, function (currTokClass) {\n        var currSubClassesExtendingTypes = [currTokClass.tokenType];\n        var currParentClass = utils_1.getSuperClass(currTokClass);\n        while (!isBaseTokenClass(currParentClass) && currParentClass !== Object) {\n            var newExtendingTypes = utils_1.difference(currSubClassesExtendingTypes, currParentClass.extendingTokenTypes);\n            currParentClass.extendingTokenTypes = currParentClass.extendingTokenTypes.concat(newExtendingTypes);\n            currSubClassesExtendingTypes.push(currParentClass.tokenType);\n            currParentClass = utils_1.getSuperClass(currParentClass);\n        }\n    });\n}\nexports.assignExtendingTokensProp = assignExtendingTokensProp;\nfunction hasShortKeyProperty(tokClass) {\n    return utils_1.has(tokClass, \"tokenType\");\n}\nexports.hasShortKeyProperty = hasShortKeyProperty;\nfunction hasExtendingTokensTypesProperty(tokClass) {\n    return utils_1.has(tokClass, \"extendingTokenTypes\");\n}\nexports.hasExtendingTokensTypesProperty = hasExtendingTokensTypesProperty;\nfunction createSimpleLazyToken(startOffset, endOffset, tokClass, cacheData) {\n    return {\n        startOffset: startOffset,\n        endOffset: endOffset,\n        tokenType: tokClass.tokenType,\n        cacheData: cacheData\n    };\n}\nexports.createSimpleLazyToken = createSimpleLazyToken;\nfunction createLazyTokenInstance(startOffset, endOffset, tokClass, cacheData) {\n    return new tokClass(startOffset, endOffset, cacheData);\n}\nexports.createLazyTokenInstance = createLazyTokenInstance;\nfunction isInheritanceBasedToken(token) {\n    return token instanceof tokens_public_1.Token || token instanceof tokens_public_1.LazyToken;\n}\nexports.isInheritanceBasedToken = isInheritanceBasedToken;\nfunction getImageFromLazyToken(lazyToken) {\n    if (lazyToken.isInsertedInRecovery) {\n        return \"\";\n    }\n    return lazyToken.cacheData.orgText.substring(lazyToken.startOffset, lazyToken.endOffset + 1);\n}\nexports.getImageFromLazyToken = getImageFromLazyToken;\nfunction getStartLineFromLazyToken(lazyToken) {\n    if (lazyToken.isInsertedInRecovery) {\n        return NaN;\n    }\n    ensureLineDataProcessing(lazyToken.cacheData);\n    return getStartLineFromLineToOffset(lazyToken.startOffset, lazyToken.cacheData.lineToOffset);\n}\nexports.getStartLineFromLazyToken = getStartLineFromLazyToken;\nfunction getStartColumnFromLazyToken(lazyToken) {\n    if (lazyToken.isInsertedInRecovery) {\n        return NaN;\n    }\n    ensureLineDataProcessing(lazyToken.cacheData);\n    return getStartColumnFromLineToOffset(lazyToken.startOffset, lazyToken.cacheData.lineToOffset);\n}\nexports.getStartColumnFromLazyToken = getStartColumnFromLazyToken;\nfunction getEndLineFromLazyToken(lazyToken) {\n    if (lazyToken.isInsertedInRecovery) {\n        return NaN;\n    }\n    ensureLineDataProcessing(lazyToken.cacheData);\n    return getEndLineFromLineToOffset(lazyToken.endOffset, lazyToken.cacheData.lineToOffset);\n}\nexports.getEndLineFromLazyToken = getEndLineFromLazyToken;\nfunction getEndColumnFromLazyToken(lazyToken) {\n    if (lazyToken.isInsertedInRecovery) {\n        return NaN;\n    }\n    ensureLineDataProcessing(lazyToken.cacheData);\n    return getEndColumnFromLineToOffset(lazyToken.endOffset, lazyToken.cacheData.lineToOffset);\n}\nexports.getEndColumnFromLazyToken = getEndColumnFromLazyToken;\nfunction ensureLineDataProcessing(cacheData) {\n    if (utils_1.isEmpty(cacheData.lineToOffset)) {\n        fillUpLineToOffset(cacheData.lineToOffset, cacheData.orgText);\n    }\n}\nexports.ensureLineDataProcessing = ensureLineDataProcessing;\nfunction isLazyTokenType(tokType) {\n    return tokens_public_1.LazyToken.prototype.isPrototypeOf(tokType.prototype) ||\n        tokens_public_1.SimpleLazyToken.prototype.isPrototypeOf(tokType.prototype);\n}\nexports.isLazyTokenType = isLazyTokenType;\nfunction isSimpleTokenType(tokType) {\n    return tokens_public_1.SimpleLazyToken.prototype.isPrototypeOf(tokType.prototype);\n}\nexports.isSimpleTokenType = isSimpleTokenType;\n//# sourceMappingURL=tokens.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/scan/tokens.js\n// module id = 4\n// module chunks = 0","\"use strict\";\nvar gast_public_1 = require(\"./gast_public\");\nvar gast_1 = require(\"./gast\");\nvar utils_1 = require(\"../../utils/utils\");\nfunction first(prod) {\n    if (prod instanceof gast_public_1.gast.NonTerminal) {\n        // this could in theory cause infinite loops if\n        // (1) prod A refs prod B.\n        // (2) prod B refs prod A\n        // (3) AB can match the empty set\n        // in other words a cycle where everything is optional so the first will keep\n        // looking ahead for the next optional part and will never exit\n        // currently there is no safeguard for this unique edge case because\n        // (1) not sure a grammar in which this can happen is useful for anything (productive)\n        return first(prod.referencedRule);\n    }\n    else if (prod instanceof gast_public_1.gast.Terminal) {\n        return firstForTerminal(prod);\n    }\n    else if (gast_1.isSequenceProd(prod)) {\n        return firstForSequence(prod);\n    }/* istanbul ignore else */ \n    else if (gast_1.isBranchingProd(prod)) {\n        return firstForBranching(prod);\n    }\n    else {\n        /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n    }\n}\nexports.first = first;\nfunction firstForSequence(prod) {\n    var firstSet = [];\n    var seq = prod.definition;\n    var nextSubProdIdx = 0;\n    var hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    var currSubProd;\n    // so we enter the loop at least once (if the definition is not empty\n    var isLastInnerProdOptional = true;\n    // scan a sequence until it's end or until we have found a NONE optional production in it\n    while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n        currSubProd = seq[nextSubProdIdx];\n        isLastInnerProdOptional = gast_1.isOptionalProd(currSubProd);\n        firstSet = firstSet.concat(first(currSubProd));\n        nextSubProdIdx = nextSubProdIdx + 1;\n        hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    }\n    return utils_1.uniq(firstSet);\n}\nexports.firstForSequence = firstForSequence;\nfunction firstForBranching(prod) {\n    var allAlternativesFirsts = utils_1.map(prod.definition, function (innerProd) {\n        return first(innerProd);\n    });\n    return utils_1.uniq(utils_1.flatten(allAlternativesFirsts));\n}\nexports.firstForBranching = firstForBranching;\nfunction firstForTerminal(terminal) {\n    return [terminal.terminalType];\n}\nexports.firstForTerminal = firstForTerminal;\n//# sourceMappingURL=first.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/first.js\n// module id = 5\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\nvar gast_public_1 = require(\"./gast_public\");\nvar utils_1 = require(\"../../utils/utils\");\nfunction isSequenceProd(prod) {\n    return prod instanceof gast_public_1.gast.Flat ||\n        prod instanceof gast_public_1.gast.Option ||\n        prod instanceof gast_public_1.gast.Repetition ||\n        prod instanceof gast_public_1.gast.RepetitionMandatory ||\n        prod instanceof gast_public_1.gast.RepetitionMandatoryWithSeparator ||\n        prod instanceof gast_public_1.gast.RepetitionWithSeparator ||\n        prod instanceof gast_public_1.gast.Terminal ||\n        prod instanceof gast_public_1.gast.Rule;\n}\nexports.isSequenceProd = isSequenceProd;\nfunction isOptionalProd(prod, alreadyVisited) {\n    if (alreadyVisited === void 0) { alreadyVisited = []; }\n    var isDirectlyOptional = prod instanceof gast_public_1.gast.Option ||\n        prod instanceof gast_public_1.gast.Repetition ||\n        prod instanceof gast_public_1.gast.RepetitionWithSeparator;\n    if (isDirectlyOptional) {\n        return true;\n    }\n    // note that this can cause infinite loop if one optional empty TOP production has a cyclic dependency with another\n    // empty optional top rule\n    // may be indirectly optional ((A?B?C?) | (D?E?F?))\n    if (prod instanceof gast_public_1.gast.Alternation) {\n        // for OR its enough for just one of the alternatives to be optional\n        return utils_1.some(prod.definition, function (subProd) {\n            return isOptionalProd(subProd, alreadyVisited);\n        });\n    }\n    else if (prod instanceof gast_public_1.gast.NonTerminal && utils_1.contains(alreadyVisited, prod)) {\n        // avoiding stack overflow due to infinite recursion\n        return false;\n    }\n    else if (prod instanceof gast_public_1.gast.AbstractProduction) {\n        if (prod instanceof gast_public_1.gast.NonTerminal) {\n            alreadyVisited.push(prod);\n        }\n        return utils_1.every(prod.definition, function (subProd) {\n            return isOptionalProd(subProd, alreadyVisited);\n        });\n    }\n    else {\n        return false;\n    }\n}\nexports.isOptionalProd = isOptionalProd;\nfunction isBranchingProd(prod) {\n    return prod instanceof gast_public_1.gast.Alternation;\n}\nexports.isBranchingProd = isBranchingProd;\nfunction getProductionDslName(prod) {\n    if (prod instanceof gast_public_1.gast.NonTerminal) {\n        return \"SUBRULE\";\n    }\n    else if (prod instanceof gast_public_1.gast.Option) {\n        return \"OPTION\";\n    }\n    else if (prod instanceof gast_public_1.gast.Alternation) {\n        return \"OR\";\n    }\n    else if (prod instanceof gast_public_1.gast.RepetitionMandatory) {\n        return \"AT_LEAST_ONE\";\n    }\n    else if (prod instanceof gast_public_1.gast.RepetitionMandatoryWithSeparator) {\n        return \"AT_LEAST_ONE_SEP\";\n    }\n    else if (prod instanceof gast_public_1.gast.RepetitionWithSeparator) {\n        return \"MANY_SEP\";\n    }\n    else if (prod instanceof gast_public_1.gast.Repetition) {\n        return \"MANY\";\n    }/* istanbul ignore else */ \n    else if (prod instanceof gast_public_1.gast.Terminal) {\n        return \"CONSUME\";\n    }\n    else {\n        /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n    }\n}\nexports.getProductionDslName = getProductionDslName;\nvar GastCloneVisitor = (function (_super) {\n    __extends(GastCloneVisitor, _super);\n    function GastCloneVisitor() {\n        return _super.apply(this, arguments) /* istanbul ignore next */ || this;\n    }\n    GastCloneVisitor.prototype.visitNonTerminal = function (node) {\n        return new gast_public_1.gast.NonTerminal(node.nonTerminalName, undefined, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitFlat = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.Flat(definition);\n    };\n    GastCloneVisitor.prototype.visitOption = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.Option(definition, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitRepetition = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.Repetition(definition, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitRepetitionMandatory = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.RepetitionMandatory(definition, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitRepetitionMandatoryWithSeparator = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.RepetitionMandatoryWithSeparator(definition, node.separator, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitRepetitionWithSeparator = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.RepetitionWithSeparator(definition, node.separator, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitAlternation = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.Alternation(definition, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitTerminal = function (node) {\n        return new gast_public_1.gast.Terminal(node.terminalType, node.occurrenceInParent);\n    };\n    GastCloneVisitor.prototype.visitRule = function (node) {\n        var _this = this;\n        var definition = utils_1.map(node.definition, function (currSubDef) { return _this.visit(currSubDef); });\n        return new gast_public_1.gast.Rule(node.name, definition, node.orgText);\n    };\n    return GastCloneVisitor;\n}(gast_public_1.gast.GAstVisitor));\nfunction cloneProduction(prod) {\n    var cloningVisitor = new GastCloneVisitor();\n    return cloningVisitor.visit(prod);\n}\nexports.cloneProduction = cloneProduction;\n//# sourceMappingURL=gast.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/gast.js\n// module id = 6\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\n/* tslint:disable:no-use-before-declare */\nvar rest_1 = require(\"./rest\");\nvar gast_public_1 = require(\"./gast_public\");\nvar utils_1 = require(\"../../utils/utils\");\nvar tokens_public_1 = require(\"../../scan/tokens_public\");\nvar first_1 = require(\"./first\");\n/* tslint:enable:no-use-before-declare */\nvar AbstractNextPossibleTokensWalker = (function (_super) {\n    __extends(AbstractNextPossibleTokensWalker, _super);\n    function AbstractNextPossibleTokensWalker(topProd, path) {\n        var _this = _super.call(this) || this;\n        _this.topProd = topProd;\n        _this.path = path;\n        _this.possibleTokTypes = [];\n        _this.nextProductionName = \"\";\n        _this.nextProductionOccurrence = 0;\n        _this.found = false;\n        _this.isAtEndOfPath = false;\n        return _this;\n    }\n    AbstractNextPossibleTokensWalker.prototype.startWalking = function () {\n        this.found = false;\n        if (this.path.ruleStack[0] !== this.topProd.name) {\n            throw Error(\"The path does not start with the walker's top Rule!\");\n        }\n        // immutable for the win\n        this.ruleStack = (utils_1.cloneArr(this.path.ruleStack)).reverse(); // intelij bug requires assertion\n        this.occurrenceStack = (utils_1.cloneArr(this.path.occurrenceStack)).reverse(); // intelij bug requires assertion\n        // already verified that the first production is valid, we now seek the 2nd production\n        this.ruleStack.pop();\n        this.occurrenceStack.pop();\n        this.updateExpectedNext();\n        this.walk(this.topProd);\n        return this.possibleTokTypes;\n    };\n    AbstractNextPossibleTokensWalker.prototype.walk = function (prod, prevRest) {\n        if (prevRest === void 0) { prevRest = []; }\n        // stop scanning once we found the path\n        if (!this.found) {\n            _super.prototype.walk.call(this, prod, prevRest);\n        }\n    };\n    AbstractNextPossibleTokensWalker.prototype.walkProdRef = function (refProd, currRest, prevRest) {\n        // found the next production, need to keep walking in it\n        if (refProd.referencedRule.name === this.nextProductionName &&\n            refProd.occurrenceInParent === this.nextProductionOccurrence) {\n            var fullRest = currRest.concat(prevRest);\n            this.updateExpectedNext();\n            this.walk(refProd.referencedRule, fullRest);\n        }\n    };\n    AbstractNextPossibleTokensWalker.prototype.updateExpectedNext = function () {\n        // need to consume the Terminal\n        if (utils_1.isEmpty(this.ruleStack)) {\n            // must reset nextProductionXXX to avoid walking down another Top Level production while what we are\n            // really seeking is the last Terminal...\n            this.nextProductionName = \"\";\n            this.nextProductionOccurrence = 0;\n            this.isAtEndOfPath = true;\n        }\n        else {\n            this.nextProductionName = this.ruleStack.pop();\n            this.nextProductionOccurrence = this.occurrenceStack.pop();\n        }\n    };\n    return AbstractNextPossibleTokensWalker;\n}(rest_1.RestWalker));\nexports.AbstractNextPossibleTokensWalker = AbstractNextPossibleTokensWalker;\nvar NextAfterTokenWalker = (function (_super) {\n    __extends(NextAfterTokenWalker, _super);\n    function NextAfterTokenWalker(topProd, path) {\n        var _this = _super.call(this, topProd, path) /* istanbul ignore next */ || this;\n        _this.path = path;\n        _this.nextTerminalName = \"\";\n        _this.nextTerminalOccurrence = 0;\n        _this.nextTerminalName = tokens_public_1.tokenName(_this.path.lastTok);\n        _this.nextTerminalOccurrence = _this.path.lastTokOccurrence;\n        return _this;\n    }\n    NextAfterTokenWalker.prototype.walkTerminal = function (terminal, currRest, prevRest) {\n        if (this.isAtEndOfPath && tokens_public_1.tokenName(terminal.terminalType) === this.nextTerminalName &&\n            terminal.occurrenceInParent === this.nextTerminalOccurrence && !(this.found)) {\n            var fullRest = currRest.concat(prevRest);\n            var restProd = new gast_public_1.gast.Flat(fullRest);\n            this.possibleTokTypes = first_1.first(restProd);\n            this.found = true;\n        }\n    };\n    return NextAfterTokenWalker;\n}(AbstractNextPossibleTokensWalker));\nexports.NextAfterTokenWalker = NextAfterTokenWalker;\n/**\n * This walker only \"walks\" a single \"TOP\" level in the Grammar Ast, this means\n * it never \"follows\" production refs\n */\nvar AbstractNextTerminalAfterProductionWalker = (function (_super) {\n    __extends(AbstractNextTerminalAfterProductionWalker, _super);\n    function AbstractNextTerminalAfterProductionWalker(topRule, occurrence) {\n        var _this = _super.call(this) || this;\n        _this.topRule = topRule;\n        _this.occurrence = occurrence;\n        _this.result = { token: undefined, occurrence: undefined, isEndOfRule: undefined };\n        return _this;\n    }\n    AbstractNextTerminalAfterProductionWalker.prototype.startWalking = function () {\n        this.walk(this.topRule);\n        return this.result;\n    };\n    return AbstractNextTerminalAfterProductionWalker;\n}(rest_1.RestWalker));\nexports.AbstractNextTerminalAfterProductionWalker = AbstractNextTerminalAfterProductionWalker;\nvar NextTerminalAfterManyWalker = (function (_super) {\n    __extends(NextTerminalAfterManyWalker, _super);\n    function NextTerminalAfterManyWalker() {\n        return _super.apply(this, arguments) /* istanbul ignore next */ || this;\n    }\n    NextTerminalAfterManyWalker.prototype.walkMany = function (manyProd, currRest, prevRest) {\n        if (manyProd.occurrenceInParent === this.occurrence) {\n            var firstAfterMany = utils_1.first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterMany === undefined;\n            if (firstAfterMany instanceof gast_public_1.gast.Terminal) {\n                this.result.token = firstAfterMany.terminalType;\n                this.result.occurrence = firstAfterMany.occurrenceInParent;\n            }\n        }\n        else {\n            _super.prototype.walkMany.call(this, manyProd, currRest, prevRest);\n        }\n    };\n    return NextTerminalAfterManyWalker;\n}(AbstractNextTerminalAfterProductionWalker));\nexports.NextTerminalAfterManyWalker = NextTerminalAfterManyWalker;\nvar NextTerminalAfterManySepWalker = (function (_super) {\n    __extends(NextTerminalAfterManySepWalker, _super);\n    function NextTerminalAfterManySepWalker() {\n        return _super.apply(this, arguments) /* istanbul ignore next */ || this;\n    }\n    NextTerminalAfterManySepWalker.prototype.walkManySep = function (manySepProd, currRest, prevRest) {\n        if (manySepProd.occurrenceInParent === this.occurrence) {\n            var firstAfterManySep = utils_1.first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterManySep === undefined;\n            if (firstAfterManySep instanceof gast_public_1.gast.Terminal) {\n                this.result.token = firstAfterManySep.terminalType;\n                this.result.occurrence = firstAfterManySep.occurrenceInParent;\n            }\n        }\n        else {\n            _super.prototype.walkManySep.call(this, manySepProd, currRest, prevRest);\n        }\n    };\n    return NextTerminalAfterManySepWalker;\n}(AbstractNextTerminalAfterProductionWalker));\nexports.NextTerminalAfterManySepWalker = NextTerminalAfterManySepWalker;\nvar NextTerminalAfterAtLeastOneWalker = (function (_super) {\n    __extends(NextTerminalAfterAtLeastOneWalker, _super);\n    function NextTerminalAfterAtLeastOneWalker() {\n        return _super.apply(this, arguments) /* istanbul ignore next */ || this;\n    }\n    NextTerminalAfterAtLeastOneWalker.prototype.walkAtLeastOne = function (atLeastOneProd, currRest, prevRest) {\n        if (atLeastOneProd.occurrenceInParent === this.occurrence) {\n            var firstAfterAtLeastOne = utils_1.first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterAtLeastOne === undefined;\n            if (firstAfterAtLeastOne instanceof gast_public_1.gast.Terminal) {\n                this.result.token = firstAfterAtLeastOne.terminalType;\n                this.result.occurrence = firstAfterAtLeastOne.occurrenceInParent;\n            }\n        }\n        else {\n            _super.prototype.walkAtLeastOne.call(this, atLeastOneProd, currRest, prevRest);\n        }\n    };\n    return NextTerminalAfterAtLeastOneWalker;\n}(AbstractNextTerminalAfterProductionWalker));\nexports.NextTerminalAfterAtLeastOneWalker = NextTerminalAfterAtLeastOneWalker;\n// TODO: reduce code duplication in the AfterWalkers\nvar NextTerminalAfterAtLeastOneSepWalker = (function (_super) {\n    __extends(NextTerminalAfterAtLeastOneSepWalker, _super);\n    function NextTerminalAfterAtLeastOneSepWalker() {\n        return _super.apply(this, arguments) /* istanbul ignore next */ || this;\n    }\n    NextTerminalAfterAtLeastOneSepWalker.prototype.walkAtLeastOneSep = function (atleastOneSepProd, currRest, prevRest) {\n        if (atleastOneSepProd.occurrenceInParent === this.occurrence) {\n            var firstAfterfirstAfterAtLeastOneSep = utils_1.first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === undefined;\n            if (firstAfterfirstAfterAtLeastOneSep instanceof gast_public_1.gast.Terminal) {\n                this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n                this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.occurrenceInParent;\n            }\n        }\n        else {\n            _super.prototype.walkAtLeastOneSep.call(this, atleastOneSepProd, currRest, prevRest);\n        }\n    };\n    return NextTerminalAfterAtLeastOneSepWalker;\n}(AbstractNextTerminalAfterProductionWalker));\nexports.NextTerminalAfterAtLeastOneSepWalker = NextTerminalAfterAtLeastOneSepWalker;\nfunction possiblePathsFrom(targetDef, maxLength, currPath) {\n    if (currPath === void 0) { currPath = []; }\n    // avoid side effects\n    currPath = utils_1.cloneArr(currPath);\n    var result = [];\n    var i = 0;\n    function remainingPathWith(nextDef) {\n        return nextDef.concat(utils_1.drop(targetDef, i + 1));\n    }\n    function getAlternativesForProd(prod) {\n        var alternatives = possiblePathsFrom(remainingPathWith(prod.definition), maxLength, currPath);\n        return result.concat(alternatives);\n    }\n    /**\n     * Mandatory productions will halt the loop as the paths computed from their recursive calls will already contain the\n     * following (rest) of the targetDef.\n     *\n     * For optional productions (Option/Repetition/...) the loop will continue to represent the paths that do not include the\n     * the optional production.\n     */\n    while (currPath.length < maxLength && i < targetDef.length) {\n        var prod = targetDef[i];\n        if (prod instanceof gast_public_1.gast.Flat) {\n            return getAlternativesForProd(prod);\n        }\n        else if (prod instanceof gast_public_1.gast.NonTerminal) {\n            return getAlternativesForProd(prod);\n        }\n        else if (prod instanceof gast_public_1.gast.Option) {\n            result = getAlternativesForProd(prod);\n        }\n        else if (prod instanceof gast_public_1.gast.RepetitionMandatory) {\n            return getAlternativesForProd(prod);\n        }\n        else if (prod instanceof gast_public_1.gast.RepetitionMandatoryWithSeparator) {\n            return getAlternativesForProd(prod);\n        }\n        else if (prod instanceof gast_public_1.gast.RepetitionWithSeparator) {\n            result = getAlternativesForProd(prod);\n        }\n        else if (prod instanceof gast_public_1.gast.Repetition) {\n            result = getAlternativesForProd(prod);\n        }\n        else if (prod instanceof gast_public_1.gast.Alternation) {\n            utils_1.forEach(prod.definition, function (currAlt) {\n                result = getAlternativesForProd(currAlt);\n            });\n            return result;\n        }/* istanbul ignore else */ \n        else if (prod instanceof gast_public_1.gast.Terminal) {\n            currPath.push(prod.terminalType);\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n        i++;\n    }\n    result.push({\n        partialPath: currPath,\n        suffixDef: utils_1.drop(targetDef, 1)\n    });\n    return result;\n}\nexports.possiblePathsFrom = possiblePathsFrom;\nfunction nextPossibleTokensAfter(initialDef, tokenVector, tokMatcher, maxLookAhead) {\n    var EXIT_NON_TERMINAL = \"EXIT_NONE_TERMINAL\";\n    // to avoid creating a new Array each time.\n    var EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n    var EXIT_ALTERNATIVE = \"EXIT_ALTERNATIVE\";\n    var foundCompletePath = false;\n    var tokenVectorLength = tokenVector.length;\n    var minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n    var result = [];\n    var possiblePaths = [];\n    possiblePaths.push({ idx: -1, def: initialDef, ruleStack: [], occurrenceStack: [] });\n    while (!utils_1.isEmpty(possiblePaths)) {\n        var currPath = possiblePaths.pop();\n        // skip alternatives if no more results can be found (assuming deterministic grammar with fixed lookahead)\n        if (currPath === EXIT_ALTERNATIVE) {\n            if (foundCompletePath &&\n                utils_1.last(possiblePaths).idx <= minimalAlternativesIndex) {\n                // remove irrelevant alternative\n                possiblePaths.pop();\n            }\n            continue;\n        }\n        var currDef = currPath.def;\n        var currIdx = currPath.idx;\n        var currRuleStack = currPath.ruleStack;\n        var currOccurrenceStack = currPath.occurrenceStack;\n        // For Example: an empty path could exist in a valid grammar in the case of an EMPTY_ALT\n        if (utils_1.isEmpty(currDef)) {\n            continue;\n        }\n        var prod = currDef[0];\n        if (prod === EXIT_NON_TERMINAL) {\n            var nextPath = {\n                idx: currIdx,\n                def: utils_1.drop(currDef),\n                ruleStack: utils_1.dropRight(currRuleStack),\n                occurrenceStack: utils_1.dropRight(currOccurrenceStack)\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof gast_public_1.gast.Terminal) {\n            if (currIdx < tokenVectorLength - 1) {\n                var nextIdx = currIdx + 1;\n                var actualToken = tokenVector[nextIdx];\n                if (tokMatcher(actualToken, prod.terminalType)) {\n                    var nextPath = {\n                        idx: nextIdx,\n                        def: utils_1.drop(currDef),\n                        ruleStack: currRuleStack,\n                        occurrenceStack: currOccurrenceStack\n                    };\n                    possiblePaths.push(nextPath);\n                }\n            }/* istanbul ignore else */ \n            else if (currIdx === tokenVectorLength - 1) {\n                \n                result.push({\n                    nextTokenType: prod.terminalType,\n                    nextTokenOccurrence: prod.occurrenceInParent,\n                    ruleStack: currRuleStack,\n                    occurrenceStack: currOccurrenceStack\n                });\n                foundCompletePath = true;\n            }\n            else {\n                /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n            }\n        }\n        else if (prod instanceof gast_public_1.gast.NonTerminal) {\n            var newRuleStack = utils_1.cloneArr(currRuleStack);\n            newRuleStack.push(prod.nonTerminalName);\n            var newOccurrenceStack = utils_1.cloneArr(currOccurrenceStack);\n            newOccurrenceStack.push(prod.occurrenceInParent);\n            var nextPath = {\n                idx: currIdx,\n                def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, utils_1.drop(currDef)),\n                ruleStack: newRuleStack,\n                occurrenceStack: newOccurrenceStack\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof gast_public_1.gast.Option) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            var nextPathWithout = {\n                idx: currIdx,\n                def: utils_1.drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            var nextPathWith = {\n                idx: currIdx,\n                def: prod.definition.concat(utils_1.drop(currDef)),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof gast_public_1.gast.RepetitionMandatory) {\n            // TODO:(THE NEW operators here take a while...) (convert once?)\n            var secondIteration = new gast_public_1.gast.Repetition(prod.definition, prod.occurrenceInParent);\n            var nextDef = prod.definition.concat([secondIteration], utils_1.drop(currDef));\n            var nextPath = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof gast_public_1.gast.RepetitionMandatoryWithSeparator) {\n            // TODO:(THE NEW operators here take a while...) (convert once?)\n            var separatorGast = new gast_public_1.gast.Terminal(prod.separator);\n            var secondIteration = new gast_public_1.gast.Repetition([separatorGast].concat(prod.definition), prod.occurrenceInParent);\n            var nextDef = prod.definition.concat([secondIteration], utils_1.drop(currDef));\n            var nextPath = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof gast_public_1.gast.RepetitionWithSeparator) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            var nextPathWithout = {\n                idx: currIdx,\n                def: utils_1.drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            var separatorGast = new gast_public_1.gast.Terminal(prod.separator);\n            var nthRepetition = new gast_public_1.gast.Repetition([separatorGast].concat(prod.definition), prod.occurrenceInParent);\n            var nextDef = prod.definition.concat([nthRepetition], utils_1.drop(currDef));\n            var nextPathWith = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof gast_public_1.gast.Repetition) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            var nextPathWithout = {\n                idx: currIdx,\n                def: utils_1.drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            // TODO: an empty repetition will cause infinite loops here, will the parser detect this in selfAnalysis?\n            var nthRepetition = new gast_public_1.gast.Repetition(prod.definition, prod.occurrenceInParent);\n            var nextDef = prod.definition.concat([nthRepetition], utils_1.drop(currDef));\n            var nextPathWith = {\n                idx: currIdx, def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof gast_public_1.gast.Alternation) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            for (var i = prod.definition.length - 1; i >= 0; i--) {\n                var currAlt = prod.definition[i];\n                var currAltPath = {\n                    idx: currIdx,\n                    def: currAlt.definition.concat(utils_1.drop(currDef)),\n                    ruleStack: currRuleStack,\n                    occurrenceStack: currOccurrenceStack\n                };\n                possiblePaths.push(currAltPath);\n                possiblePaths.push(EXIT_ALTERNATIVE);\n            }\n        }\n        else if (prod instanceof gast_public_1.gast.Flat) {\n            possiblePaths.push({\n                idx: currIdx,\n                def: prod.definition.concat(utils_1.drop(currDef)),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack\n            });\n        }/* istanbul ignore else */ \n        else if (prod instanceof gast_public_1.gast.Rule) {\n            possiblePaths.push(expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack));\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n    }\n    return result;\n}\nexports.nextPossibleTokensAfter = nextPossibleTokensAfter;\nfunction expandTopLevelRule(topRule, currIdx, currRuleStack, currOccurrenceStack) {\n    var newRuleStack = utils_1.cloneArr(currRuleStack);\n    newRuleStack.push(topRule.name);\n    var newCurrOccurrenceStack = utils_1.cloneArr(currOccurrenceStack);\n    // top rule is always assumed to have been called with occurrence index 1\n    newCurrOccurrenceStack.push(1);\n    return {\n        idx: currIdx,\n        def: topRule.definition,\n        ruleStack: newRuleStack,\n        occurrenceStack: newCurrOccurrenceStack\n    };\n}\n//# sourceMappingURL=interpreter.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/interpreter.js\n// module id = 7\n// module chunks = 0","\"use strict\";\nvar gast_public_1 = require(\"./gast_public\");\nvar utils_1 = require(\"../../utils/utils\");\n/**\n *  A Grammar Walker that computes the \"remaining\" grammar \"after\" a productions in the grammar.\n */\nvar RestWalker = (function () {\n    function RestWalker() {\n    }\n    RestWalker.prototype.walk = function (prod, prevRest) {\n        var _this = this;\n        if (prevRest === void 0) { prevRest = []; }\n        utils_1.forEach(prod.definition, function (subProd, index) {\n            var currRest = utils_1.drop(prod.definition, index + 1);\n            if (subProd instanceof gast_public_1.gast.NonTerminal) {\n                _this.walkProdRef(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof gast_public_1.gast.Terminal) {\n                _this.walkTerminal(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof gast_public_1.gast.Flat) {\n                _this.walkFlat(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof gast_public_1.gast.Option) {\n                _this.walkOption(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof gast_public_1.gast.RepetitionMandatory) {\n                _this.walkAtLeastOne(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof gast_public_1.gast.RepetitionMandatoryWithSeparator) {\n                _this.walkAtLeastOneSep(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof gast_public_1.gast.RepetitionWithSeparator) {\n                _this.walkManySep(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof gast_public_1.gast.Repetition) {\n                _this.walkMany(subProd, currRest, prevRest);\n            }/* istanbul ignore else */ \n            else if (subProd instanceof gast_public_1.gast.Alternation) {\n                _this.walkOr(subProd, currRest, prevRest);\n            }\n            else {\n                /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n            }\n        });\n    };\n    RestWalker.prototype.walkTerminal = function (terminal, currRest, prevRest) { };\n    RestWalker.prototype.walkProdRef = function (refProd, currRest, prevRest) { };\n    RestWalker.prototype.walkFlat = function (flatProd, currRest, prevRest) {\n        // ABCDEF => after the D the rest is EF\n        var fullOrRest = currRest.concat(prevRest);\n        this.walk(flatProd, fullOrRest);\n    };\n    RestWalker.prototype.walkOption = function (optionProd, currRest, prevRest) {\n        // ABC(DE)?F => after the (DE)? the rest is F\n        var fullOrRest = currRest.concat(prevRest);\n        this.walk(optionProd, fullOrRest);\n    };\n    RestWalker.prototype.walkAtLeastOne = function (atLeastOneProd, currRest, prevRest) {\n        // ABC(DE)+F => after the (DE)+ the rest is (DE)?F\n        var fullAtLeastOneRest = [new gast_public_1.gast.Option(atLeastOneProd.definition)].concat(currRest, prevRest);\n        this.walk(atLeastOneProd, fullAtLeastOneRest);\n    };\n    RestWalker.prototype.walkAtLeastOneSep = function (atLeastOneSepProd, currRest, prevRest) {\n        // ABC DE(,DE)* F => after the (,DE)+ the rest is (,DE)?F\n        var fullAtLeastOneSepRest = restForRepetitionWithSeparator(atLeastOneSepProd, currRest, prevRest);\n        this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n    };\n    RestWalker.prototype.walkMany = function (manyProd, currRest, prevRest) {\n        // ABC(DE)*F => after the (DE)* the rest is (DE)?F\n        var fullManyRest = [new gast_public_1.gast.Option(manyProd.definition)].concat(currRest, prevRest);\n        this.walk(manyProd, fullManyRest);\n    };\n    RestWalker.prototype.walkManySep = function (manySepProd, currRest, prevRest) {\n        // ABC (DE(,DE)*)? F => after the (,DE)* the rest is (,DE)?F\n        var fullManySepRest = restForRepetitionWithSeparator(manySepProd, currRest, prevRest);\n        this.walk(manySepProd, fullManySepRest);\n    };\n    RestWalker.prototype.walkOr = function (orProd, currRest, prevRest) {\n        var _this = this;\n        // ABC(D|E|F)G => when finding the (D|E|F) the rest is G\n        var fullOrRest = currRest.concat(prevRest);\n        // walk all different alternatives\n        utils_1.forEach(orProd.definition, function (alt) {\n            // wrapping each alternative in a single definition wrapper\n            // to avoid errors in computing the rest of that alternative in the invocation to computeInProdFollows\n            // (otherwise for OR([alt1,alt2]) alt2 will be considered in 'rest' of alt1\n            var prodWrapper = new gast_public_1.gast.Flat([alt]);\n            _this.walk(prodWrapper, fullOrRest);\n        });\n    };\n    return RestWalker;\n}());\nexports.RestWalker = RestWalker;\nfunction restForRepetitionWithSeparator(repSepProd, currRest, prevRest) {\n    var repSepRest = [new gast_public_1.gast.Option([new gast_public_1.gast.Terminal(repSepProd.separator)].concat(repSepProd.definition))];\n    var fullRepSepRest = repSepRest.concat(currRest, prevRest);\n    return fullRepSepRest;\n}\n//# sourceMappingURL=rest.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/rest.js\n// module id = 8\n// module chunks = 0","\"use strict\";\nvar cache = require(\"./cache\");\nvar exceptions_public_1 = require(\"./exceptions_public\");\nvar lang_extensions_1 = require(\"../lang/lang_extensions\");\nvar resolver_1 = require(\"./grammar/resolver\");\nvar checks_1 = require(\"./grammar/checks\");\nvar utils_1 = require(\"../utils/utils\");\nvar follow_1 = require(\"./grammar/follow\");\nvar tokens_public_1 = require(\"../scan/tokens_public\");\nvar lookahead_1 = require(\"./grammar/lookahead\");\nvar gast_builder_1 = require(\"./gast_builder\");\nvar interpreter_1 = require(\"./grammar/interpreter\");\nvar constants_1 = require(\"./constants\");\nvar gast_public_1 = require(\"./grammar/gast_public\");\nvar gast_1 = require(\"./grammar/gast\");\nvar tokens_1 = require(\"../scan/tokens\");\nvar serializeGrammar = gast_public_1.gast.serializeGrammar;\nvar ParserDefinitionErrorType;\n(function (ParserDefinitionErrorType) {\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_RULE_NAME\"] = 0] = \"INVALID_RULE_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"DUPLICATE_RULE_NAME\"] = 1] = \"DUPLICATE_RULE_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_RULE_OVERRIDE\"] = 2] = \"INVALID_RULE_OVERRIDE\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"DUPLICATE_PRODUCTIONS\"] = 3] = \"DUPLICATE_PRODUCTIONS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"UNRESOLVED_SUBRULE_REF\"] = 4] = \"UNRESOLVED_SUBRULE_REF\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"LEFT_RECURSION\"] = 5] = \"LEFT_RECURSION\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"NONE_LAST_EMPTY_ALT\"] = 6] = \"NONE_LAST_EMPTY_ALT\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"AMBIGUOUS_ALTS\"] = 7] = \"AMBIGUOUS_ALTS\";\n})(ParserDefinitionErrorType = exports.ParserDefinitionErrorType || (exports.ParserDefinitionErrorType = {}));\nvar IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\nvar END_OF_FILE = new tokens_public_1.EOF();\nEND_OF_FILE.tokenType = tokens_public_1.EOF.tokenType;\nObject.freeze(END_OF_FILE);\n// Lookahead keys are 32Bit integers in the form\n// ZZZZZZZZZZZZZZZZZZZZZZZZ-YYYY-XXXX\n// XXXX -> Occurrence Index bitmap.\n// YYYY -> DSL Method Name bitmap.\n// ZZZZZZZZZZZZZZZZZZZZZZZZ -> Rule short Index bitmap.\nvar BITS_FOR_METHOD_IDX = 4;\nvar BITS_FOR_OCCURRENCE_IDX = 4;\n// short string used as part of mapping keys.\n// being short improves the performance when composing KEYS for maps out of these\n// The 4 - 7 bits (16 possible values, are reserved for the DSL method indices)\n/* tslint:disable */\nvar OR_IDX = 1 << BITS_FOR_METHOD_IDX;\nvar OPTION_IDX = 2 << BITS_FOR_METHOD_IDX;\nvar MANY_IDX = 3 << BITS_FOR_METHOD_IDX;\nvar AT_LEAST_ONE_IDX = 4 << BITS_FOR_METHOD_IDX;\nvar MANY_SEP_IDX = 5 << BITS_FOR_METHOD_IDX;\nvar AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_METHOD_IDX;\nvar DEFAULT_PARSER_CONFIG = Object.freeze({\n    recoveryEnabled: false,\n    maxLookahead: 5,\n    ignoredIssues: {},\n    dynamicTokensEnabled: false\n});\nvar DEFAULT_RULE_CONFIG = Object.freeze({\n    recoveryValueFunc: function () { return undefined; },\n    resyncEnabled: true\n});\n/**\n * Convenience used to express an empty alternative in an OR (alternation).\n * can be used to more clearly describe the intent in a case of empty alternation.\n *\n * For example:\n *\n * 1. without using EMPTY_ALT:\n *\n *    this.OR([\n *      {ALT: () => {\n *        this.CONSUME1(OneTok)\n *        return \"1\"\n *      }},\n *      {ALT: () => {\n *        this.CONSUME1(TwoTok)\n *        return \"2\"\n *      }},\n *      {ALT: () => { // implicitly empty because there are no invoked grammar rules (OR/MANY/CONSUME...) inside this alternative.\n *        return \"666\"\n *      }},\n *    ])\n *\n *\n * 2. using EMPTY_ALT:\n *\n *    this.OR([\n *      {ALT: () => {\n *        this.CONSUME1(OneTok)\n *        return \"1\"\n *      }},\n *      {ALT: () => {\n *        this.CONSUME1(TwoTok)\n *        return \"2\"\n *      }},\n *      {ALT: EMPTY_ALT(\"666\")}, // explicitly empty, clearer intent\n *    ])\n *\n */\nfunction EMPTY_ALT(value) {\n    if (value === void 0) { value = undefined; }\n    return function () {\n        return value;\n    };\n}\nexports.EMPTY_ALT = EMPTY_ALT;\nvar EOF_FOLLOW_KEY = {};\n/**\n * A Recognizer capable of self analysis to determine it's grammar structure\n * This is used for more advanced features requiring such information.\n * For example: Error Recovery, Automatic lookahead calculation.\n */\nvar Parser = (function () {\n    function Parser(input, tokensMapOrArr, config) {\n        if (config === void 0) { config = DEFAULT_PARSER_CONFIG; }\n        this._errors = [];\n        this._input = [];\n        this.inputIdx = -1;\n        this.savedTokenIdx = -1;\n        this.isBackTrackingStack = [];\n        this.RULE_STACK = [];\n        this.RULE_OCCURRENCE_STACK = [];\n        this.tokensMap = undefined;\n        this.definedRulesNames = [];\n        this.shortRuleNameToFull = new lang_extensions_1.HashTable();\n        this.ruleShortNameIdx = 1;\n        /**\n         * Only used internally for storing productions as they are built for the first time.\n         * The final productions should be accessed from the static cache.\n         */\n        this._productions = new lang_extensions_1.HashTable();\n        this._input = input;\n        // configuration\n        this.recoveryEnabled = utils_1.has(config, \"recoveryEnabled\") ?\n            config.recoveryEnabled :\n            DEFAULT_PARSER_CONFIG.recoveryEnabled;\n        // performance optimization, NOOP will be inlined which\n        // effectively means that this optional feature does not exist\n        // when not used.\n        if (!this.recoveryEnabled) {\n            this.attemptInRepetitionRecovery = utils_1.NOOP;\n        }\n        this.dynamicTokensEnabled = utils_1.has(config, \"dynamicTokensEnabled\") ?\n            config.dynamicTokensEnabled :\n            DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n        this.maxLookahead = utils_1.has(config, \"maxLookahead\") ?\n            config.maxLookahead :\n            DEFAULT_PARSER_CONFIG.maxLookahead;\n        this.ignoredIssues = utils_1.has(config, \"ignoredIssues\") ?\n            config.ignoredIssues :\n            DEFAULT_PARSER_CONFIG.ignoredIssues;\n        this.className = lang_extensions_1.classNameFromInstance(this);\n        this.firstAfterRepMap = cache.getFirstAfterRepForClass(this.className);\n        this.classLAFuncs = cache.getLookaheadFuncsForClass(this.className);\n        if (!cache.CLASS_TO_DEFINITION_ERRORS.containsKey(this.className)) {\n            this.definitionErrors = [];\n            cache.CLASS_TO_DEFINITION_ERRORS.put(this.className, this.definitionErrors);\n        }\n        else {\n            this.definitionErrors = cache.CLASS_TO_DEFINITION_ERRORS.get(this.className);\n        }\n        if (utils_1.isArray(tokensMapOrArr)) {\n            this.tokensMap = utils_1.reduce(tokensMapOrArr, function (acc, tokenClazz) {\n                acc[tokens_public_1.tokenName(tokenClazz)] = tokenClazz;\n                return acc;\n            }, {});\n        }\n        else if (utils_1.isObject(tokensMapOrArr)) {\n            this.tokensMap = utils_1.cloneObj(tokensMapOrArr);\n        }\n        else {\n            throw new Error(\"'tokensMapOrArr' argument must be An Array of Token constructors or a Dictionary of Tokens.\");\n        }\n        var allTokens = utils_1.values(this.tokensMap);\n        var areAllStructuredTokens = utils_1.every(allTokens, function (currTokType) {\n            return tokens_1.isSimpleTokenType(currTokType);\n        });\n        if (areAllStructuredTokens) {\n            this.tokenMatcher = tokens_1.tokenStructuredMatcher;\n            this.tokenClassIdentityFunc = tokens_1.tokenStructuredIdentity;\n            // same IdentityFunc used in structured Mode\n            this.tokenInstanceIdentityFunc = tokens_1.tokenStructuredIdentity;\n        }\n        else {\n            this.tokenMatcher = tokens_1.tokenInstanceofMatcher;\n            this.tokenClassIdentityFunc = tokens_1.tokenClassIdentity;\n            this.tokenInstanceIdentityFunc = tokens_1.tokenInstanceIdentity;\n        }\n        // always add EOF to the tokenNames -> constructors map. it is useful to assure all the input has been\n        // parsed with a clear error message (\"expecting EOF but found ...\")\n        /* tslint:disable */\n        this.tokensMap[\"EOF\"] = tokens_public_1.EOF;\n        /* tslint:enable */\n        // Because ES2015+ syntax should be supported for creating Token classes\n        // We cannot assume that the Token classes were created using the \"extendToken\" utilities\n        // Therefore we must augment the Token classes both on Lexer initialization and on Parser initialization\n        tokens_1.augmentTokenClasses(utils_1.values(this.tokensMap));\n    }\n    Parser.performSelfAnalysis = function (parserInstance) {\n        var definitionErrors = [];\n        var defErrorsMsgs;\n        var className = lang_extensions_1.classNameFromInstance(parserInstance);\n        if (className === \"\") {\n            // just a simple \"throw Error\" without any fancy \"definition error\" because the logic below relies on a unique parser name to\n            // save/access those definition errors...\n            throw Error(\"A Parser's constructor may not be an anonymous Function, it must be a named function\\n\" +\n                \"The constructor's name is used at runtime for performance (caching) purposes.\");\n        }\n        // this information should only be computed once\n        if (!cache.CLASS_TO_SELF_ANALYSIS_DONE.containsKey(className)) {\n            cache.CLASS_TO_SELF_ANALYSIS_DONE.put(className, true);\n            var orgProductions_1 = parserInstance._productions;\n            var clonedProductions_1 = new lang_extensions_1.HashTable();\n            // clone the grammar productions to support grammar inheritance. requirements:\n            // 1. We want to avoid rebuilding the grammar every time so a cache for the productions is used.\n            // 2. We need to collect the production from multiple grammars in an inheritance scenario during constructor invocation\n            //    so the myGast variable is used.\n            // 3. If a Production has been overridden references to it in the GAST must also be updated.\n            utils_1.forEach(orgProductions_1.keys(), function (key) {\n                var value = orgProductions_1.get(key);\n                clonedProductions_1.put(key, gast_1.cloneProduction(value));\n            });\n            cache.getProductionsForClass(className).putAll(clonedProductions_1);\n            // assumes this cache has been initialized (in the relevant parser's constructor)\n            // TODO: consider making the self analysis a member method to resolve this.\n            // that way it won't be callable before the constructor has been invoked...\n            definitionErrors = cache.CLASS_TO_DEFINITION_ERRORS.get(className);\n            var resolverErrors = resolver_1.resolveGrammar(clonedProductions_1);\n            definitionErrors.push.apply(definitionErrors, resolverErrors); // mutability for the win?\n            // only perform additional grammar validations IFF no resolving errors have occurred.\n            // as unresolved grammar may lead to unhandled runtime exceptions in the follow up validations.\n            if (utils_1.isEmpty(resolverErrors)) {\n                var validationErrors = checks_1.validateGrammar(clonedProductions_1.values(), parserInstance.maxLookahead, parserInstance.ignoredIssues);\n                definitionErrors.push.apply(definitionErrors, validationErrors); // mutability for the win?\n            }\n            if (!utils_1.isEmpty(definitionErrors) && !Parser.DEFER_DEFINITION_ERRORS_HANDLING) {\n                defErrorsMsgs = utils_1.map(definitionErrors, function (defError) { return defError.message; });\n                throw new Error(\"Parser Definition Errors detected\\n: \" + defErrorsMsgs.join(\"\\n-------------------------------\\n\"));\n            }\n            if (utils_1.isEmpty(definitionErrors)) {\n                var allFollows = follow_1.computeAllProdsFollows(clonedProductions_1.values());\n                cache.setResyncFollowsForClass(className, allFollows);\n            }\n        }\n        // reThrow the validation errors each time an erroneous parser is instantiated\n        if (!utils_1.isEmpty(cache.CLASS_TO_DEFINITION_ERRORS.get(className)) && !Parser.DEFER_DEFINITION_ERRORS_HANDLING) {\n            defErrorsMsgs = utils_1.map(cache.CLASS_TO_DEFINITION_ERRORS.get(className), function (defError) { return defError.message; });\n            throw new Error(\"Parser Definition Errors detected\\n: \" + defErrorsMsgs.join(\"\\n-------------------------------\\n\"));\n        }\n    };\n    Object.defineProperty(Parser.prototype, \"errors\", {\n        get: function () {\n            return utils_1.cloneArr(this._errors);\n        },\n        set: function (newErrors) {\n            this._errors = newErrors;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Parser.prototype, \"input\", {\n        get: function () {\n            return utils_1.cloneArr(this._input);\n        },\n        set: function (newInput) {\n            this.reset();\n            this._input = newInput;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    /**\n     * Resets the parser state, should be overridden for custom parsers which \"carry\" additional state.\n     * When overriding, remember to also invoke the super implementation!\n     */\n    Parser.prototype.reset = function () {\n        this.resetLexerState();\n        this.isBackTrackingStack = [];\n        this.errors = [];\n        this._input = [];\n        this.RULE_STACK = [];\n        this.RULE_OCCURRENCE_STACK = [];\n    };\n    Parser.prototype.isAtEndOfInput = function () {\n        return this.tokenMatcher(this.LA(1), tokens_public_1.EOF);\n    };\n    Parser.prototype.getGAstProductions = function () {\n        return cache.getProductionsForClass(this.className);\n    };\n    // This is more than a convenience method.\n    // It is mostly used to draw the diagrams and having this method present on the parser instance\n    // can avoid certain situations in which the serialization logic would fail due to multiple versions of chevrotain\n    // bundled (due to multiple prototype chains and \"instanceof\" usage).\n    Parser.prototype.getSerializedGastProductions = function () {\n        return serializeGrammar(cache.getProductionsForClass(this.className).values());\n    };\n    /**\n     * @param startRuleName {string}\n     * @param precedingInput {ISimpleTokenOrIToken[]} - The token vector up to (not including) the content assist point\n     * @returns {ISyntacticContentAssistPath[]}\n     */\n    Parser.prototype.computeContentAssist = function (startRuleName, precedingInput) {\n        var startRuleGast = cache.getProductionsForClass(this.className).get(startRuleName);\n        if (utils_1.isUndefined(startRuleGast)) {\n            throw Error(\"Rule ->\" + startRuleName + \"<- does not exist in this grammar.\");\n        }\n        return interpreter_1.nextPossibleTokensAfter([startRuleGast], precedingInput, this.tokenMatcher, this.maxLookahead);\n    };\n    Parser.prototype.isBackTracking = function () {\n        return !(utils_1.isEmpty(this.isBackTrackingStack));\n    };\n    Parser.prototype.getCurrRuleFullName = function () {\n        var shortName = utils_1.last(this.RULE_STACK);\n        return this.shortRuleNameToFull.get(shortName);\n    };\n    Parser.prototype.shortRuleNameToFullName = function (shortName) {\n        return this.shortRuleNameToFull.get(shortName);\n    };\n    Parser.prototype.getHumanReadableRuleStack = function () {\n        var _this = this;\n        return utils_1.map(this.RULE_STACK, function (currShortName) { return _this.shortRuleNameToFullName(currShortName); });\n    };\n    Parser.prototype.SAVE_ERROR = function (error) {\n        if (exceptions_public_1.exceptions.isRecognitionException(error)) {\n            error.context = {\n                ruleStack: this.getHumanReadableRuleStack(),\n                ruleOccurrenceStack: utils_1.cloneArr(this.RULE_OCCURRENCE_STACK)\n            };\n            this._errors.push(error);\n            return error;\n        }\n        else {\n            throw Error(\"Trying to save an Error which is not a RecognitionException\");\n        }\n    };\n    /**\n     * @param grammarRule - The rule to try and parse in backtracking mode.\n     * @param isValid - A predicate that given the result of the parse attempt will \"decide\" if the parse was successfully or not.\n     *\n     * @return {Function():boolean} a lookahead function that will try to parse the given grammarRule and will return true if succeed.\n     */\n    Parser.prototype.BACKTRACK = function (grammarRule, isValid) {\n        return function () {\n            // save org state\n            this.isBackTrackingStack.push(1);\n            var orgState = this.saveRecogState();\n            try {\n                var ruleResult = grammarRule.call(this);\n                return isValid(ruleResult);\n            }\n            catch (e) {\n                if (exceptions_public_1.exceptions.isRecognitionException(e)) {\n                    return false;\n                }\n                else {\n                    throw e;\n                }\n            }\n            finally {\n                this.reloadRecogState(orgState);\n                this.isBackTrackingStack.pop();\n            }\n        };\n    };\n    // skips a token and returns the next token\n    Parser.prototype.SKIP_TOKEN = function () {\n        // example: assume 45 tokens in the input, if input index is 44 it means that NEXT_TOKEN will return\n        // input[45] which is the 46th item and no longer exists,\n        // so in this case the largest valid input index is 43 (input.length - 2 )\n        if (this.inputIdx <= this._input.length - 2) {\n            this.consumeToken();\n            return this.LA(1);\n        }\n        else {\n            return END_OF_FILE;\n        }\n    };\n    // Parsing DSL\n    /**\n     * Convenience method equivalent to CONSUME1.\n     * @see CONSUME1\n     */\n    Parser.prototype.CONSUME = function (tokClass) {\n        return this.CONSUME1(tokClass);\n    };\n    /**\n     *\n     * A Parsing DSL method use to consume a single terminal Token.\n     * a Token will be consumed, IFF the next token in the token vector is an instanceof tokClass.\n     * otherwise the parser will attempt to perform error recovery.\n     *\n     * The index in the method name indicates the unique occurrence of a terminal consumption\n     * inside a the top level rule. What this means is that if a terminal appears\n     * more than once in a single rule, each appearance must have a difference index.\n     *\n     * for example:\n     *\n     * function parseQualifiedName() {\n     *    this.CONSUME1(Identifier);\n     *    this.MANY(()=> {\n     *       this.CONSUME1(Dot);\n     *       this.CONSUME2(Identifier); // <-- here we use CONSUME2 because the terminal\n     *    });                           //     'Identifier' has already appeared previously in the\n     *                                  //     the rule 'parseQualifiedName'\n     * }\n     *\n     * @param {Function} tokClass - A constructor function specifying the type of token to be consumed.\n     *\n     * @returns {Token} - The consumed token.\n     */\n    // TODO: what is the returned type? ISimpleTokenOrIToken or IToken? or || ?\n    Parser.prototype.CONSUME1 = function (tokClass) {\n        return this.consumeInternal(tokClass, 1);\n    };\n    /**\n     * @see CONSUME1\n     */\n    Parser.prototype.CONSUME2 = function (tokClass) {\n        return this.consumeInternal(tokClass, 2);\n    };\n    /**\n     * @see CONSUME1\n     */\n    Parser.prototype.CONSUME3 = function (tokClass) {\n        return this.consumeInternal(tokClass, 3);\n    };\n    /**\n     * @see CONSUME1\n     */\n    Parser.prototype.CONSUME4 = function (tokClass) {\n        return this.consumeInternal(tokClass, 4);\n    };\n    /**\n     * @see CONSUME1\n     */\n    Parser.prototype.CONSUME5 = function (tokClass) {\n        return this.consumeInternal(tokClass, 5);\n    };\n    /**\n     * Convenience method equivalent to SUBRULE1\n     * @see SUBRULE1\n     */\n    Parser.prototype.SUBRULE = function (ruleToCall, args) {\n        if (args === void 0) { args = []; }\n        return this.SUBRULE1(ruleToCall, args);\n    };\n    /**\n     * The Parsing DSL Method is used by one rule to call another.\n     *\n     * This may seem redundant as it does not actually do much.\n     * However using it is mandatory for all sub rule invocations.\n     * calling another rule without wrapping in SUBRULE(...)\n     * will cause errors/mistakes in the Recognizer's self analysis,\n     * which will lead to errors in error recovery/automatic lookahead calculation\n     * and any other functionality relying on the Recognizer's self analysis\n     * output.\n     *\n     * As in CONSUME the index in the method name indicates the occurrence\n     * of the sub rule invocation in its rule.\n     *\n     * @param {Function} ruleToCall - The rule to invoke.\n     * @param {*[]} args - The arguments to pass to the invoked subrule.\n     * @returns {*} - The result of invoking ruleToCall.\n     */\n    Parser.prototype.SUBRULE1 = function (ruleToCall, args) {\n        if (args === void 0) { args = []; }\n        return ruleToCall.call(this, 1, args);\n    };\n    /**\n     * @see SUBRULE1\n     */\n    Parser.prototype.SUBRULE2 = function (ruleToCall, args) {\n        if (args === void 0) { args = []; }\n        return ruleToCall.call(this, 2, args);\n    };\n    /**\n     * @see SUBRULE1\n     */\n    Parser.prototype.SUBRULE3 = function (ruleToCall, args) {\n        if (args === void 0) { args = []; }\n        return ruleToCall.call(this, 3, args);\n    };\n    /**\n     * @see SUBRULE1\n     */\n    Parser.prototype.SUBRULE4 = function (ruleToCall, args) {\n        if (args === void 0) { args = []; }\n        return ruleToCall.call(this, 4, args);\n    };\n    /**\n     * @see SUBRULE1\n     */\n    Parser.prototype.SUBRULE5 = function (ruleToCall, args) {\n        if (args === void 0) { args = []; }\n        return ruleToCall.call(this, 5, args);\n    };\n    /**\n     * Convenience method equivalent to OPTION1.\n     * @see OPTION1\n     */\n    Parser.prototype.OPTION = function (predicateOrAction, action) {\n        return this.OPTION1.call(this, predicateOrAction, action);\n    };\n    /**\n     * Parsing DSL Method that Indicates an Optional production\n     * in EBNF notation: [...].\n     *\n     * Note that the 'action' param is optional. so both of the following forms are valid:\n     *\n     * - short: this.OPTION(()=>{ this.CONSUME(Digit});\n     * - long: this.OPTION(predicateFunc, ()=>{ this.CONSUME(Digit});\n     *\n     * The 'predicateFunc' in the long form can be used to add constraints (none grammar related)\n     * to optionally invoking the grammar action.\n     *\n     * As in CONSUME the index in the method name indicates the occurrence\n     * of the optional production in it's top rule.\n     *\n     * @param {Function} predicateOrAction - The predicate / gate function that implements the constraint on the grammar\n     *                                       or the grammar action to optionally invoke once.\n     * @param {Function} [action] - The action to optionally invoke.\n     *\n     * @returns {OUT}\n     */\n    Parser.prototype.OPTION1 = function (predicateOrAction, action) {\n        return this.optionInternal(predicateOrAction, action, 1);\n    };\n    /**\n     * @see OPTION1\n     */\n    Parser.prototype.OPTION2 = function (predicateOrAction, action) {\n        return this.optionInternal(predicateOrAction, action, 2);\n    };\n    /**\n     * @see OPTION1\n     */\n    Parser.prototype.OPTION3 = function (predicateOrAction, action) {\n        return this.optionInternal(predicateOrAction, action, 3);\n    };\n    /**\n     * @see OPTION1\n     */\n    Parser.prototype.OPTION4 = function (predicateOrAction, action) {\n        return this.optionInternal(predicateOrAction, action, 4);\n    };\n    /**\n     * @see OPTION1\n     */\n    Parser.prototype.OPTION5 = function (predicateOrAction, action) {\n        return this.optionInternal(predicateOrAction, action, 5);\n    };\n    /**\n     * Convenience method equivalent to OR1.\n     * @see OR1\n     */\n    Parser.prototype.OR = function (alts, errMsgTypes) {\n        return this.OR1(alts, errMsgTypes);\n    };\n    /**\n     * Parsing DSL method that indicates a choice between a set of alternatives must be made.\n     * This is equivalent to EBNF alternation (A | B | C | D ...)\n     *\n     * There are two forms:\n     *\n     * - short: this.OR([\n     *           {ALT:()=>{this.CONSUME(One)}},\n     *           {ALT:()=>{this.CONSUME(Two)}},\n     *           {ALT:()=>{this.CONSUME(Three)}},\n     *        ], \"a number\")\n     *\n     * - long: this.OR([\n     *           {GATE: predicateFunc1, ALT:()=>{this.CONSUME(One)}},\n     *           {GATE: predicateFuncX, ALT:()=>{this.CONSUME(Two)}},\n     *           {GATE: predicateFuncX, ALT:()=>{this.CONSUME(Three)}},\n     *        ], \"a number\")\n     *\n     * They can also be mixed:\n     * mixed: this.OR([\n     *           {GATE: predicateFunc1, ALT:()=>{this.CONSUME(One)}},\n     *           {ALT:()=>{this.CONSUME(Two)}},\n     *           {ALT:()=>{this.CONSUME(Three)}}\n     *        ], \"a number\")\n     *\n     * The 'predicateFuncX' in the long form can be used to add constraints (none grammar related) to choosing the alternative.\n     *\n     * As in CONSUME the index in the method name indicates the occurrence\n     * of the alternation production in it's top rule.\n     *\n     * @param {{ALT:Function}[] | {GATE:Function, ALT:Function}[]} alts - An array of alternatives.\n     *\n     * @param {string} [errMsgTypes] - A description for the alternatives used in error messages\n     *                                 If none is provided, the error message will include the names of the expected\n     *                                 Tokens sequences which may start each alternative.\n     *\n     * @returns {*} - The result of invoking the chosen alternative.\n     */\n    Parser.prototype.OR1 = function (alts, errMsgTypes) {\n        return this.orInternal(alts, errMsgTypes, 1);\n    };\n    /**\n     * @see OR1\n     */\n    Parser.prototype.OR2 = function (alts, errMsgTypes) {\n        return this.orInternal(alts, errMsgTypes, 2);\n    };\n    /**\n     * @see OR1\n     */\n    Parser.prototype.OR3 = function (alts, errMsgTypes) {\n        return this.orInternal(alts, errMsgTypes, 3);\n    };\n    /**\n     * @see OR1\n     */\n    Parser.prototype.OR4 = function (alts, errMsgTypes) {\n        return this.orInternal(alts, errMsgTypes, 4);\n    };\n    /**\n     * @see OR1\n     */\n    Parser.prototype.OR5 = function (alts, errMsgTypes) {\n        return this.orInternal(alts, errMsgTypes, 5);\n    };\n    /**\n     * Convenience method equivalent to MANY1.\n     * @see MANY1\n     */\n    Parser.prototype.MANY = function (predicateOrAction, action) {\n        return this.MANY1.call(this, predicateOrAction, action);\n    };\n    /**\n     * Parsing DSL method, that indicates a repetition of zero or more.\n     * This is equivalent to EBNF repetition {...}.\n     *\n     * Note that the 'action' param is optional. so both of the following forms are valid:\n     *\n     * short: this.MANY(()=>{\n     *                       this.CONSUME(Comma};\n     *                       this.CONSUME(Digit});\n     *\n     * long: this.MANY(predicateFunc, () => {\n     *                       this.CONSUME(Comma};\n     *                       this.CONSUME(Digit});\n     *\n     * The 'predicateFunc' in the long form can be used to add constraints (none grammar related) taking another iteration.\n     *\n     * As in CONSUME the index in the method name indicates the occurrence\n     * of the repetition production in it's top rule.\n     *\n     * @param {Function} predicateOrAction - The predicate / gate function that implements the constraint on the grammar\n     *                                   or the grammar action to optionally invoke multiple times.\n     * @param {Function} [action] - The action to optionally invoke multiple times.\n     *\n     * @returns {OUT[]}\n     */\n    Parser.prototype.MANY1 = function (predicateOrAction, action) {\n        return this.manyInternal(1, predicateOrAction, action, []);\n    };\n    /**\n     * @see MANY1\n     */\n    Parser.prototype.MANY2 = function (predicateOrAction, action) {\n        return this.manyInternal(2, predicateOrAction, action, []);\n    };\n    /**\n     * @see MANY1\n     */\n    Parser.prototype.MANY3 = function (predicateOrAction, action) {\n        return this.manyInternal(3, predicateOrAction, action, []);\n    };\n    /**\n     * @see MANY1\n     */\n    Parser.prototype.MANY4 = function (predicateOrAction, action) {\n        return this.manyInternal(4, predicateOrAction, action, []);\n    };\n    /**\n     * @see MANY1\n     */\n    Parser.prototype.MANY5 = function (predicateOrAction, action) {\n        return this.manyInternal(5, predicateOrAction, action, []);\n    };\n    /**\n     * Convenience method equivalent to MANY_SEP1.\n     * @see MANY_SEP1\n     */\n    Parser.prototype.MANY_SEP = function (separator, action) {\n        return this.MANY_SEP1.call(this, separator, action);\n    };\n    /**\n     * Parsing DSL method, that indicates a repetition of zero or more with a separator\n     * Token between the repetitions.\n     *\n     * Example:\n     *\n     * this.MANY_SEP(Comma, () => {\n     *                     this.CONSUME(Number};\n     *                     ...\n     *                   );\n     *\n     * Note that for the purposes of deciding on whether or not another iteration exists\n     * Only a single Token is examined (The separator). Therefore if the grammar being implemented is\n     * so \"crazy\" to require multiple tokens to identify an item separator please use the basic DSL methods\n     * to implement it.\n     *\n     * As in CONSUME the index in the method name indicates the occurrence\n     * of the repetition production in it's top rule.\n     *\n     * @param {TokenConstructor} separator - The Token class which will be used as a separator between repetitions.\n     * @param {Function} [action] - The action to optionally invoke.\n     *\n     * @return {ISeparatedIterationResult<OUT>}\n     */\n    Parser.prototype.MANY_SEP1 = function (separator, action) {\n        return this.manySepFirstInternal(1, separator, action, { values: [], separators: [] });\n    };\n    /**\n     * @see MANY_SEP1\n     */\n    Parser.prototype.MANY_SEP2 = function (separator, action) {\n        return this.manySepFirstInternal(2, separator, action, { values: [], separators: [] });\n    };\n    /**\n     * @see MANY_SEP1\n     */\n    Parser.prototype.MANY_SEP3 = function (separator, action) {\n        return this.manySepFirstInternal(3, separator, action, { values: [], separators: [] });\n    };\n    /**\n     * @see MANY_SEP1\n     */\n    Parser.prototype.MANY_SEP4 = function (separator, action) {\n        return this.manySepFirstInternal(4, separator, action, { values: [], separators: [] });\n    };\n    /**\n     * @see MANY_SEP1\n     */\n    Parser.prototype.MANY_SEP5 = function (separator, action) {\n        return this.manySepFirstInternal(5, separator, action, { values: [], separators: [] });\n    };\n    /**\n     * Convenience method equivalent to AT_LEAST_ONE1.\n     * @see AT_LEAST_ONE1\n     */\n    Parser.prototype.AT_LEAST_ONE = function (predicateOrAction, action, errMsg) {\n        return this.AT_LEAST_ONE1.call(this, predicateOrAction, action, errMsg);\n    };\n    /**\n     * Convenience method, same as MANY but the repetition is of one or more.\n     * failing to match at least one repetition will result in a parsing error and\n     * cause the parser to attempt error recovery.\n     *\n     * @see MANY1\n     *\n     * @param {Function} predicateOrAction  - The predicate / gate function that implements the constraint on the grammar\n     *                                        or the grammar action to invoke at least once.\n     * @param {Function} [action] - The action to optionally invoke.\n     * @param {string} [errMsg] - Short title/classification to what is being matched.\n     *\n     * @return {OUT[]}\n     */\n    Parser.prototype.AT_LEAST_ONE1 = function (predicateOrAction, action, errMsg) {\n        return this.atLeastOneInternal(1, predicateOrAction, action, errMsg, []);\n    };\n    /**\n     * @see AT_LEAST_ONE1\n     */\n    Parser.prototype.AT_LEAST_ONE2 = function (predicateOrAction, action, errMsg) {\n        return this.atLeastOneInternal(2, predicateOrAction, action, errMsg, []);\n    };\n    /**\n     * @see AT_LEAST_ONE1\n     */\n    Parser.prototype.AT_LEAST_ONE3 = function (predicateOrAction, action, errMsg) {\n        return this.atLeastOneInternal(3, predicateOrAction, action, errMsg, []);\n    };\n    /**\n     * @see AT_LEAST_ONE1\n     */\n    Parser.prototype.AT_LEAST_ONE4 = function (predicateOrAction, action, errMsg) {\n        return this.atLeastOneInternal(4, predicateOrAction, action, errMsg, []);\n    };\n    /**\n     * @see AT_LEAST_ONE1\n     */\n    Parser.prototype.AT_LEAST_ONE5 = function (predicateOrAction, action, errMsg) {\n        return this.atLeastOneInternal(5, predicateOrAction, action, errMsg, []);\n    };\n    /**\n     * Convenience method equivalent to AT_LEAST_ONE_SEP1.\n     * @see AT_LEAST_ONE1\n     */\n    Parser.prototype.AT_LEAST_ONE_SEP = function (separator, action, errMsg) {\n        return this.AT_LEAST_ONE_SEP1.call(this, separator, action, errMsg);\n    };\n    /**\n     *\n     * Convenience method, same as MANY_SEP but the repetition is of one or more.\n     * failing to match at least one repetition will result in a parsing error and\n     * cause the parser to attempt error recovery.\n     *\n     * @see MANY_SEP1\n     *\n     * @param {TokenConstructor} separator - The Token class which will be used as a separator between repetitions.\n     * @param {Function} [action] - The action to optionally invoke.\n     * @param {string} [errMsg] - Short title/classification to what is being matched.\n     *\n     * @return {ISeparatedIterationResult<OUT>}\n     */\n    Parser.prototype.AT_LEAST_ONE_SEP1 = function (separator, action, errMsg) {\n        return this.atLeastOneSepFirstInternal(1, separator, action, errMsg, { values: [], separators: [] });\n    };\n    /**\n     * @see AT_LEAST_ONE_SEP1\n     */\n    Parser.prototype.AT_LEAST_ONE_SEP2 = function (separator, action, errMsg) {\n        return this.atLeastOneSepFirstInternal(2, separator, action, errMsg, { values: [], separators: [] });\n    };\n    /**\n     * @see AT_LEAST_ONE_SEP1\n     */\n    Parser.prototype.AT_LEAST_ONE_SEP3 = function (separator, action, errMsg) {\n        return this.atLeastOneSepFirstInternal(3, separator, action, errMsg, { values: [], separators: [] });\n    };\n    /**\n     * @see AT_LEAST_ONE_SEP1\n     */\n    Parser.prototype.AT_LEAST_ONE_SEP4 = function (separator, action, errMsg) {\n        return this.atLeastOneSepFirstInternal(4, separator, action, errMsg, { values: [], separators: [] });\n    };\n    /**\n     * @see AT_LEAST_ONE_SEP1\n     */\n    Parser.prototype.AT_LEAST_ONE_SEP5 = function (separator, action, errMsg) {\n        return this.atLeastOneSepFirstInternal(5, separator, action, errMsg, { values: [], separators: [] });\n    };\n    /**\n     *\n     * @param {string} name - The name of the rule.\n     * @param {Function} implementation - The implementation of the rule.\n     * @param {IRuleConfig} [config] - The rule's optional configuration.\n     *\n     * @returns {Function} - The parsing rule which is the production implementation wrapped with the parsing logic that handles\n     *                     Parser state / error recovery&reporting/ ...\n     */\n    Parser.prototype.RULE = function (name, implementation, config) {\n        if (config === void 0) { config = DEFAULT_RULE_CONFIG; }\n        var ruleErrors = checks_1.validateRuleName(name, this.className);\n        ruleErrors = ruleErrors.concat(checks_1.validateRuleDoesNotAlreadyExist(name, this.definedRulesNames, this.className));\n        this.definedRulesNames.push(name);\n        this.definitionErrors.push.apply(this.definitionErrors, ruleErrors); // mutability for the win\n        // only build the gast representation once.\n        if (!(this._productions.containsKey(name))) {\n            var gastProduction = gast_builder_1.buildTopProduction(implementation.toString(), name, this.tokensMap);\n            this._productions.put(name, gastProduction);\n        }\n        else {\n            var parserClassProductions = cache.getProductionsForClass(this.className);\n            var cachedProduction = parserClassProductions.get(name);\n            // in case of duplicate rules the cache will not be filled at this point.\n            if (!utils_1.isUndefined(cachedProduction)) {\n                // filling up the _productions is always needed to inheriting grammars can access it (as an instance member)\n                // otherwise they will be unaware of productions defined in super grammars.\n                this._productions.put(name, cachedProduction);\n            }\n        }\n        var ruleImplementation = this.defineRule(name, implementation, config);\n        this[name] = ruleImplementation;\n        return ruleImplementation;\n    };\n    /**\n     * @See RULE\n     * Same as RULE, but should only be used in \"extending\" grammars to override rules/productions\n     * from the super grammar.\n     */\n    Parser.prototype.OVERRIDE_RULE = function (name, impl, config) {\n        if (config === void 0) { config = DEFAULT_RULE_CONFIG; }\n        var ruleErrors = checks_1.validateRuleName(name, this.className);\n        ruleErrors = ruleErrors.concat(checks_1.validateRuleIsOverridden(name, this.definedRulesNames, this.className));\n        this.definitionErrors.push.apply(this.definitionErrors, ruleErrors); // mutability for the win\n        var alreadyOverridden = cache.getProductionOverriddenForClass(this.className);\n        // only build the GAST of an overridden rule once.\n        if (!alreadyOverridden.containsKey(name)) {\n            alreadyOverridden.put(name, true);\n            var gastProduction = gast_builder_1.buildTopProduction(impl.toString(), name, this.tokensMap);\n            this._productions.put(name, gastProduction);\n        }\n        else {\n            var parserClassProductions = cache.getProductionsForClass(this.className);\n            // filling up the _productions is always needed to inheriting grammars can access it (as an instance member)\n            // otherwise they will be unaware of productions defined in super grammars.\n            this._productions.put(name, parserClassProductions.get(name));\n        }\n        return this.defineRule(name, impl, config);\n    };\n    Parser.prototype.ruleInvocationStateUpdate = function (shortName, idxInCallingRule) {\n        this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n        this.RULE_STACK.push(shortName);\n    };\n    Parser.prototype.ruleFinallyStateUpdate = function () {\n        this.RULE_STACK.pop();\n        this.RULE_OCCURRENCE_STACK.pop();\n        if ((this.RULE_STACK.length === 0) && !this.isAtEndOfInput()) {\n            var firstRedundantTok = this.LA(1);\n            this.SAVE_ERROR(new exceptions_public_1.exceptions.NotAllInputParsedException(\"Redundant input, expecting EOF but found: \" + tokens_public_1.getImage(firstRedundantTok), firstRedundantTok));\n        }\n    };\n    /**\n     * Returns an \"imaginary\" Token to insert when Single Token Insertion is done\n     * Override this if you require special behavior in your grammar.\n     * For example if an IntegerToken is required provide one with the image '0' so it would be valid syntactically.\n     */\n    Parser.prototype.getTokenToInsert = function (tokClass) {\n        var tokToInsert;\n        if (tokens_public_1.LazyToken.prototype.isPrototypeOf(tokClass.prototype)) {\n            tokToInsert = new tokClass(NaN, NaN, {\n                orgText: \"\",\n                lineToOffset: []\n            });\n        }\n        else if (tokens_public_1.SimpleLazyToken.prototype.isPrototypeOf(tokClass.prototype)) {\n            tokToInsert = {\n                startOffset: NaN,\n                endOffset: NaN,\n                cacheData: {\n                    orgText: \"\",\n                    lineToOffset: []\n                }\n            };\n        }/* istanbul ignore else */ \n        else if (tokens_public_1.Token.prototype.isPrototypeOf(tokClass.prototype)) {\n            tokToInsert = new tokClass(\"\", NaN, NaN, NaN, NaN, NaN);\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n        tokToInsert.isInsertedInRecovery = true;\n        return tokToInsert;\n    };\n    /**\n     * By default all tokens type may be inserted. This behavior may be overridden in inheriting Recognizers\n     * for example: One may decide that only punctuation tokens may be inserted automatically as they have no additional\n     * semantic value. (A mandatory semicolon has no additional semantic meaning, but an Integer may have additional meaning\n     * depending on its int value and context (Inserting an integer 0 in cardinality: \"[1..]\" will cause semantic issues\n     * as the max of the cardinality will be greater than the min value (and this is a false error!).\n     */\n    Parser.prototype.canTokenTypeBeInsertedInRecovery = function (tokClass) {\n        return true;\n    };\n    /**\n     * @param {Token} actualToken - The actual unexpected (mismatched) Token instance encountered.\n     * @param {Function} expectedTokType - The Class of the expected Token.\n     * @returns {string} - The error message saved as part of a MismatchedTokenException.\n     */\n    Parser.prototype.getMisMatchTokenErrorMessage = function (expectedTokType, actualToken) {\n        var hasLabel = tokens_public_1.hasTokenLabel(expectedTokType);\n        var expectedMsg = hasLabel ?\n            \"--> \" + tokens_public_1.tokenLabel(expectedTokType) + \" <--\" :\n            \"token of type --> \" + tokens_public_1.tokenName(expectedTokType) + \" <--\";\n        var msg = \"Expecting \" + expectedMsg + \" but found --> '\" + tokens_public_1.getImage(actualToken) + \"' <--\";\n        return msg;\n    };\n    Parser.prototype.getCurrentGrammarPath = function (tokClass, tokIdxInRule) {\n        var pathRuleStack = this.getHumanReadableRuleStack();\n        var pathOccurrenceStack = utils_1.cloneArr(this.RULE_OCCURRENCE_STACK);\n        var grammarPath = {\n            ruleStack: pathRuleStack,\n            occurrenceStack: pathOccurrenceStack,\n            lastTok: tokClass,\n            lastTokOccurrence: tokIdxInRule\n        };\n        return grammarPath;\n    };\n    // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n    // TODO: should this be more explicitly part of the public API?\n    Parser.prototype.getNextPossibleTokenTypes = function (grammarPath) {\n        var topRuleName = utils_1.first(grammarPath.ruleStack);\n        var gastProductions = this.getGAstProductions();\n        var topProduction = gastProductions.get(topRuleName);\n        var nextPossibleTokenTypes = new interpreter_1.NextAfterTokenWalker(topProduction, grammarPath).startWalking();\n        return nextPossibleTokenTypes;\n    };\n    /**\n     * @param tokClass - The Type of Token we wish to consume (Reference to its constructor function).\n     * @param idx - Occurrence index of consumed token in the invoking parser rule text\n     *         for example:\n     *         IDENT (DOT IDENT)*\n     *         the first ident will have idx 1 and the second one idx 2\n     *         * note that for the second ident the idx is always 2 even if its invoked 30 times in the same rule\n     *           the idx is about the position in grammar (source code) and has nothing to do with a specific invocation\n     *           details.\n     *\n     * @returns {Token} - The consumed Token.\n     */\n    Parser.prototype.consumeInternal = function (tokClass, idx) {\n        // TODO: this is an hack to avoid try catch block in V8, should be removed once V8 supports try/catch optimizations.\n        // as the IF/ELSE itself has some overhead.\n        if (!this.recoveryEnabled) {\n            return this.consumeInternalOptimized(tokClass);\n        }\n        else {\n            return this.consumeInternalWithTryCatch(tokClass, idx);\n        }\n    };\n    Parser.prototype.consumeInternalWithTryCatch = function (tokClass, idx) {\n        try {\n            return this.consumeInternalOptimized(tokClass);\n        }\n        catch (eFromConsumption) {\n            // no recovery allowed during backtracking, otherwise backtracking may recover invalid syntax and accept it\n            // but the original syntax could have been parsed successfully without any backtracking + recovery\n            if (this.recoveryEnabled &&\n                // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n                eFromConsumption.name === \"MismatchedTokenException\" && !this.isBackTracking()) {\n                var follows = this.getFollowsForInRuleRecovery(tokClass, idx);\n                try {\n                    return this.tryInRuleRecovery(tokClass, follows);\n                }\n                catch (eFromInRuleRecovery) {\n                    if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n                        // failed in RuleRecovery.\n                        // throw the original error in order to trigger reSync error recovery\n                        throw eFromConsumption;\n                    }\n                    else {\n                        throw eFromInRuleRecovery;\n                    }\n                }\n            }\n            else {\n                throw eFromConsumption;\n            }\n        }\n    };\n    /**\n     * Convenience method equivalent to LA(1)\n     * It is no longer used directly in chevrotain due to\n     * performance considerations (avoid the need for inlining optimizations).\n     *\n     * But it is maintained for backward compatibility reasons.\n     *\n     * @deprecated\n     */\n    Parser.prototype.NEXT_TOKEN = function () {\n        return this.LA(1);\n    };\n    // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n    // or lexers dependent on parser context.\n    Parser.prototype.LA = function (howMuch) {\n        if (this._input.length <= this.inputIdx + howMuch) {\n            return END_OF_FILE;\n        }\n        else {\n            return this._input[this.inputIdx + howMuch];\n        }\n    };\n    Parser.prototype.consumeToken = function () {\n        this.inputIdx++;\n    };\n    Parser.prototype.saveLexerState = function () {\n        this.savedTokenIdx = this.inputIdx;\n    };\n    Parser.prototype.restoreLexerState = function () {\n        this.inputIdx = this.savedTokenIdx;\n    };\n    Parser.prototype.resetLexerState = function () {\n        this.inputIdx = -1;\n    };\n    Parser.prototype.moveLexerStateToEnd = function () {\n        this.inputIdx = this.input.length - 1;\n    };\n    // other functionality\n    Parser.prototype.saveRecogState = function () {\n        // errors is a getter which will clone the errors array\n        var savedErrors = this.errors;\n        var savedRuleStack = utils_1.cloneArr(this.RULE_STACK);\n        return {\n            errors: savedErrors,\n            lexerState: this.inputIdx,\n            RULE_STACK: savedRuleStack\n        };\n    };\n    Parser.prototype.reloadRecogState = function (newState) {\n        this.errors = newState.errors;\n        this.inputIdx = newState.lexerState;\n        this.RULE_STACK = newState.RULE_STACK;\n    };\n    Parser.prototype.defineRule = function (ruleName, impl, config) {\n        var resyncEnabled = utils_1.has(config, \"resyncEnabled\") ?\n            config.resyncEnabled :\n            DEFAULT_RULE_CONFIG.resyncEnabled;\n        var recoveryValueFunc = utils_1.has(config, \"recoveryValueFunc\") ?\n            config.recoveryValueFunc :\n            DEFAULT_RULE_CONFIG.recoveryValueFunc;\n        // performance optimization: Use small integers as keys for the longer human readable \"full\" rule names.\n        // this greatly improves Map access time (as much as 8% for some performance benchmarks).\n        /* tslint:disable */\n        var shortName = this.ruleShortNameIdx << (BITS_FOR_METHOD_IDX + BITS_FOR_OCCURRENCE_IDX);\n        /* tslint:enable */\n        this.ruleShortNameIdx++;\n        this.shortRuleNameToFull.put(shortName, ruleName);\n        function invokeRuleNoTry(args) {\n            var result = impl.apply(this, args);\n            this.ruleFinallyStateUpdate();\n            return result;\n        }\n        function invokeRuleWithTry(args, isFirstRule) {\n            try {\n                // actual parsing happens here\n                return impl.apply(this, args);\n            }\n            catch (e) {\n                // TODO: this is part of a Performance hack for V8 due to lack of support\n                // of try/catch optimizations. Should be removed once V8 supports that.\n                // This is needed because in case of an error during a nested subRule\n                // there will be no \"finally\" block to perform the \"ruleFinallyStateUpdate\"\n                // So this block properly rewinds the parser's state in the case error recovery is disabled.\n                if (isFirstRule) {\n                    for (var i = this.RULE_STACK.length; i > 1; i--) {\n                        this.ruleFinallyStateUpdate();\n                    }\n                }\n                var isFirstInvokedRule = (this.RULE_STACK.length === 1);\n                // note the reSync is always enabled for the first rule invocation, because we must always be able to\n                // reSync with EOF and just output some INVALID ParseTree\n                // during backtracking reSync recovery is disabled, otherwise we can't be certain the backtracking\n                // path is really the most valid one\n                var reSyncEnabled = resyncEnabled && !this.isBackTracking() && this.recoveryEnabled;\n                if (exceptions_public_1.exceptions.isRecognitionException(e)) {\n                    if (reSyncEnabled) {\n                        var reSyncTokType = this.findReSyncTokenType();\n                        if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n                            e.resyncedTokens = this.reSyncTo(reSyncTokType);\n                            return recoveryValueFunc();\n                        }\n                        else {\n                            // to be handled farther up the call stack\n                            throw e;\n                        }\n                    }\n                    else if (isFirstInvokedRule) {\n                        // otherwise a Redundant input error will be created as well and we cannot guarantee that this is indeed the case\n                        this.moveLexerStateToEnd();\n                        // the parser should never throw one of its own errors outside its flow.\n                        // even if error recovery is disabled\n                        return recoveryValueFunc();\n                    }\n                    else {\n                        // to be handled farther up the call stack\n                        throw e;\n                    }\n                }\n                else {\n                    // some other Error type which we don't know how to handle (for example a built in JavaScript Error)\n                    throw e;\n                }\n            }\n            finally {\n                this.ruleFinallyStateUpdate();\n            }\n        }\n        var wrappedGrammarRule = function (idxInCallingRule, args) {\n            if (idxInCallingRule === void 0) { idxInCallingRule = 1; }\n            this.ruleInvocationStateUpdate(shortName, idxInCallingRule);\n            // TODO: performance hack due to V8 lack of try/catch optimizations.\n            // should be removed once V8 support those.\n            var isFirstRule = this.RULE_STACK.length === 1;\n            if (!this.recoveryEnabled && !isFirstRule) {\n                return invokeRuleNoTry.call(this, args);\n            }\n            else {\n                return invokeRuleWithTry.call(this, args, isFirstRule);\n            }\n        };\n        var ruleNamePropName = \"ruleName\";\n        wrappedGrammarRule[ruleNamePropName] = ruleName;\n        return wrappedGrammarRule;\n    };\n    Parser.prototype.tryInRepetitionRecovery = function (grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n        var _this = this;\n        // TODO: can the resyncTokenType be cached?\n        var reSyncTokType = this.findReSyncTokenType();\n        this.saveLexerState();\n        var resyncedTokens = [];\n        var passedResyncPoint = false;\n        var nextTokenWithoutResync = this.LA(1);\n        var currToken = this.LA(1);\n        var generateErrorMessage = function () {\n            // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n            // the error that would have been thrown\n            var msg = _this.getMisMatchTokenErrorMessage(expectedTokType, nextTokenWithoutResync);\n            var error = new exceptions_public_1.exceptions.MismatchedTokenException(msg, nextTokenWithoutResync);\n            // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n            error.resyncedTokens = utils_1.dropRight(resyncedTokens);\n            _this.SAVE_ERROR(error);\n        };\n        while (!passedResyncPoint) {\n            // re-synced to a point where we can safely exit the repetition/\n            if (this.tokenMatcher(currToken, expectedTokType)) {\n                generateErrorMessage();\n                return; // must return here to avoid reverting the inputIdx\n            }\n            else if (lookAheadFunc.call(this)) {\n                generateErrorMessage();\n                // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n                grammarRule.apply(this, grammarRuleArgs);\n                return; // must return here to avoid reverting the inputIdx\n            }\n            else if (this.tokenMatcher(currToken, reSyncTokType)) {\n                passedResyncPoint = true;\n            }\n            else {\n                currToken = this.SKIP_TOKEN();\n                this.addToResyncTokens(currToken, resyncedTokens);\n            }\n        }\n        // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n        // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n        // \"between rules\" resync recovery later in the flow.\n        this.restoreLexerState();\n    };\n    Parser.prototype.shouldInRepetitionRecoveryBeTried = function (expectTokAfterLastMatch, nextTokIdx) {\n        // arguments to try and perform resync into the next iteration of the many are missing\n        if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n            return false;\n        }\n        // no need to recover, next token is what we expect...\n        if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n            return false;\n        }\n        // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n        // and prefer some backtracking path that includes recovered errors.\n        if (this.isBackTracking()) {\n            return false;\n        }\n        // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n        // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n        //noinspection RedundantIfStatementJS\n        if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n            return false;\n        }\n        return true;\n    };\n    // Error Recovery functionality\n    Parser.prototype.getFollowsForInRuleRecovery = function (tokClass, tokIdxInRule) {\n        var grammarPath = this.getCurrentGrammarPath(tokClass, tokIdxInRule);\n        var follows = this.getNextPossibleTokenTypes(grammarPath);\n        return follows;\n    };\n    Parser.prototype.tryInRuleRecovery = function (expectedTokType, follows) {\n        if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n            var tokToInsert = this.getTokenToInsert(expectedTokType);\n            return tokToInsert;\n        }\n        if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n            var nextTok = this.SKIP_TOKEN();\n            this.consumeToken();\n            return nextTok;\n        }\n        throw new InRuleRecoveryException(\"sad sad panda\");\n    };\n    Parser.prototype.canPerformInRuleRecovery = function (expectedToken, follows) {\n        return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n            this.canRecoverWithSingleTokenDeletion(expectedToken);\n    };\n    Parser.prototype.canRecoverWithSingleTokenInsertion = function (expectedTokType, follows) {\n        var _this = this;\n        if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n            return false;\n        }\n        // must know the possible following tokens to perform single token insertion\n        if (utils_1.isEmpty(follows)) {\n            return false;\n        }\n        var mismatchedTok = this.LA(1);\n        var isMisMatchedTokInFollows = utils_1.find(follows, function (possibleFollowsTokType) {\n            return _this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n        }) !== undefined;\n        return isMisMatchedTokInFollows;\n    };\n    Parser.prototype.canRecoverWithSingleTokenDeletion = function (expectedTokType) {\n        var isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n        return isNextTokenWhatIsExpected;\n    };\n    Parser.prototype.isInCurrentRuleReSyncSet = function (tokenType) {\n        var followKey = this.getCurrFollowKey();\n        var currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n        return utils_1.contains(currentRuleReSyncSet, tokenType);\n    };\n    Parser.prototype.findReSyncTokenType = function () {\n        var allPossibleReSyncTokTypes = this.flattenFollowSet();\n        // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n        var nextToken = this.LA(1);\n        var k = 2;\n        while (true) {\n            var nextTokenType = tokens_public_1.getTokenConstructor(nextToken);\n            if (utils_1.contains(allPossibleReSyncTokTypes, nextTokenType)) {\n                return nextTokenType;\n            }\n            nextToken = this.LA(k);\n            k++;\n        }\n    };\n    Parser.prototype.getCurrFollowKey = function () {\n        // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n        if (this.RULE_STACK.length === 1) {\n            return EOF_FOLLOW_KEY;\n        }\n        var currRuleIdx = this.RULE_STACK.length - 1;\n        var currRuleOccIdx = currRuleIdx;\n        var prevRuleIdx = currRuleIdx - 1;\n        return {\n            ruleName: this.shortRuleNameToFullName(this.RULE_STACK[currRuleIdx]),\n            idxInCallingRule: this.RULE_OCCURRENCE_STACK[currRuleOccIdx],\n            inRule: this.shortRuleNameToFullName(this.RULE_STACK[prevRuleIdx])\n        };\n    };\n    Parser.prototype.buildFullFollowKeyStack = function () {\n        var _this = this;\n        return utils_1.map(this.RULE_STACK, function (ruleName, idx) {\n            if (idx === 0) {\n                return EOF_FOLLOW_KEY;\n            }\n            return {\n                ruleName: _this.shortRuleNameToFullName(ruleName),\n                idxInCallingRule: _this.RULE_OCCURRENCE_STACK[idx],\n                inRule: _this.shortRuleNameToFullName(_this.RULE_STACK[idx - 1])\n            };\n        });\n    };\n    Parser.prototype.flattenFollowSet = function () {\n        var _this = this;\n        var followStack = utils_1.map(this.buildFullFollowKeyStack(), function (currKey) {\n            return _this.getFollowSetFromFollowKey(currKey);\n        });\n        return utils_1.flatten(followStack);\n    };\n    Parser.prototype.getFollowSetFromFollowKey = function (followKey) {\n        if (followKey === EOF_FOLLOW_KEY) {\n            return [tokens_public_1.EOF];\n        }\n        var followName = followKey.ruleName + followKey.idxInCallingRule + constants_1.IN + followKey.inRule;\n        return cache.getResyncFollowsForClass(this.className).get(followName);\n    };\n    // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n    // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n    Parser.prototype.addToResyncTokens = function (token, resyncTokens) {\n        if (!this.tokenMatcher(token, tokens_public_1.EOF)) {\n            resyncTokens.push(token);\n        }\n        return resyncTokens;\n    };\n    Parser.prototype.reSyncTo = function (tokClass) {\n        var resyncedTokens = [];\n        var nextTok = this.LA(1);\n        while ((this.tokenMatcher(nextTok, tokClass)) === false) {\n            nextTok = this.SKIP_TOKEN();\n            this.addToResyncTokens(nextTok, resyncedTokens);\n        }\n        // the last token is not part of the error.\n        return utils_1.dropRight(resyncedTokens);\n    };\n    Parser.prototype.attemptInRepetitionRecovery = function (prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker) {\n        var key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n        var firstAfterRepInfo = this.firstAfterRepMap.get(key);\n        if (firstAfterRepInfo === undefined) {\n            var currRuleName = this.getCurrRuleFullName();\n            var ruleGrammar = this.getGAstProductions().get(currRuleName);\n            var walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n            firstAfterRepInfo = walker.startWalking();\n            this.firstAfterRepMap.put(key, firstAfterRepInfo);\n        }\n        var expectTokAfterLastMatch = firstAfterRepInfo.token;\n        var nextTokIdx = firstAfterRepInfo.occurrence;\n        var isEndOfRule = firstAfterRepInfo.isEndOfRule;\n        // special edge case of a TOP most repetition after which the input should END.\n        // this will force an attempt for inRule recovery in that scenario.\n        if (this.RULE_STACK.length === 1 &&\n            isEndOfRule &&\n            expectTokAfterLastMatch === undefined) {\n            expectTokAfterLastMatch = tokens_public_1.EOF;\n            nextTokIdx = 1;\n        }\n        if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx)) {\n            // TODO: performance optimization: instead of passing the original args here, we modify\n            // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n            // to avoid searching the cache for it once more.\n            this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n        }\n    };\n    // Implementation of parsing DSL\n    Parser.prototype.optionInternal = function (predicateOrAction, action, occurrence) {\n        var lookAheadFunc = this.getLookaheadFuncForOption(occurrence);\n        if (action === undefined) {\n            action = predicateOrAction;\n        } // predicate present\n        else if (!predicateOrAction.call(this)) {\n            return undefined;\n        }\n        if ((lookAheadFunc).call(this)) {\n            return action.call(this);\n        }\n        return undefined;\n    };\n    Parser.prototype.atLeastOneInternal = function (prodOccurrence, predicate, action, userDefinedErrMsg, result) {\n        var _this = this;\n        var lookAheadFunc = this.getLookaheadFuncForAtLeastOne(prodOccurrence);\n        if (!utils_1.isFunction(action)) {\n            userDefinedErrMsg = action;\n            action = predicate;\n        }\n        else {\n            var orgLookAheadFunc_1 = lookAheadFunc;\n            lookAheadFunc = function () {\n                return predicate.call(_this) &&\n                    orgLookAheadFunc_1.call(_this);\n            };\n        }\n        if (lookAheadFunc.call(this)) {\n            result.push(action.call(this));\n            while (lookAheadFunc.call(this)) {\n                result.push(action.call(this));\n            }\n        }\n        else {\n            throw this.raiseEarlyExitException(prodOccurrence, lookahead_1.PROD_TYPE.REPETITION_MANDATORY, userDefinedErrMsg);\n        }\n        // note that while it may seem that this can cause an error because by using a recursive call to\n        // AT_LEAST_ONE we change the grammar to AT_LEAST_TWO, AT_LEAST_THREE ... , the possible recursive call\n        // from the tryInRepetitionRecovery(...) will only happen IFF there really are TWO/THREE/.... items.\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        this.attemptInRepetitionRecovery(this.atLeastOneInternal, [prodOccurrence, lookAheadFunc, action, userDefinedErrMsg, result], lookAheadFunc, AT_LEAST_ONE_IDX, prodOccurrence, interpreter_1.NextTerminalAfterAtLeastOneWalker);\n        return result;\n    };\n    Parser.prototype.atLeastOneSepFirstInternal = function (prodOccurrence, separator, action, userDefinedErrMsg, result) {\n        var _this = this;\n        var firstIterationLookaheadFunc = this.getLookaheadFuncForAtLeastOneSep(prodOccurrence);\n        var values = result.values;\n        var separators = result.separators;\n        // 1st iteration\n        if (firstIterationLookaheadFunc.call(this)) {\n            values.push(action.call(this));\n            var separatorLookAheadFunc = function () { return _this.tokenMatcher(_this.LA(1), separator); };\n            // 2nd..nth iterations\n            while (this.tokenMatcher(this.LA(1), separator)) {\n                // note that this CONSUME will never enter recovery because\n                // the separatorLookAheadFunc checks that the separator really does exist.\n                separators.push(this.CONSUME(separator));\n                values.push(action.call(this));\n            }\n            // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n            this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [prodOccurrence, separator, separatorLookAheadFunc, action, interpreter_1.NextTerminalAfterAtLeastOneSepWalker, result], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, interpreter_1.NextTerminalAfterAtLeastOneSepWalker);\n        }\n        else {\n            throw this.raiseEarlyExitException(prodOccurrence, lookahead_1.PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, userDefinedErrMsg);\n        }\n        return result;\n    };\n    Parser.prototype.manyInternal = function (prodOccurrence, predicate, action, result) {\n        var _this = this;\n        var lookaheadFunction = this.getLookaheadFuncForMany(prodOccurrence);\n        if (action === undefined) {\n            action = predicate;\n        }\n        else {\n            var orgLookaheadFunction_1 = lookaheadFunction;\n            lookaheadFunction = function () {\n                return predicate.call(_this) &&\n                    orgLookaheadFunction_1.call(_this);\n            };\n        }\n        while (lookaheadFunction.call(this)) {\n            result.push(action.call(this));\n        }\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        this.attemptInRepetitionRecovery(this.manyInternal, [prodOccurrence, lookaheadFunction, action, result], lookaheadFunction, MANY_IDX, prodOccurrence, interpreter_1.NextTerminalAfterManyWalker);\n        return result;\n    };\n    Parser.prototype.manySepFirstInternal = function (prodOccurrence, separator, action, result) {\n        var _this = this;\n        var firstIterationLaFunc = this.getLookaheadFuncForManySep(prodOccurrence);\n        var values = result.values;\n        var separators = result.separators;\n        // 1st iteration\n        if (firstIterationLaFunc.call(this)) {\n            values.push(action.call(this));\n            var separatorLookAheadFunc = function () { return _this.tokenMatcher(_this.LA(1), separator); };\n            // 2nd..nth iterations\n            while (this.tokenMatcher(this.LA(1), separator)) {\n                // note that this CONSUME will never enter recovery because\n                // the separatorLookAheadFunc checks that the separator really does exist.\n                separators.push(this.CONSUME(separator));\n                values.push(action.call(this));\n            }\n            // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n            this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [prodOccurrence, separator, separatorLookAheadFunc, action, interpreter_1.NextTerminalAfterManySepWalker, result], separatorLookAheadFunc, MANY_SEP_IDX, prodOccurrence, interpreter_1.NextTerminalAfterManySepWalker);\n        }\n        return result;\n    };\n    Parser.prototype.repetitionSepSecondInternal = function (prodOccurrence, separator, separatorLookAheadFunc, action, nextTerminalAfterWalker, result) {\n        while (separatorLookAheadFunc()) {\n            // note that this CONSUME will never enter recovery because\n            // the separatorLookAheadFunc checks that the separator really does exist.\n            result.separators.push(this.CONSUME(separator));\n            result.values.push(action.call(this));\n        }\n        // we can only arrive to this function after an error\n        // has occurred (hence the name 'second') so the following\n        // IF will always be entered, its possible to remove it...\n        // however it is kept to avoid confusion and be consistent.\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        /* istanbul ignore else */\n        this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [prodOccurrence, separator, separatorLookAheadFunc, action, nextTerminalAfterWalker, result], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, nextTerminalAfterWalker);\n    };\n    Parser.prototype.orInternal = function (alts, errMsgTypes, occurrence) {\n        var laFunc = this.getLookaheadFuncForOr(occurrence, alts);\n        var altToTake = laFunc.call(this, alts);\n        if (altToTake !== undefined) {\n            var chosenAlternative = alts[altToTake];\n            return chosenAlternative.ALT.call(this);\n        }\n        this.raiseNoAltException(occurrence, errMsgTypes);\n    };\n    // to enable optimizations this logic has been extract to a method as its invoker contains try/catch\n    Parser.prototype.consumeInternalOptimized = function (expectedTokClass) {\n        var nextToken = this.LA(1);\n        if (this.tokenMatcher(nextToken, expectedTokClass)) {\n            this.consumeToken();\n            return nextToken;\n        }\n        else {\n            var msg = this.getMisMatchTokenErrorMessage(expectedTokClass, nextToken);\n            throw this.SAVE_ERROR(new exceptions_public_1.exceptions.MismatchedTokenException(msg, nextToken));\n        }\n    };\n    // this actually returns a number, but it is always used as a string (object prop key)\n    Parser.prototype.getKeyForAutomaticLookahead = function (dslMethodIdx, occurrence) {\n        var ruleStack = this.RULE_STACK;\n        var currRuleShortName = ruleStack[ruleStack.length - 1];\n        /* tslint:disable */\n        return occurrence | dslMethodIdx | currRuleShortName;\n        /* tslint:enable */\n    };\n    Parser.prototype.getLookaheadFuncForOr = function (occurrence, alts) {\n        var key = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n        var laFunc = this.classLAFuncs.get(key);\n        if (laFunc === undefined) {\n            var ruleName = this.getCurrRuleFullName();\n            var ruleGrammar = this.getGAstProductions().get(ruleName);\n            // note that hasPredicates is only computed once.\n            var hasPredicates = utils_1.some(alts, function (currAlt) { return utils_1.isFunction(currAlt.GATE); });\n            laFunc = lookahead_1.buildLookaheadFuncForOr(occurrence, ruleGrammar, this.maxLookahead, hasPredicates, this.tokenMatcher, this.tokenClassIdentityFunc, this.tokenInstanceIdentityFunc, this.dynamicTokensEnabled);\n            this.classLAFuncs.put(key, laFunc);\n            return laFunc;\n        }\n        else {\n            return laFunc;\n        }\n    };\n    // Automatic lookahead calculation\n    Parser.prototype.getLookaheadFuncForOption = function (occurrence) {\n        var key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n        return this.getLookaheadFuncFor(key, occurrence, lookahead_1.buildLookaheadForOption, this.maxLookahead);\n    };\n    Parser.prototype.getLookaheadFuncForMany = function (occurrence) {\n        var key = this.getKeyForAutomaticLookahead(MANY_IDX, occurrence);\n        return this.getLookaheadFuncFor(key, occurrence, lookahead_1.buildLookaheadForMany, this.maxLookahead);\n    };\n    Parser.prototype.getLookaheadFuncForManySep = function (occurrence) {\n        var key = this.getKeyForAutomaticLookahead(MANY_SEP_IDX, occurrence);\n        return this.getLookaheadFuncFor(key, occurrence, lookahead_1.buildLookaheadForManySep, this.maxLookahead);\n    };\n    Parser.prototype.getLookaheadFuncForAtLeastOne = function (occurrence) {\n        var key = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_IDX, occurrence);\n        return this.getLookaheadFuncFor(key, occurrence, lookahead_1.buildLookaheadForAtLeastOne, this.maxLookahead);\n    };\n    Parser.prototype.getLookaheadFuncForAtLeastOneSep = function (occurrence) {\n        var key = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_SEP_IDX, occurrence);\n        return this.getLookaheadFuncFor(key, occurrence, lookahead_1.buildLookaheadForAtLeastOneSep, this.maxLookahead);\n    };\n    // TODO: consider caching the error message computed information\n    Parser.prototype.raiseNoAltException = function (occurrence, errMsgTypes) {\n        var errSuffix = \"\\nbut found: '\" + tokens_public_1.getImage(this.LA(1)) + \"'\";\n        if (errMsgTypes === undefined) {\n            var ruleName = this.getCurrRuleFullName();\n            var ruleGrammar = this.getGAstProductions().get(ruleName);\n            // TODO: getLookaheadPathsForOr can be slow for large enough maxLookahead and certain grammars, consider caching ?\n            var lookAheadPathsPerAlternative = lookahead_1.getLookaheadPathsForOr(occurrence, ruleGrammar, this.maxLookahead);\n            var allLookAheadPaths = utils_1.reduce(lookAheadPathsPerAlternative, function (result, currAltPaths) { return result.concat(currAltPaths); }, []);\n            var nextValidTokenSequences = utils_1.map(allLookAheadPaths, function (currPath) {\n                return \"[\" + utils_1.map(currPath, function (currTokenClass) { return tokens_public_1.tokenLabel(currTokenClass); }).join(\", \") + \"]\";\n            });\n            var nextValidSequenceItems = utils_1.map(nextValidTokenSequences, function (itemMsg, idx) { return \"  \" + (idx + 1) + \". \" + itemMsg; });\n            errMsgTypes = \"one of these possible Token sequences:\\n\" + nextValidSequenceItems.join(\"\\n\");\n        }\n        throw this.SAVE_ERROR(new exceptions_public_1.exceptions.NoViableAltException(\"Expecting: \" + errMsgTypes + errSuffix, this.LA(1)));\n    };\n    Parser.prototype.getLookaheadFuncFor = function (key, occurrence, laFuncBuilder, maxLookahead) {\n        var laFunc = this.classLAFuncs.get(key);\n        if (laFunc === undefined) {\n            var ruleName = this.getCurrRuleFullName();\n            var ruleGrammar = this.getGAstProductions().get(ruleName);\n            laFunc = laFuncBuilder.apply(null, \n            //TODO: change\n            [occurrence, ruleGrammar, maxLookahead, this.tokenMatcher,\n                this.tokenClassIdentityFunc, this.tokenInstanceIdentityFunc, this.dynamicTokensEnabled]);\n            this.classLAFuncs.put(key, laFunc);\n            return laFunc;\n        }\n        else {\n            return laFunc;\n        }\n    };\n    // TODO: consider caching the error message computed information\n    Parser.prototype.raiseEarlyExitException = function (occurrence, prodType, userDefinedErrMsg) {\n        var errSuffix = \" but found: '\" + tokens_public_1.getImage(this.LA(1)) + \"'\";\n        if (userDefinedErrMsg === undefined) {\n            var ruleName = this.getCurrRuleFullName();\n            var ruleGrammar = this.getGAstProductions().get(ruleName);\n            var lookAheadPathsPerAlternative = lookahead_1.getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, this.maxLookahead);\n            var insideProdPaths = lookAheadPathsPerAlternative[0];\n            var nextValidTokenSequences = utils_1.map(insideProdPaths, function (currPath) {\n                return \"[\" + utils_1.map(currPath, function (currTokenClass) { return tokens_public_1.tokenLabel(currTokenClass); }).join(\",\") + \"]\";\n            });\n            userDefinedErrMsg = \"expecting at least one iteration which starts with one of these possible Token sequences::\\n  \" +\n                (\"<\" + nextValidTokenSequences.join(\" ,\") + \">\");\n        }\n        else {\n            userDefinedErrMsg = \"Expecting at least one \" + userDefinedErrMsg;\n        }\n        throw this.SAVE_ERROR(new exceptions_public_1.exceptions.EarlyExitException(userDefinedErrMsg + errSuffix, this.LA(1)));\n    };\n    return Parser;\n}());\nParser.NO_RESYNC = false;\n// Set this flag to true if you don't want the Parser to throw error when problems in it's definition are detected.\n// (normally during the parser's constructor).\n// This is a design time flag, it will not affect the runtime error handling of the parser, just design time errors,\n// for example: duplicate rule names, referencing an unresolved subrule, ect...\n// This flag should not be enabled during normal usage, it is used in special situations, for example when\n// needing to display the parser definition errors in some GUI(online playground).\nParser.DEFER_DEFINITION_ERRORS_HANDLING = false;\nexports.Parser = Parser;\nfunction InRuleRecoveryException(message) {\n    this.name = IN_RULE_RECOVERY_EXCEPTION;\n    this.message = message;\n}\nInRuleRecoveryException.prototype = Error.prototype;\n//# sourceMappingURL=parser_public.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/parser_public.js\n// module id = 9\n// module chunks = 0","\"use strict\";\nvar tokens_public_1 = require(\"./tokens_public\");\nvar lexer_1 = require(\"./lexer\");\nvar utils_1 = require(\"../utils/utils\");\nvar tokens_1 = require(\"./tokens\");\nvar LexerDefinitionErrorType;\n(function (LexerDefinitionErrorType) {\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_MIX_LAZY_AND_NOT_LAZY\"] = 11] = \"LEXER_DEFINITION_CANNOT_MIX_LAZY_AND_NOT_LAZY\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_MIX_SIMPLE_AND_NOT_SIMPLE\"] = 12] = \"LEXER_DEFINITION_CANNOT_MIX_SIMPLE_AND_NOT_SIMPLE\";\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\nvar Lexer = (function () {\n    /**\n     * @param {SingleModeLexerDefinition | IMultiModeLexerDefinition} lexerDefinition -\n     *  Structure composed of constructor functions for the Tokens types this lexer will support.\n     *\n     *  In the case of {SingleModeLexerDefinition} the structure is simply an array of Token constructors.\n     *  In the case of {IMultiModeLexerDefinition} the structure is an object with two properties:\n     *    1. a \"modes\" property where each value is an array of Token.\n     *    2. a \"defaultMode\" property specifying the initial lexer mode.\n     *\n     *  constructors.\n     *\n     *  for example:\n     *  {\n     *     \"modes\" : {\n     *     \"modeX\" : [Token1, Token2]\n     *     \"modeY\" : [Token3, Token4]\n     *     }\n     *\n     *     \"defaultMode\" : \"modeY\"\n     *  }\n     *\n     *  A lexer with {MultiModesDefinition} is simply multiple Lexers where only one (mode) can be active at the same time.\n     *  This is useful for lexing languages where there are different lexing rules depending on context.\n     *\n     *  The current lexing mode is selected via a \"mode stack\".\n     *  The last (peek) value in the stack will be the current mode of the lexer.\n     *\n     *  Each Token class can define that it will cause the Lexer to (after consuming an instance of the Token):\n     *  1. PUSH_MODE : push a new mode to the \"mode stack\"\n     *  2. POP_MODE  : pop the last mode from the \"mode stack\"\n     *\n     *  Examples:\n     *       export class Attribute extends Token {\n     *          static PATTERN = ...\n     *          static PUSH_MODE = \"modeY\"\n     *       }\n     *\n     *       export class EndAttribute extends Token {\n     *          static PATTERN = ...\n     *          static POP_MODE = true\n     *       }\n     *\n     *  The Token constructors must be in one of these forms:\n     *\n     *  1. With a PATTERN property that has a RegExp value for tokens to match:\n     *     example: -->class Integer extends Token { static PATTERN = /[1-9]\\d }<--\n     *\n     *  2. With a PATTERN property that has the value of the var Lexer.NA defined above.\n     *     This is a convenience form used to avoid matching Token classes that only act as categories.\n     *     example: -->class Keyword extends Token { static PATTERN = NA }<--\n     *\n     *\n     *   The following RegExp patterns are not supported:\n     *   a. '$' for match at end of input\n     *   b. /b global flag\n     *   c. /m multi-line flag\n     *\n     *   The Lexer will identify the first pattern that matches, Therefor the order of Token Constructors may be significant.\n     *   For example when one pattern may match a prefix of another pattern.\n     *\n     *   Note that there are situations in which we may wish to order the longer pattern after the shorter one.\n     *   For example: keywords vs Identifiers.\n     *   'do'(/do/) and 'donald'(/w+)\n     *\n     *   * If the Identifier pattern appears before the 'do' pattern, both 'do' and 'donald'\n     *     will be lexed as an Identifier.\n     *\n     *   * If the 'do' pattern appears before the Identifier pattern 'do' will be lexed correctly as a keyword.\n     *     however 'donald' will be lexed as TWO separate tokens: keyword 'do' and identifier 'nald'.\n     *\n     *   To resolve this problem, add a static property on the keyword's constructor named: LONGER_ALT\n     *   example:\n     *\n     *       export class Identifier extends Keyword { static PATTERN = /[_a-zA-Z][_a-zA-Z0-9]/ }\n     *       export class Keyword extends Token {\n     *          static PATTERN = lex.NA\n     *          static LONGER_ALT = Identifier\n     *       }\n     *       export class Do extends Keyword { static PATTERN = /do/ }\n     *       export class While extends Keyword { static PATTERN = /while/ }\n     *       export class Return extends Keyword { static PATTERN = /return/ }\n     *\n     *   The lexer will then also attempt to match a (longer) Identifier each time a keyword is matched.\n     *\n     *\n     * @param {boolean} [deferDefinitionErrorsHandling=false] -\n     *                  An optional flag indicating that lexer definition errors\n     *                  should not automatically cause an error to be raised.\n     *                  This can be useful when wishing to indicate lexer errors in another manner\n     *                  than simply throwing an error (for example in an online playground).\n     */\n    function Lexer(lexerDefinition, deferDefinitionErrorsHandling) {\n        if (deferDefinitionErrorsHandling === void 0) { deferDefinitionErrorsHandling = false; }\n        var _this = this;\n        this.lexerDefinition = lexerDefinition;\n        this.lexerDefinitionErrors = [];\n        this.modes = [];\n        this.allPatterns = {};\n        this.patternIdxToClass = {};\n        this.patternIdxToGroup = {};\n        this.patternIdxToLongerAltIdx = {};\n        this.patternIdxToCanLineTerminator = {};\n        this.patternIdxToPushMode = {};\n        this.patternIdxToPopMode = {};\n        this.emptyGroups = {};\n        var actualDefinition;\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if (utils_1.isArray(lexerDefinition)) {\n            actualDefinition = { modes: {} };\n            actualDefinition.modes[lexer_1.DEFAULT_MODE] = utils_1.cloneArr(lexerDefinition);\n            actualDefinition[lexer_1.DEFAULT_MODE] = lexer_1.DEFAULT_MODE;\n        }\n        else {\n            actualDefinition = utils_1.cloneObj(lexerDefinition);\n        }\n        this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(lexer_1.performRuntimeChecks(actualDefinition));\n        // for extra robustness to avoid throwing an none informative error message\n        actualDefinition.modes = actualDefinition.modes ? actualDefinition.modes : {};\n        // an error of undefined TokenClasses will be detected in \"performRuntimeChecks\" above.\n        // this transformation is to increase robustness in the case of partially invalid lexer definition.\n        utils_1.forEach(actualDefinition.modes, function (currModeValue, currModeName) {\n            actualDefinition.modes[currModeName] = utils_1.reject(currModeValue, function (currTokClass) { return utils_1.isUndefined(currTokClass); });\n        });\n        var allModeNames = utils_1.keys(actualDefinition.modes);\n        utils_1.forEach(actualDefinition.modes, function (currModDef, currModName) {\n            _this.modes.push(currModName);\n            _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat(lexer_1.validatePatterns(currModDef, allModeNames));\n            // If definition errors were encountered, the analysis phase may fail unexpectedly/\n            // Considering a lexer with definition errors may never be used, there is no point\n            // to performing the analysis anyhow...\n            if (utils_1.isEmpty(_this.lexerDefinitionErrors)) {\n                tokens_1.augmentTokenClasses(currModDef);\n                var currAnalyzeResult = lexer_1.analyzeTokenClasses(currModDef);\n                _this.allPatterns[currModName] = currAnalyzeResult.allPatterns;\n                _this.patternIdxToClass[currModName] = currAnalyzeResult.patternIdxToClass;\n                _this.patternIdxToGroup[currModName] = currAnalyzeResult.patternIdxToGroup;\n                _this.patternIdxToLongerAltIdx[currModName] = currAnalyzeResult.patternIdxToLongerAltIdx;\n                _this.patternIdxToCanLineTerminator[currModName] = currAnalyzeResult.patternIdxToCanLineTerminator;\n                _this.patternIdxToPushMode[currModName] = currAnalyzeResult.patternIdxToPushMode;\n                _this.patternIdxToPopMode[currModName] = currAnalyzeResult.patternIdxToPopMode;\n                _this.emptyGroups = utils_1.merge(_this.emptyGroups, currAnalyzeResult.emptyGroups);\n            }\n        });\n        this.defaultMode = actualDefinition.defaultMode;\n        var allTokensTypes = utils_1.flatten(utils_1.mapValues(actualDefinition.modes, function (currModDef) { return currModDef; }));\n        // Lazy Mode handling\n        var lazyCheckResult = lexer_1.checkLazyMode(allTokensTypes);\n        this.isLazyTokenMode = lazyCheckResult.isLazy;\n        this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(lazyCheckResult.errors);\n        // Simple Mode handling\n        var simpleCheckResult = lexer_1.checkSimpleMode(allTokensTypes);\n        this.isSimpleTokenMode = simpleCheckResult.isSimple;\n        this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(simpleCheckResult.errors);\n        if (!utils_1.isEmpty(this.lexerDefinitionErrors) && !deferDefinitionErrorsHandling) {\n            var allErrMessages = utils_1.map(this.lexerDefinitionErrors, function (error) {\n                return error.message;\n            });\n            var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n            throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n        }\n    }\n    /**\n     * Will lex(Tokenize) a string.\n     * Note that this can be called repeatedly on different strings as this method\n     * does not modify the state of the Lexer.\n     *\n     * @param {string} text - The string to lex\n     * @param {string} [initialMode] - The initial Lexer Mode to start with, by default this will be the first mode in the lexer's\n     *                                 definition. If the lexer has no explicit modes it will be the implicit single 'default_mode' mode.\n     *\n     * @returns {ILexingResult}\n     */\n    Lexer.prototype.tokenize = function (text, initialMode) {\n        if (initialMode === void 0) { initialMode = this.defaultMode; }\n        if (!utils_1.isEmpty(this.lexerDefinitionErrors)) {\n            var allErrMessages = utils_1.map(this.lexerDefinitionErrors, function (error) {\n                return error.message;\n            });\n            var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n            throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n        }\n        if (this.isLazyTokenMode) {\n            if (this.isSimpleTokenMode) {\n                return this.tokenizeInternalLazy(text, initialMode, tokens_1.createSimpleLazyToken);\n            }\n            else {\n                return this.tokenizeInternalLazy(text, initialMode, tokens_1.createLazyTokenInstance);\n            }\n        }\n        else {\n            return this.tokenizeInternal(text, initialMode);\n        }\n    };\n    // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n    // This is intentional due to performance considerations.\n    Lexer.prototype.tokenizeInternal = function (text, initialMode) {\n        var _this = this;\n        var match, i, j, matchAlt, longerAltIdx, matchedImage, imageLength, group, tokClass, newToken, errLength, fixForEndingInLT, c, droppedChar, lastLTIdx, msg, lastCharIsLT;\n        var orgInput = text;\n        var offset = 0;\n        var matchedTokens = [];\n        var errors = [];\n        var line = 1;\n        var column = 1;\n        var groups = lexer_1.cloneEmptyGroups(this.emptyGroups);\n        var currModePatterns = [];\n        var currModePatternsLength = 0;\n        var currModePatternIdxToLongerAltIdx = [];\n        var currModePatternIdxToGroup = [];\n        var currModePatternIdxToClass = [];\n        var currModePatternIdxToCanLineTerminator = [];\n        var patternIdxToPushMode = [];\n        var patternIdxToPopMode = [];\n        var modeStack = [];\n        var pop_mode = function (popToken) {\n            // TODO: perhaps avoid this error in the edge case there is no more input?\n            if (modeStack.length === 1) {\n                // if we try to pop the last mode there lexer will no longer have ANY mode.\n                // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n                var msg_1 = \"Unable to pop Lexer Mode after encountering Token ->\" + tokens_public_1.getImage(popToken) + \"<- The Mode Stack is empty\";\n                errors.push({\n                    line: tokens_public_1.getStartLine(popToken),\n                    column: tokens_public_1.getStartColumn(popToken),\n                    length: tokens_public_1.getImage(popToken).length,\n                    message: msg_1\n                });\n            }\n            else {\n                modeStack.pop();\n                var newMode = utils_1.last(modeStack);\n                currModePatterns = _this.allPatterns[newMode];\n                currModePatternsLength = currModePatterns.length;\n                currModePatternIdxToLongerAltIdx = _this.patternIdxToLongerAltIdx[newMode];\n                currModePatternIdxToGroup = _this.patternIdxToGroup[newMode];\n                currModePatternIdxToClass = _this.patternIdxToClass[newMode];\n                currModePatternIdxToCanLineTerminator = _this.patternIdxToCanLineTerminator[newMode];\n                patternIdxToPushMode = _this.patternIdxToPushMode[newMode];\n                patternIdxToPopMode = _this.patternIdxToPopMode[newMode];\n            }\n        };\n        function push_mode(newMode) {\n            modeStack.push(newMode);\n            currModePatterns = this.allPatterns[newMode];\n            currModePatternsLength = currModePatterns.length;\n            currModePatternIdxToLongerAltIdx = this.patternIdxToLongerAltIdx[newMode];\n            currModePatternIdxToGroup = this.patternIdxToGroup[newMode];\n            currModePatternIdxToClass = this.patternIdxToClass[newMode];\n            currModePatternIdxToCanLineTerminator = this.patternIdxToCanLineTerminator[newMode];\n            patternIdxToPushMode = this.patternIdxToPushMode[newMode];\n            patternIdxToPopMode = this.patternIdxToPopMode[newMode];\n        }\n        // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n        // seem to matter performance wise.\n        push_mode.call(this, initialMode);\n        while (text.length > 0) {\n            match = null;\n            for (i = 0; i < currModePatternsLength; i++) {\n                match = currModePatterns[i].exec(text);\n                if (match !== null) {\n                    // even though this pattern matched we must try a another longer alternative.\n                    // this can be used to prioritize keywords over identifiers\n                    longerAltIdx = currModePatternIdxToLongerAltIdx[i];\n                    if (longerAltIdx) {\n                        matchAlt = currModePatterns[longerAltIdx].exec(text);\n                        if (matchAlt && matchAlt[0].length > match[0].length) {\n                            match = matchAlt;\n                            i = longerAltIdx;\n                        }\n                    }\n                    break;\n                }\n            }\n            // successful match\n            if (match !== null) {\n                matchedImage = match[0];\n                imageLength = matchedImage.length;\n                group = currModePatternIdxToGroup[i];\n                if (group !== undefined) {\n                    tokClass = currModePatternIdxToClass[i];\n                    newToken = new tokClass(matchedImage, offset, line, column);\n                    if (group === \"default\") {\n                        matchedTokens.push(newToken);\n                    }\n                    else {\n                        groups[group].push(newToken);\n                    }\n                }\n                text = text.slice(imageLength);\n                offset = offset + imageLength;\n                column = column + imageLength; // TODO: with newlines the column may be assigned twice\n                if (currModePatternIdxToCanLineTerminator[i]) {\n                    var lineTerminatorsInMatch = lexer_1.countLineTerminators(matchedImage);\n                    // TODO: identify edge case of one token ending in '\\r' and another one starting with '\\n'\n                    if (lineTerminatorsInMatch !== 0) {\n                        line = line + lineTerminatorsInMatch;\n                        lastLTIdx = imageLength - 1;\n                        while (lastLTIdx >= 0) {\n                            c = matchedImage.charCodeAt(lastLTIdx);\n                            // scan in reverse to find last lineTerminator in image\n                            if (c === 13 || c === 10) {\n                                break;\n                            }\n                            lastLTIdx--;\n                        }\n                        column = imageLength - lastLTIdx;\n                        if (group !== undefined) {\n                            lastCharIsLT = lastLTIdx === imageLength - 1;\n                            fixForEndingInLT = lastCharIsLT ?\n                                -1 :\n                                0;\n                            if (!(lineTerminatorsInMatch === 1 && lastCharIsLT)) {\n                                // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n                                newToken.endLine = line + fixForEndingInLT;\n                                // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n                                // inclusive to exclusive range.\n                                newToken.endColumn = column - 1 + -fixForEndingInLT;\n                            }\n                        }\n                    }\n                }\n                // mode handling, must pop before pushing if a Token both acts as both\n                // otherwise it would be a NO-OP\n                if (patternIdxToPopMode[i]) {\n                    // need to save the PUSH_MODE property as if the mode is popped\n                    // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n                    var pushMode = patternIdxToPushMode[i];\n                    pop_mode(newToken);\n                    if (pushMode) {\n                        push_mode.call(this, pushMode);\n                    }\n                }\n                else if (patternIdxToPushMode[i]) {\n                    push_mode.call(this, patternIdxToPushMode[i]);\n                }\n            }\n            else {\n                var errorStartOffset = offset;\n                var errorLine = line;\n                var errorColumn = column;\n                var foundResyncPoint = false;\n                while (!foundResyncPoint && text.length > 0) {\n                    // drop chars until we succeed in matching something\n                    droppedChar = text.charCodeAt(0);\n                    if (droppedChar === 10 ||\n                        (droppedChar === 13 &&\n                            (text.length === 1 || (text.length > 1 && text.charCodeAt(1) !== 10)))) {\n                        line++;\n                        column = 1;\n                    }\n                    else {\n                        // either when skipping the next char, or when consuming the following pattern\n                        // (which will have to start in a '\\n' if we manage to consume it)\n                        column++;\n                    }\n                    text = text.substr(1);\n                    offset++;\n                    for (j = 0; j < currModePatterns.length; j++) {\n                        foundResyncPoint = currModePatterns[j].exec(text);\n                        if (foundResyncPoint !== null) {\n                            break;\n                        }\n                    }\n                }\n                errLength = offset - errorStartOffset;\n                // at this point we either re-synced or reached the end of the input text\n                msg = \"unexpected character: ->\" + orgInput.charAt(errorStartOffset) + \"<- at offset: \" + errorStartOffset + \",\" +\n                    (\" skipped \" + (offset - errorStartOffset) + \" characters.\");\n                errors.push({ line: errorLine, column: errorColumn, length: errLength, message: msg });\n            }\n        }\n        return { tokens: matchedTokens, groups: groups, errors: errors };\n    };\n    Lexer.prototype.tokenizeInternalLazy = function (text, initialMode, tokenCreator) {\n        var _this = this;\n        var match, i, j, matchAlt, longerAltIdx, matchedImage, imageLength, group, tokClass, newToken, errLength, droppedChar, msg;\n        var orgInput = text;\n        var offset = 0;\n        var matchedTokens = [];\n        var errors = [];\n        var groups = lexer_1.cloneEmptyGroups(this.emptyGroups);\n        var currModePatterns = [];\n        var currModePatternsLength = 0;\n        var currModePatternIdxToLongerAltIdx = [];\n        var currModePatternIdxToGroup = [];\n        var currModePatternIdxToClass = [];\n        var patternIdxToPushMode = [];\n        var patternIdxToPopMode = [];\n        var lazyCacheData = {\n            orgText: text,\n            lineToOffset: []\n        };\n        var modeStack = [];\n        var pop_mode = function (popToken) {\n            // TODO: perhaps avoid this error in the edge case there is no more input?\n            if (modeStack.length === 1) {\n                // if we try to pop the last mode there lexer will no longer have ANY mode.\n                // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n                var msg_2 = \"Unable to pop Lexer Mode after encountering Token ->\" + tokens_public_1.getImage(popToken) + \"<- The Mode Stack is empty\";\n                errors.push({\n                    line: tokens_public_1.getStartLine(popToken),\n                    column: tokens_public_1.getStartColumn(popToken),\n                    length: tokens_public_1.getImage(popToken).length,\n                    message: msg_2\n                });\n            }\n            else {\n                modeStack.pop();\n                var newMode = utils_1.last(modeStack);\n                currModePatterns = _this.allPatterns[newMode];\n                currModePatternsLength = currModePatterns.length;\n                currModePatternIdxToLongerAltIdx = _this.patternIdxToLongerAltIdx[newMode];\n                currModePatternIdxToGroup = _this.patternIdxToGroup[newMode];\n                currModePatternIdxToClass = _this.patternIdxToClass[newMode];\n                patternIdxToPushMode = _this.patternIdxToPushMode[newMode];\n                patternIdxToPopMode = _this.patternIdxToPopMode[newMode];\n            }\n        };\n        function push_mode(newMode) {\n            modeStack.push(newMode);\n            currModePatterns = this.allPatterns[newMode];\n            currModePatternsLength = currModePatterns.length;\n            currModePatternIdxToLongerAltIdx = this.patternIdxToLongerAltIdx[newMode];\n            currModePatternIdxToGroup = this.patternIdxToGroup[newMode];\n            currModePatternIdxToClass = this.patternIdxToClass[newMode];\n            patternIdxToPushMode = this.patternIdxToPushMode[newMode];\n            patternIdxToPopMode = this.patternIdxToPopMode[newMode];\n        }\n        // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n        // seem to matter performance wise.\n        push_mode.call(this, initialMode);\n        while (text.length > 0) {\n            match = null;\n            for (i = 0; i < currModePatternsLength; i++) {\n                match = currModePatterns[i].exec(text);\n                if (match !== null) {\n                    // even though this pattern matched we must try a another longer alternative.\n                    // this can be used to prioritize keywords over identifiers\n                    longerAltIdx = currModePatternIdxToLongerAltIdx[i];\n                    if (longerAltIdx) {\n                        matchAlt = currModePatterns[longerAltIdx].exec(text);\n                        if (matchAlt && matchAlt[0].length > match[0].length) {\n                            match = matchAlt;\n                            i = longerAltIdx;\n                        }\n                    }\n                    break;\n                }\n            }\n            // successful match\n            if (match !== null) {\n                matchedImage = match[0];\n                imageLength = matchedImage.length;\n                group = currModePatternIdxToGroup[i];\n                if (group !== undefined) {\n                    tokClass = currModePatternIdxToClass[i];\n                    // the end offset is non inclusive.\n                    newToken = tokenCreator(offset, offset + imageLength - 1, tokClass, lazyCacheData);\n                    if (group === \"default\") {\n                        matchedTokens.push(newToken);\n                    }\n                    else {\n                        groups[group].push(newToken);\n                    }\n                }\n                text = text.slice(imageLength);\n                offset = offset + imageLength;\n                // mode handling, must pop before pushing if a Token both acts as both\n                // otherwise it would be a NO-OP\n                if (patternIdxToPopMode[i]) {\n                    // need to save the PUSH_MODE property as if the mode is popped\n                    // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n                    var pushMode = patternIdxToPushMode[i];\n                    pop_mode(newToken);\n                    if (pushMode) {\n                        push_mode.call(this, pushMode);\n                    }\n                }\n                else if (patternIdxToPushMode[i]) {\n                    push_mode.call(this, patternIdxToPushMode[i]);\n                }\n            }\n            else {\n                var errorStartOffset = offset;\n                var foundResyncPoint = false;\n                while (!foundResyncPoint && text.length > 0) {\n                    // drop chars until we succeed in matching something\n                    droppedChar = text.charCodeAt(0);\n                    text = text.substr(1);\n                    offset++;\n                    for (j = 0; j < currModePatterns.length; j++) {\n                        foundResyncPoint = currModePatterns[j].exec(text);\n                        if (foundResyncPoint !== null) {\n                            break;\n                        }\n                    }\n                }\n                errLength = offset - errorStartOffset;\n                // at this point we either re-synced or reached the end of the input text\n                msg = \"unexpected character: ->\" + orgInput.charAt(errorStartOffset) + \"<- at offset: \" + errorStartOffset + \",\" +\n                    (\" skipped \" + (offset - errorStartOffset) + \" characters.\");\n                if (utils_1.isEmpty(lazyCacheData.lineToOffset)) {\n                    tokens_1.fillUpLineToOffset(lazyCacheData.lineToOffset, lazyCacheData.orgText);\n                }\n                var errorLine = tokens_1.getStartLineFromLineToOffset(errorStartOffset, lazyCacheData.lineToOffset);\n                var errorColumn = tokens_1.getStartColumnFromLineToOffset(errorStartOffset, lazyCacheData.lineToOffset);\n                errors.push({ line: errorLine, column: errorColumn, length: errLength, message: msg });\n            }\n        }\n        return { tokens: matchedTokens, groups: groups, errors: errors };\n    };\n    return Lexer;\n}());\nLexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\nLexer.NA = /NOT_APPLICABLE/;\nexports.Lexer = Lexer;\n//# sourceMappingURL=lexer_public.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/scan/lexer_public.js\n// module id = 10\n// module chunks = 0","\"use strict\";\nvar parser_public_1 = require(\"./parse/parser_public\");\nvar lexer_public_1 = require(\"./scan/lexer_public\");\nvar tokens_public_1 = require(\"./scan/tokens_public\");\nvar exceptions_public_1 = require(\"./parse/exceptions_public\");\nvar gast_public_1 = require(\"./parse/grammar/gast_public\");\nvar cache_public_1 = require(\"./parse/cache_public\");\nvar interpreter_1 = require(\"./parse/grammar/interpreter\");\nvar version_1 = require(\"./version\");\n/**\n * defines the public API of\n * changes here may require major version change. (semVer)\n */\nvar API = {};\n// semantic version\nAPI.VERSION = version_1.VERSION;\n// runtime API\nAPI.Parser = parser_public_1.Parser;\nAPI.ParserDefinitionErrorType = parser_public_1.ParserDefinitionErrorType;\nAPI.Lexer = lexer_public_1.Lexer;\nAPI.LexerDefinitionErrorType = lexer_public_1.LexerDefinitionErrorType;\nAPI.Token = tokens_public_1.Token;\nAPI.LazyToken = tokens_public_1.LazyToken;\nAPI.SimpleLazyToken = tokens_public_1.SimpleLazyToken;\n// TODO: remove this, does not belong on the API.\nAPI.VirtualToken = tokens_public_1.VirtualToken;\nAPI.EOF = tokens_public_1.EOF;\n// Tokens utilities\nAPI.extendToken = tokens_public_1.extendToken;\nAPI.extendLazyToken = tokens_public_1.extendLazyToken;\nAPI.extendSimpleLazyToken = tokens_public_1.extendSimpleLazyToken;\nAPI.tokenName = tokens_public_1.tokenName;\nAPI.tokenLabel = tokens_public_1.tokenLabel;\nAPI.tokenMatcher = tokens_public_1.tokenMatcher;\nAPI.createToken = tokens_public_1.createToken;\nAPI.createLazyToken = tokens_public_1.createLazyToken;\nAPI.createSimpleLazyToken = tokens_public_1.createSimpleLazyToken;\n// Tokens getters\nAPI.getImage = tokens_public_1.getImage;\nAPI.getStartOffset = tokens_public_1.getStartOffset;\nAPI.getStartLine = tokens_public_1.getStartLine;\nAPI.getStartColumn = tokens_public_1.getStartColumn;\nAPI.getEndOffset = tokens_public_1.getEndOffset;\nAPI.getEndLine = tokens_public_1.getEndLine;\nAPI.getEndColumn = tokens_public_1.getEndColumn;\nAPI.getTokenConstructor = tokens_public_1.getTokenConstructor;\n// Other Utilities\nAPI.EMPTY_ALT = parser_public_1.EMPTY_ALT;\nAPI.exceptions = {};\nAPI.exceptions.isRecognitionException = exceptions_public_1.exceptions.isRecognitionException;\nAPI.exceptions.EarlyExitException = exceptions_public_1.exceptions.EarlyExitException;\nAPI.exceptions.MismatchedTokenException = exceptions_public_1.exceptions.MismatchedTokenException;\nAPI.exceptions.NotAllInputParsedException = exceptions_public_1.exceptions.NotAllInputParsedException;\nAPI.exceptions.NoViableAltException = exceptions_public_1.exceptions.NoViableAltException;\n// grammar reflection API\nAPI.gast = {};\nAPI.gast.GAstVisitor = gast_public_1.gast.GAstVisitor;\nAPI.gast.Flat = gast_public_1.gast.Flat;\nAPI.gast.Repetition = gast_public_1.gast.Repetition;\nAPI.gast.RepetitionWithSeparator = gast_public_1.gast.RepetitionWithSeparator;\nAPI.gast.RepetitionMandatory = gast_public_1.gast.RepetitionMandatory;\nAPI.gast.RepetitionMandatoryWithSeparator = gast_public_1.gast.RepetitionMandatoryWithSeparator;\nAPI.gast.Option = gast_public_1.gast.Option;\nAPI.gast.Alternation = gast_public_1.gast.Alternation;\nAPI.gast.NonTerminal = gast_public_1.gast.NonTerminal;\nAPI.gast.Terminal = gast_public_1.gast.Terminal;\nAPI.gast.Rule = gast_public_1.gast.Rule;\nAPI.gast.serializeGrammar = gast_public_1.gast.serializeGrammar;\nAPI.gast.serializeProduction = gast_public_1.gast.serializeProduction;\nAPI.interperter = {};\nAPI.interperter.NextAfterTokenWalker = interpreter_1.NextAfterTokenWalker;\nAPI.clearCache = cache_public_1.clearCache;\nmodule.exports = API;\n//# sourceMappingURL=api.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/api.js\n// module id = 11\n// module chunks = 0","/**\n * module used to cache static information about parsers,\n */\n\"use strict\";\nvar lang_extensions_1 = require(\"../lang/lang_extensions\");\nvar utils_1 = require(\"./../utils/utils\");\nexports.CLASS_TO_DEFINITION_ERRORS = new lang_extensions_1.HashTable();\nexports.CLASS_TO_SELF_ANALYSIS_DONE = new lang_extensions_1.HashTable();\nexports.CLASS_TO_GRAMMAR_PRODUCTIONS = new lang_extensions_1.HashTable();\nfunction getProductionsForClass(className) {\n    return getFromNestedHashTable(className, exports.CLASS_TO_GRAMMAR_PRODUCTIONS);\n}\nexports.getProductionsForClass = getProductionsForClass;\nexports.CLASS_TO_RESYNC_FOLLOW_SETS = new lang_extensions_1.HashTable();\nfunction getResyncFollowsForClass(className) {\n    return getFromNestedHashTable(className, exports.CLASS_TO_RESYNC_FOLLOW_SETS);\n}\nexports.getResyncFollowsForClass = getResyncFollowsForClass;\nfunction setResyncFollowsForClass(className, followSet) {\n    exports.CLASS_TO_RESYNC_FOLLOW_SETS.put(className, followSet);\n}\nexports.setResyncFollowsForClass = setResyncFollowsForClass;\nexports.CLASS_TO_LOOKAHEAD_FUNCS = new lang_extensions_1.HashTable();\nfunction getLookaheadFuncsForClass(className) {\n    return getFromNestedHashTable(className, exports.CLASS_TO_LOOKAHEAD_FUNCS);\n}\nexports.getLookaheadFuncsForClass = getLookaheadFuncsForClass;\nexports.CLASS_TO_FIRST_AFTER_REPETITION = new lang_extensions_1.HashTable();\nfunction getFirstAfterRepForClass(className) {\n    return getFromNestedHashTable(className, exports.CLASS_TO_FIRST_AFTER_REPETITION);\n}\nexports.getFirstAfterRepForClass = getFirstAfterRepForClass;\nexports.CLASS_TO_PRODUCTION_OVERRIDEN = new lang_extensions_1.HashTable();\nfunction getProductionOverriddenForClass(className) {\n    return getFromNestedHashTable(className, exports.CLASS_TO_PRODUCTION_OVERRIDEN);\n}\nexports.getProductionOverriddenForClass = getProductionOverriddenForClass;\n// TODO reflective test to verify this has not changed, for example (OPTION6 added)\nexports.MAX_OCCURRENCE_INDEX = 5;\nfunction getFromNestedHashTable(className, hashTable) {\n    var result = hashTable.get(className);\n    if (result === undefined) {\n        hashTable.put(className, new lang_extensions_1.HashTable());\n        result = hashTable.get(className);\n    }\n    return result;\n}\nfunction clearCache() {\n    var hasTables = utils_1.filter(utils_1.values(module.exports), function (currHashTable) { return currHashTable instanceof lang_extensions_1.HashTable; });\n    utils_1.forEach(hasTables, function (currHashTable) { return currHashTable.clear(); });\n}\nexports.clearCache = clearCache;\n//# sourceMappingURL=cache.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/cache.js\n// module id = 12\n// module chunks = 0","\"use strict\";\n// TODO: can this be removed? where is it used?\nexports.IN = \"_~IN~_\";\n//# sourceMappingURL=constants.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/constants.js\n// module id = 13\n// module chunks = 0","\"use strict\";\nvar utils_1 = require(\"../utils/utils\");\nvar exceptions;\n(function (exceptions) {\n    var MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\n    var NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\n    var EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\n    var NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\n    var RECOGNITION_EXCEPTION_NAMES = [\n        MISMATCHED_TOKEN_EXCEPTION,\n        NO_VIABLE_ALT_EXCEPTION,\n        EARLY_EXIT_EXCEPTION,\n        NOT_ALL_INPUT_PARSED_EXCEPTION\n    ];\n    Object.freeze(RECOGNITION_EXCEPTION_NAMES);\n    // hacks to bypass no support for custom Errors in javascript/typescript\n    function isRecognitionException(error) {\n        // can't do instanceof on hacked custom js exceptions\n        return utils_1.contains(RECOGNITION_EXCEPTION_NAMES, error.name);\n    }\n    exceptions.isRecognitionException = isRecognitionException;\n    function MismatchedTokenException(message, token) {\n        this.name = MISMATCHED_TOKEN_EXCEPTION;\n        this.message = message;\n        this.token = token;\n        this.resyncedTokens = [];\n    }\n    exceptions.MismatchedTokenException = MismatchedTokenException;\n    // must use the \"Error.prototype\" instead of \"new Error\"\n    // because the stack trace points to where \"new Error\" was invoked\"\n    MismatchedTokenException.prototype = Error.prototype;\n    function NoViableAltException(message, token) {\n        this.name = NO_VIABLE_ALT_EXCEPTION;\n        this.message = message;\n        this.token = token;\n        this.resyncedTokens = [];\n    }\n    exceptions.NoViableAltException = NoViableAltException;\n    NoViableAltException.prototype = Error.prototype;\n    function NotAllInputParsedException(message, token) {\n        this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n        this.message = message;\n        this.token = token;\n        this.resyncedTokens = [];\n    }\n    exceptions.NotAllInputParsedException = NotAllInputParsedException;\n    NotAllInputParsedException.prototype = Error.prototype;\n    function EarlyExitException(message, token) {\n        this.name = EARLY_EXIT_EXCEPTION;\n        this.message = message;\n        this.token = token;\n        this.resyncedTokens = [];\n    }\n    exceptions.EarlyExitException = EarlyExitException;\n    EarlyExitException.prototype = Error.prototype;\n})(exceptions = exports.exceptions || (exports.exceptions = {}));\n//# sourceMappingURL=exceptions_public.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/exceptions_public.js\n// module id = 14\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\nvar utils_1 = require(\"../../utils/utils\");\nvar gast_public_1 = require(\"./gast_public\");\nvar interpreter_1 = require(\"./interpreter\");\nvar rest_1 = require(\"./rest\");\nvar PROD_TYPE;\n(function (PROD_TYPE) {\n    PROD_TYPE[PROD_TYPE[\"OPTION\"] = 0] = \"OPTION\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION\"] = 1] = \"REPETITION\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_MANDATORY\"] = 2] = \"REPETITION_MANDATORY\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_MANDATORY_WITH_SEPARATOR\"] = 3] = \"REPETITION_MANDATORY_WITH_SEPARATOR\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_WITH_SEPARATOR\"] = 4] = \"REPETITION_WITH_SEPARATOR\";\n    PROD_TYPE[PROD_TYPE[\"ALTERNATION\"] = 5] = \"ALTERNATION\";\n})(PROD_TYPE = exports.PROD_TYPE || (exports.PROD_TYPE = {}));\nfunction buildLookaheadFuncForOr(occurrence, ruleGrammar, k, hasPredicates, tokenMatcher, tokenClassIdentityFunc, tokenIdentityFunc, dynamicTokensEnabled) {\n    var lookAheadPaths = getLookaheadPathsForOr(occurrence, ruleGrammar, k);\n    return buildAlternativesLookAheadFunc(lookAheadPaths, hasPredicates, tokenMatcher, tokenClassIdentityFunc, tokenIdentityFunc, dynamicTokensEnabled);\n}\nexports.buildLookaheadFuncForOr = buildLookaheadFuncForOr;\n/**\n *  When dealing with an Optional production (OPTION/MANY/2nd iteration of AT_LEAST_ONE/...) we need to compare\n *  the lookahead \"inside\" the production and the lookahead immediately \"after\" it in the same top level rule (context free).\n *\n *  Example: given a production:\n *  ABC(DE)?DF\n *\n *  The optional '(DE)?' should only be entered if we see 'DE'. a single Token 'D' is not sufficient to distinguish between the two\n *  alternatives.\n *\n *  @returns A Lookahead function which will return true IFF the parser should parse the Optional production.\n */\nfunction buildLookaheadFuncForOptionalProd(occurrence, ruleGrammar, prodType, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    var lookAheadPaths = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k);\n    return buildSingleAlternativeLookaheadFunction(lookAheadPaths[0], tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled);\n}\nexports.buildLookaheadFuncForOptionalProd = buildLookaheadFuncForOptionalProd;\nfunction buildLookaheadForOption(optionOccurrence, ruleGrammar, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    return buildLookaheadFuncForOptionalProd(optionOccurrence, ruleGrammar, PROD_TYPE.OPTION, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled);\n}\nexports.buildLookaheadForOption = buildLookaheadForOption;\nfunction buildLookaheadForMany(optionOccurrence, ruleGrammar, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    return buildLookaheadFuncForOptionalProd(optionOccurrence, ruleGrammar, PROD_TYPE.REPETITION, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled);\n}\nexports.buildLookaheadForMany = buildLookaheadForMany;\nfunction buildLookaheadForManySep(optionOccurrence, ruleGrammar, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    return buildLookaheadFuncForOptionalProd(optionOccurrence, ruleGrammar, PROD_TYPE.REPETITION_WITH_SEPARATOR, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled);\n}\nexports.buildLookaheadForManySep = buildLookaheadForManySep;\nfunction buildLookaheadForAtLeastOne(optionOccurrence, ruleGrammar, k, tokenMatcher, tokenIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    return buildLookaheadFuncForOptionalProd(optionOccurrence, ruleGrammar, PROD_TYPE.REPETITION_MANDATORY, k, tokenMatcher, tokenIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled);\n}\nexports.buildLookaheadForAtLeastOne = buildLookaheadForAtLeastOne;\nfunction buildLookaheadForAtLeastOneSep(optionOccurrence, ruleGrammar, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    return buildLookaheadFuncForOptionalProd(optionOccurrence, ruleGrammar, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, k, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled);\n}\nexports.buildLookaheadForAtLeastOneSep = buildLookaheadForAtLeastOneSep;\nfunction buildAlternativesLookAheadFunc(alts, hasPredicates, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    var numOfAlts = alts.length;\n    var areAllOneTokenLookahead = utils_1.every(alts, function (currAlt) {\n        return utils_1.every(currAlt, function (currPath) {\n            return currPath.length === 1;\n        });\n    });\n    // This version takes into account the predicates as well.\n    if (hasPredicates) {\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function (orAlts) {\n            // unfortunately the predicates must be extracted every single time\n            // as they cannot be cached due to keep references to parameters(vars) which are no longer valid.\n            // note that in the common case of no predicates, no cpu time will be wasted on this (see else block)\n            var predicates = utils_1.map(orAlts, function (currAlt) { return currAlt.GATE; });\n            for (var t = 0; t < numOfAlts; t++) {\n                var currAlt = alts[t];\n                var currNumOfPaths = currAlt.length;\n                var currPredicate = predicates[t];\n                if (currPredicate && !currPredicate.call(this)) {\n                    // if the predicate does not match there is no point in checking the paths\n                    continue;\n                }\n                nextPath: for (var j = 0; j < currNumOfPaths; j++) {\n                    var currPath = currAlt[j];\n                    var currPathLength = currPath.length;\n                    for (var i = 0; i < currPathLength; i++) {\n                        var nextToken = this.LA(i + 1);\n                        if (!tokenMatcher(nextToken, currPath[i])) {\n                            // mismatch in current path\n                            // try the next pth\n                            continue nextPath;\n                        }\n                    }\n                    // found a full path that matches.\n                    // this will also work for an empty ALT as the loop will be skipped\n                    return t;\n                }\n            }\n            // none of the alternatives could be matched\n            return undefined;\n        };\n    }\n    else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n        var singleTokenAlts = utils_1.map(alts, function (currAlt) {\n            return utils_1.flatten(currAlt);\n        });\n        var choiceToAlt_1 = utils_1.reduce(singleTokenAlts, function (result, currAlt, idx) {\n            utils_1.forEach(currAlt, function (currTokClass) {\n                if (!utils_1.has(result, tokenClassIdentityFunc(currTokClass))) {\n                    result[tokenClassIdentityFunc(currTokClass)] = idx;\n                }\n                utils_1.forEach(currTokClass.extendingTokenTypes, function (currExtendingType) {\n                    if (!utils_1.has(result, currExtendingType)) {\n                        result[currExtendingType] = idx;\n                    }\n                });\n            });\n            return result;\n        }, {});\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function () {\n            var nextToken = this.LA(1);\n            return choiceToAlt_1[tokenInstanceIdentityFunc(nextToken)];\n        };\n    }\n    else {\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function () {\n            for (var t = 0; t < numOfAlts; t++) {\n                var currAlt = alts[t];\n                var currNumOfPaths = currAlt.length;\n                nextPath: for (var j = 0; j < currNumOfPaths; j++) {\n                    var currPath = currAlt[j];\n                    var currPathLength = currPath.length;\n                    for (var i = 0; i < currPathLength; i++) {\n                        var nextToken = this.LA(i + 1);\n                        if (!(tokenMatcher(nextToken, currPath[i]))) {\n                            // mismatch in current path\n                            // try the next pth\n                            continue nextPath;\n                        }\n                    }\n                    // found a full path that matches.\n                    // this will also work for an empty ALT as the loop will be skipped\n                    return t;\n                }\n            }\n            // none of the alternatives could be matched\n            return undefined;\n        };\n    }\n}\nexports.buildAlternativesLookAheadFunc = buildAlternativesLookAheadFunc;\nfunction buildSingleAlternativeLookaheadFunction(alt, tokenMatcher, tokenClassIdentityFunc, tokenInstanceIdentityFunc, dynamicTokensEnabled) {\n    var areAllOneTokenLookahead = utils_1.every(alt, function (currPath) {\n        return currPath.length === 1;\n    });\n    var numOfPaths = alt.length;\n    // optimized (common) case of all the lookaheads paths requiring only\n    // a single token lookahead.\n    if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n        var singleTokensClasses = utils_1.flatten(alt);\n        if (singleTokensClasses.length === 1 && utils_1.isEmpty(singleTokensClasses[0].extendingTokenTypes)) {\n            var expectedTokenType = singleTokensClasses[0];\n            var expectedTokenUniqueKey_1 = tokenClassIdentityFunc(expectedTokenType);\n            return function () {\n                return tokenInstanceIdentityFunc(this.LA(1)) === expectedTokenUniqueKey_1;\n            };\n        }\n        else {\n            var choiceToAlt_2 = utils_1.reduce(singleTokensClasses, function (result, currTokClass, idx) {\n                result[tokenClassIdentityFunc(currTokClass)] = true;\n                utils_1.forEach(currTokClass.extendingTokenTypes, function (currExtendingType) {\n                    result[currExtendingType] = true;\n                });\n                return result;\n            }, {});\n            return function () {\n                var nextToken = this.LA(1);\n                return choiceToAlt_2[tokenInstanceIdentityFunc(nextToken)] === true ? true : false;\n            };\n        }\n    }\n    else {\n        return function () {\n            nextPath: for (var j = 0; j < numOfPaths; j++) {\n                var currPath = alt[j];\n                var currPathLength = currPath.length;\n                for (var i = 0; i < currPathLength; i++) {\n                    var nextToken = this.LA(i + 1);\n                    if (!(tokenMatcher(nextToken, currPath[i]))) {\n                        // mismatch in current path\n                        // try the next pth\n                        continue nextPath;\n                    }\n                }\n                // found a full path that matches.\n                return true;\n            }\n            // none of the paths matched\n            return false;\n        };\n    }\n}\nexports.buildSingleAlternativeLookaheadFunction = buildSingleAlternativeLookaheadFunction;\nvar RestDefinitionFinderWalker = (function (_super) {\n    __extends(RestDefinitionFinderWalker, _super);\n    function RestDefinitionFinderWalker(topProd, targetOccurrence, targetProdType) {\n        var _this = _super.call(this) || this;\n        _this.topProd = topProd;\n        _this.targetOccurrence = targetOccurrence;\n        _this.targetProdType = targetProdType;\n        return _this;\n    }\n    RestDefinitionFinderWalker.prototype.startWalking = function () {\n        this.walk(this.topProd);\n        return this.restDef;\n    };\n    RestDefinitionFinderWalker.prototype.checkIsTarget = function (node, expectedProdType, currRest, prevRest) {\n        if (node.occurrenceInParent === this.targetOccurrence &&\n            this.targetProdType === expectedProdType) {\n            this.restDef = currRest.concat(prevRest);\n            return true;\n        }\n        // performance optimization, do not iterate over the entire Grammar ast after we have found the target\n        return false;\n    };\n    RestDefinitionFinderWalker.prototype.walkOption = function (optionProd, currRest, prevRest) {\n        if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n            _super.prototype.walkOption.call(this, optionProd, currRest, prevRest);\n        }\n    };\n    RestDefinitionFinderWalker.prototype.walkAtLeastOne = function (atLeastOneProd, currRest, prevRest) {\n        if (!this.checkIsTarget(atLeastOneProd, PROD_TYPE.REPETITION_MANDATORY, currRest, prevRest)) {\n            _super.prototype.walkOption.call(this, atLeastOneProd, currRest, prevRest);\n        }\n    };\n    RestDefinitionFinderWalker.prototype.walkAtLeastOneSep = function (atLeastOneSepProd, currRest, prevRest) {\n        if (!this.checkIsTarget(atLeastOneSepProd, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, currRest, prevRest)) {\n            _super.prototype.walkOption.call(this, atLeastOneSepProd, currRest, prevRest);\n        }\n    };\n    RestDefinitionFinderWalker.prototype.walkMany = function (manyProd, currRest, prevRest) {\n        if (!this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)) {\n            _super.prototype.walkOption.call(this, manyProd, currRest, prevRest);\n        }\n    };\n    RestDefinitionFinderWalker.prototype.walkManySep = function (manySepProd, currRest, prevRest) {\n        if (!this.checkIsTarget(manySepProd, PROD_TYPE.REPETITION_WITH_SEPARATOR, currRest, prevRest)) {\n            _super.prototype.walkOption.call(this, manySepProd, currRest, prevRest);\n        }\n    };\n    return RestDefinitionFinderWalker;\n}(rest_1.RestWalker));\n/**\n * Returns the definition of a target production in a top level level rule.\n */\nvar InsideDefinitionFinderVisitor = (function (_super) {\n    __extends(InsideDefinitionFinderVisitor, _super);\n    function InsideDefinitionFinderVisitor(targetOccurrence, targetProdType) {\n        var _this = _super.call(this) || this;\n        _this.targetOccurrence = targetOccurrence;\n        _this.targetProdType = targetProdType;\n        _this.result = [];\n        return _this;\n    }\n    InsideDefinitionFinderVisitor.prototype.checkIsTarget = function (node, expectedProdName) {\n        if (node.occurrenceInParent === this.targetOccurrence &&\n            this.targetProdType === expectedProdName) {\n            this.result = node.definition;\n        }\n    };\n    InsideDefinitionFinderVisitor.prototype.visitOption = function (node) {\n        this.checkIsTarget(node, PROD_TYPE.OPTION);\n    };\n    InsideDefinitionFinderVisitor.prototype.visitRepetition = function (node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION);\n    };\n    InsideDefinitionFinderVisitor.prototype.visitRepetitionMandatory = function (node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n    };\n    InsideDefinitionFinderVisitor.prototype.visitRepetitionMandatoryWithSeparator = function (node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n    };\n    InsideDefinitionFinderVisitor.prototype.visitRepetitionWithSeparator = function (node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n    };\n    InsideDefinitionFinderVisitor.prototype.visitAlternation = function (node) {\n        this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n    };\n    return InsideDefinitionFinderVisitor;\n}(gast_public_1.gast.GAstVisitor));\nfunction lookAheadSequenceFromAlternatives(altsDefs, k) {\n    function getOtherPaths(pathsAndSuffixes, filterIdx) {\n        return utils_1.reduce(pathsAndSuffixes, function (result, currPathsAndSuffixes, currIdx) {\n            if (currIdx !== filterIdx) {\n                var currPartialPaths = utils_1.map(currPathsAndSuffixes, function (singlePathAndSuffix) { return singlePathAndSuffix.partialPath; });\n                return result.concat(currPartialPaths);\n            }\n            return result;\n        }, []);\n    }\n    function isUniquePrefix(arr, item) {\n        return utils_1.find(arr, function (currOtherPath) {\n            return utils_1.every(item, function (currPathTok, idx) {\n                return currPathTok === currOtherPath[idx];\n            });\n        }) === undefined;\n    }\n    function initializeArrayOfArrays(size) {\n        var result = [];\n        for (var i = 0; i < size; i++) {\n            result.push([]);\n        }\n        return result;\n    }\n    var partialAlts = utils_1.map(altsDefs, function (currAlt) { return interpreter_1.possiblePathsFrom([currAlt], 1); });\n    var finalResult = initializeArrayOfArrays(partialAlts.length);\n    var newData = partialAlts;\n    // maxLookahead loop\n    for (var pathLength = 1; pathLength <= k; pathLength++) {\n        var currDataset = newData;\n        newData = initializeArrayOfArrays(currDataset.length);\n        // alternatives loop\n        for (var resultIdx = 0; resultIdx < currDataset.length; resultIdx++) {\n            var currAltPathsAndSuffixes = currDataset[resultIdx];\n            var otherPaths = getOtherPaths(currDataset, resultIdx);\n            // paths in current alternative loop\n            for (var currPathIdx = 0; currPathIdx < currAltPathsAndSuffixes.length; currPathIdx++) {\n                var currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n                var suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n                var isUnique = isUniquePrefix(otherPaths, currPathPrefix);\n                // even if a path is not unique, but there are no longer alternatives to try\n                // or if we have reached the maximum lookahead (k) permitted.\n                if (isUnique ||\n                    utils_1.isEmpty(suffixDef) ||\n                    currPathPrefix.length === k) {\n                    var currAltResult = finalResult[resultIdx];\n                    if (!containsPath(currAltResult, currPathPrefix)) {\n                        currAltResult.push(currPathPrefix);\n                    }\n                }\n                else {\n                    var newPartialPathsAndSuffixes = interpreter_1.possiblePathsFrom(suffixDef, pathLength + 1, currPathPrefix);\n                    newData[resultIdx] = newData[resultIdx].concat(newPartialPathsAndSuffixes);\n                }\n            }\n        }\n    }\n    return finalResult;\n}\nexports.lookAheadSequenceFromAlternatives = lookAheadSequenceFromAlternatives;\nfunction getLookaheadPathsForOr(occurrence, ruleGrammar, k) {\n    var visitor = new InsideDefinitionFinderVisitor(occurrence, PROD_TYPE.ALTERNATION);\n    ruleGrammar.accept(visitor);\n    return lookAheadSequenceFromAlternatives(visitor.result, k);\n}\nexports.getLookaheadPathsForOr = getLookaheadPathsForOr;\nfunction getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k) {\n    var insideDefVisitor = new InsideDefinitionFinderVisitor(occurrence, prodType);\n    ruleGrammar.accept(insideDefVisitor);\n    var insideDef = insideDefVisitor.result;\n    var afterDefWalker = new RestDefinitionFinderWalker(ruleGrammar, occurrence, prodType);\n    var afterDef = afterDefWalker.startWalking();\n    var insideFlat = new gast_public_1.gast.Flat(insideDef);\n    var afterFlat = new gast_public_1.gast.Flat(afterDef);\n    return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\nexports.getLookaheadPathsForOptionalProd = getLookaheadPathsForOptionalProd;\nfunction containsPath(alternative, path) {\n    var found = utils_1.find(alternative, function (otherPath) {\n        return path.length === otherPath.length &&\n            utils_1.every(path, function (targetItem, idx) {\n                return targetItem === otherPath[idx];\n            });\n    });\n    return found !== undefined;\n}\nexports.containsPath = containsPath;\n//# sourceMappingURL=lookahead.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/lookahead.js\n// module id = 15\n// module chunks = 0","\"use strict\";\n// needs a separate module as this is required inside chevrotain productive code\n// and also in the entry point for webpack(api.ts).\n// A separate file avoids cyclic dependencies and webpack errors.\nexports.VERSION = \"0.21.1\";\n//# sourceMappingURL=version.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/version.js\n// module id = 16\n// module chunks = 0","import { Parser, Lexer }  from \"chevrotain\";\n\nconst {\n    allTokens,\n    WhiteSpace,\n    Plus, Minus, Multi, Div,\n    LParen, RParen,\n    NumberLiteral,\n    AdditionOperator, MultiplicationOperator\n} = require(\"./tokens\");\n\nconst CalculatorLexer = new Lexer(allTokens);\n\n// ----------------- parser -----------------\nclass Calculator extends Parser {\n\tconstructor(input) {\n\t\tconsole.time(\"parser construction\");\n\t\tsuper(input, allTokens);\n\n\t\tvar $ = this;\n\n\t\t$.RULE(\"expression\", function() {\n\t\t\treturn $.SUBRULE($.additionExpression)\n\t\t});\n\n\t\t//  lowest precedence thus it is first in the rule chain\n\t\t// The precedence of binary expressions is determined by how far down the Parse Tree\n\t\t// The binary expression appears.\n\t\t$.RULE(\"additionExpression\", function() {\n\t\t\tvar value, op, rhsVal;\n\n\t\t\t// parsing part\n\t\t\tvalue = $.SUBRULE($.multiplicationExpression);\n\t\t\t$.MANY(function() {\n\t\t\t\t// consuming 'AdditionOperator' will consume either Plus or Minus as they are subclasses of AdditionOperator\n\t\t\t\top = $.CONSUME(AdditionOperator);\n\t\t\t\t//  the index \"2\" in SUBRULE2 is needed to identify the unique position in the grammar during runtime\n\t\t\t\trhsVal = $.SUBRULE2($.multiplicationExpression);\n\n\t\t\t\t// interpreter part\n\t\t\t\tif (op instanceof Plus) {\n\t\t\t\t\tvalue += rhsVal\n\t\t\t\t} else { // op instanceof Minus\n\t\t\t\t\tvalue -= rhsVal\n\t\t\t\t}\n\t\t\t});\n\n\t\t\treturn value\n\t\t});\n\n\n\t\t$.RULE(\"multiplicationExpression\", function() {\n\t\t\tvar value, op, rhsVal;\n\n\t\t\t// parsing part\n\t\t\tvalue = $.SUBRULE($.atomicExpression);\n\t\t\t$.MANY(function() {\n\t\t\t\top = $.CONSUME(MultiplicationOperator);\n\t\t\t\t//  the index \"2\" in SUBRULE2 is needed to identify the unique position in the grammar during runtime\n\t\t\t\trhsVal = $.SUBRULE2($.atomicExpression);\n\n\t\t\t\t// interpreter part\n\t\t\t\tif (op instanceof Multi) {\n\t\t\t\t\tvalue *= rhsVal\n\t\t\t\t} else { // op instanceof Div\n\t\t\t\t\tvalue /= rhsVal\n\t\t\t\t}\n\t\t\t});\n\n\t\t\treturn value\n\t\t});\n\n\n\t\t$.RULE(\"atomicExpression\", function() {\n\t\t\t// @formatter:off\n\t\t\t\treturn $.OR([\n\t\t\t\t\t// parenthesisExpression has the highest precedence and thus it appears\n\t\t\t\t\t// in the \"lowest\" leaf in the expression ParseTree.\n\t\t\t\t\t{ALT: function(){ return $.SUBRULE($.parenthesisExpression)}},\n\t\t\t\t\t{ALT: function(){ return parseInt($.CONSUME(NumberLiteral).image, 10)}}\n\t\t\t\t], \"a number or parenthesis expression\");\n\t\t\t\t// @formatter:on\n\t\t});\n\n\t\t$.RULE(\"parenthesisExpression\", function() {\n\t\t\tvar expValue;\n\n\t\t\t$.CONSUME(LParen);\n\t\t\texpValue = $.SUBRULE($.expression);\n\t\t\t$.CONSUME(RParen);\n\n\t\t\treturn expValue\n\t\t});\n\n\t\t// very important to call this after all the rules have been defined.\n\t\t// otherwise the parser may not work correctly as it will lack information\n\t\t// derived during the self analysis phase.\n\t\tParser.performSelfAnalysis(this);\n\t\tconsole.timeEnd(\"parser construction\");\n\t}\n\n\t// avoids inserting number literals as these can have multiple(and infinite) semantic values, thus it is unlikely\n\t// we can choose the correct number value to insert.\n\tcanTokenTypeBeInsertedInRecovery(tokClass) {\n\t\treturn tokClass !== NumberLiteral\n\t};\n}\n\n\n// wrapping it all togater\n// reuse the same parser instance.\nvar parser = new Calculator([]);\n\n\nexport default function calculator(text) {\n\tconsole.group(\"Parsing: '\"+ text + \"'\");\n\n\t// Tokenize input text\n    var lex = CalculatorLexer.tokenize(text);\n\n\t// Report lexer errors or success\n    if (lex.errors.length) {\n    \tconsole.group(\"Lexer errors\");\n    \tfor (let error of lex.errors) {\n    \t\tconsole.error(error);\n    \t}\n    \tconsole.groupEnd();\n    }\n    else {\n    \tconsole.info(\"Lexer passed with tokens:\", lex.tokens);\n    }\n\n    // Setting a new input will RESET the parser instance's state.\n    parser.input = lex.tokens;\n\n    // Parse the text.\n    // Note that any top level rule may be used as an entry point.\n    var value = parser.expression();\n\n\t// Report parser errors or success\n    if (parser.errors.length) {\n    \tconsole.group(\"Parser errors\");\n    \tfor (let error of parser.errors) {\n    \t\tconsole.error(error.name + \": \" + error.message + \"\\n\", error);\n    \t}\n    \tconsole.groupEnd();\n    }\n\telse {\n\t\tconsole.info(\"Parser returned value:\", value);\n\t}\n\n\tconsole.groupEnd();\n\n\treturn { value, lex, errors: parser.errors };\n};\n\n// DEBUG\nwindow.lexer = CalculatorLexer;\nwindow.calculator = calculator;\nwindow.parser = parser;\n\n\n\n// WEBPACK FOOTER //\n// ./calculator.js","import { Token, Lexer } from \"chevrotain\";\n\n// using the NA pattern marks this Token class as 'irrelevant' for the Lexer.\n// AdditionOperator defines a Tokens hierarchy but only the leafs in this hierarchy define\n// actual Tokens that can appear in the text\nexport class AdditionOperator extends Token {\n\tstatic PATTERN = Lexer.NA;\n}\nexport class Plus extends AdditionOperator {\n\tstatic PATTERN = /\\+/;\n}\nexport class Minus extends AdditionOperator {\n\tstatic PATTERN = /-/;\n}\n\nexport class MultiplicationOperator extends Token {\n\tstatic PATTERN = Lexer.NA\n}\nexport class Multi extends MultiplicationOperator {\n\tstatic PATTERN = /\\*/;\n}\nexport class Div extends MultiplicationOperator {\n\tstatic PATTERN = /\\//;\n}\n\nexport class LParen extends Token {\n\tstatic PATTERN = /\\(/;\n}\nexport class RParen extends Token {\n\tstatic PATTERN = /\\)/;\n}\nexport class NumberLiteral extends Token {\n\tstatic PATTERN = /\\d*(?:\\.\\d+)?/;\n}\n// marking WhiteSpace as 'SKIPPED' makes the lexer skip it.\nexport class WhiteSpace extends Token {\n\tstatic PATTERN = /\\s+/;\n\tstatic GROUP = Lexer.SKIPPED;\n}\n\nexport const allTokens = [WhiteSpace, // whitespace is normally very common so it should be placed first to speed up the lexer's performance\n    Plus, Minus, Multi, Div, LParen, RParen, NumberLiteral, AdditionOperator, MultiplicationOperator];\n\n\n\n// WEBPACK FOOTER //\n// ./tokens.js","\"use strict\";\nvar cache_1 = require(\"./cache\");\n/**\n * Clears the chevrotain internal cache.\n * This should not be used in regular work flows, This is intended for\n * unique use cases for example: online playground where the a parser with the same name is initialized with\n * different implementations multiple times.\n */\nfunction clearCache() {\n    cache_1.clearCache();\n}\nexports.clearCache = clearCache;\n//# sourceMappingURL=cache_public.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/cache_public.js\n// module id = 19\n// module chunks = 0","\"use strict\";\nvar range_1 = require(\"../text/range\");\nvar gast_public_1 = require(\"./grammar/gast_public\");\nvar utils_1 = require(\"../utils/utils\");\nvar ProdType;\n(function (ProdType) {\n    ProdType[ProdType[\"OPTION\"] = 0] = \"OPTION\";\n    ProdType[ProdType[\"OR\"] = 1] = \"OR\";\n    ProdType[ProdType[\"MANY\"] = 2] = \"MANY\";\n    ProdType[ProdType[\"MANY_SEP\"] = 3] = \"MANY_SEP\";\n    ProdType[ProdType[\"AT_LEAST_ONE\"] = 4] = \"AT_LEAST_ONE\";\n    ProdType[ProdType[\"AT_LEAST_ONE_SEP\"] = 5] = \"AT_LEAST_ONE_SEP\";\n    ProdType[ProdType[\"REF\"] = 6] = \"REF\";\n    ProdType[ProdType[\"TERMINAL\"] = 7] = \"TERMINAL\";\n    ProdType[ProdType[\"FLAT\"] = 8] = \"FLAT\";\n})(ProdType = exports.ProdType || (exports.ProdType = {}));\n// TODO: this regexp creates a constraint on names of Terminals (Tokens).\n// TODO: document and consider reducing the constraint by expanding the regexp\nvar terminalRegEx = /\\.\\s*CONSUME(\\d)?\\s*\\(\\s*(?:[a-zA-Z_$]\\w*\\s*\\.\\s*)*([a-zA-Z_$]\\w*)/;\nvar terminalRegGlobal = new RegExp(terminalRegEx.source, \"g\");\nvar refRegEx = /\\.\\s*SUBRULE(\\d)?\\s*\\(\\s*(?:[a-zA-Z_$]\\w*\\s*\\.\\s*)*([a-zA-Z_$]\\w*)/;\nvar refRegExGlobal = new RegExp(refRegEx.source, \"g\");\nvar optionRegEx = /\\.\\s*OPTION(\\d)?\\s*\\(/;\nvar optionRegExGlobal = new RegExp(optionRegEx.source, \"g\");\nvar manyRegEx = /\\.\\s*MANY(\\d)?\\s*\\(/;\nvar manyRegExGlobal = new RegExp(manyRegEx.source, \"g\");\nvar manyWithSeparatorRegEx = /\\.\\s*MANY_SEP(\\d)?\\s*\\(\\s*(?:[a-zA-Z_$]\\w*\\s*\\.\\s*)*([a-zA-Z_$]\\w*)/;\nvar manyWithSeparatorRegExGlobal = new RegExp(manyWithSeparatorRegEx.source, \"g\");\nvar atLeastOneWithSeparatorRegEx = /\\.\\s*AT_LEAST_ONE_SEP(\\d)?\\s*\\(\\s*(?:[a-zA-Z_$]\\w*\\s*\\.\\s*)*([a-zA-Z_$]\\w*)/;\nvar atLeastOneWithSeparatorRegExGlobal = new RegExp(atLeastOneWithSeparatorRegEx.source, \"g\");\nvar atLeastOneRegEx = /\\.\\s*AT_LEAST_ONE(\\d)?\\s*\\(/;\nvar atLeastOneRegExGlobal = new RegExp(atLeastOneRegEx.source, \"g\");\nvar orRegEx = /\\.\\s*OR(\\d)?\\s*\\(/;\nvar orRegExGlobal = new RegExp(orRegEx.source, \"g\");\nvar orPartRegEx = /\\s*(ALT)\\s*:/g;\nexports.terminalNameToConstructor = {};\nfunction buildTopProduction(impelText, name, terminals) {\n    // pseudo state. so little state does not yet mandate the complexity of wrapping in a class...\n    // TODO: this is confusing, might be time to create a class..\n    exports.terminalNameToConstructor = terminals;\n    // the top most range must strictly contain all the other ranges\n    // which is why we prefix the text with \" \" (curr Range impel is only for positive ranges)\n    var spacedImpelText = \" \" + impelText;\n    // TODO: why do we add whitespace twice?\n    var txtWithoutComments = removeComments(\" \" + spacedImpelText);\n    var textWithoutCommentsAndStrings = removeStringLiterals(txtWithoutComments);\n    var prodRanges = createRanges(textWithoutCommentsAndStrings);\n    var topRange = new range_1.Range(0, impelText.length + 2);\n    return buildTopLevel(name, topRange, prodRanges, impelText);\n}\nexports.buildTopProduction = buildTopProduction;\nfunction buildTopLevel(name, topRange, allRanges, orgText) {\n    var topLevelProd = new gast_public_1.gast.Rule(name, [], orgText);\n    return buildAbstractProd(topLevelProd, topRange, allRanges);\n}\nfunction buildProdGast(prodRange, allRanges) {\n    \"use strict\";\n    switch (prodRange.type) {\n        case ProdType.AT_LEAST_ONE:\n            return buildAtLeastOneProd(prodRange, allRanges);\n        case ProdType.AT_LEAST_ONE_SEP:\n            return buildAtLeastOneSepProd(prodRange, allRanges);\n        case ProdType.MANY_SEP:\n            return buildManySepProd(prodRange, allRanges);\n        case ProdType.MANY:\n            return buildManyProd(prodRange, allRanges);\n        case ProdType.OPTION:\n            return buildOptionProd(prodRange, allRanges);\n        case ProdType.OR:\n            return buildOrProd(prodRange, allRanges);\n        case ProdType.FLAT:\n            return buildAbstractProd(new gast_public_1.gast.Flat([]), prodRange.range, allRanges);\n        case ProdType.REF:\n            return buildRefProd(prodRange);\n        case ProdType.TERMINAL:\n            return buildTerminalProd(prodRange);\n        /* istanbul ignore next */\n        default:\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n    }\n}\nexports.buildProdGast = buildProdGast;\nfunction buildRefProd(prodRange) {\n    var reResult = refRegEx.exec(prodRange.text);\n    var isImplicitOccurrenceIdx = reResult[1] === undefined;\n    var refOccurrence = isImplicitOccurrenceIdx ? 1 : parseInt(reResult[1], 10);\n    var refProdName = reResult[2];\n    var newRef = new gast_public_1.gast.NonTerminal(refProdName, undefined, refOccurrence);\n    newRef.implicitOccurrenceIndex = isImplicitOccurrenceIdx;\n    return newRef;\n}\nfunction buildTerminalProd(prodRange) {\n    var reResult = terminalRegEx.exec(prodRange.text);\n    var isImplicitOccurrenceIdx = reResult[1] === undefined;\n    var terminalOccurrence = isImplicitOccurrenceIdx ? 1 : parseInt(reResult[1], 10);\n    var terminalName = reResult[2];\n    var terminalType = exports.terminalNameToConstructor[terminalName];\n    if (!terminalType) {\n        throw Error(\"Terminal Token name: \" + terminalName + \" not found\");\n    }\n    var newTerminal = new gast_public_1.gast.Terminal(terminalType, terminalOccurrence);\n    newTerminal.implicitOccurrenceIndex = isImplicitOccurrenceIdx;\n    return newTerminal;\n}\nfunction buildProdWithOccurrence(regEx, prodInstance, prodRange, allRanges) {\n    var reResult = regEx.exec(prodRange.text);\n    var isImplicitOccurrenceIdx = reResult[1] === undefined;\n    prodInstance.occurrenceInParent = isImplicitOccurrenceIdx ? 1 : parseInt(reResult[1], 10);\n    prodInstance.implicitOccurrenceIndex = isImplicitOccurrenceIdx;\n    // <any> due to intellij bugs\n    return buildAbstractProd(prodInstance, prodRange.range, allRanges);\n}\nfunction buildAtLeastOneProd(prodRange, allRanges) {\n    return buildProdWithOccurrence(atLeastOneRegEx, new gast_public_1.gast.RepetitionMandatory([]), prodRange, allRanges);\n}\nfunction buildAtLeastOneSepProd(prodRange, allRanges) {\n    return buildRepetitionWithSep(prodRange, allRanges, gast_public_1.gast.RepetitionMandatoryWithSeparator, atLeastOneWithSeparatorRegEx);\n}\nfunction buildManyProd(prodRange, allRanges) {\n    return buildProdWithOccurrence(manyRegEx, new gast_public_1.gast.Repetition([]), prodRange, allRanges);\n}\nfunction buildManySepProd(prodRange, allRanges) {\n    return buildRepetitionWithSep(prodRange, allRanges, gast_public_1.gast.RepetitionWithSeparator, manyWithSeparatorRegEx);\n}\nfunction buildRepetitionWithSep(prodRange, allRanges, repConstructor, regExp) {\n    var reResult = regExp.exec(prodRange.text);\n    var isImplicitOccurrenceIdx = reResult[1] === undefined;\n    var occurrenceIdx = isImplicitOccurrenceIdx ? 1 : parseInt(reResult[1], 10);\n    var sepName = reResult[2];\n    var separatorType = exports.terminalNameToConstructor[sepName];\n    if (!separatorType) {\n        throw Error(\"Separator Terminal Token name: \" + sepName + \" not found\");\n    }\n    var repetitionInstance = new repConstructor([], separatorType, occurrenceIdx);\n    repetitionInstance.implicitOccurrenceIndex = isImplicitOccurrenceIdx;\n    return buildAbstractProd(repetitionInstance, prodRange.range, allRanges);\n}\nfunction buildOptionProd(prodRange, allRanges) {\n    return buildProdWithOccurrence(optionRegEx, new gast_public_1.gast.Option([]), prodRange, allRanges);\n}\nfunction buildOrProd(prodRange, allRanges) {\n    return buildProdWithOccurrence(orRegEx, new gast_public_1.gast.Alternation([]), prodRange, allRanges);\n}\nfunction buildAbstractProd(prod, topLevelRange, allRanges) {\n    var secondLevelProds = getDirectlyContainedRanges(topLevelRange, allRanges);\n    var secondLevelInOrder = utils_1.sortBy(secondLevelProds, function (prodRng) { return prodRng.range.start; });\n    var definition = [];\n    utils_1.forEach(secondLevelInOrder, function (prodRng) {\n        definition.push(buildProdGast(prodRng, allRanges));\n    });\n    prod.definition = definition;\n    return prod;\n}\nfunction getDirectlyContainedRanges(y, prodRanges) {\n    return utils_1.filter(prodRanges, function (x) {\n        var isXDescendantOfY = y.strictlyContainsRange(x.range);\n        var xDoesNotHaveAnyAncestorWhichIsDecendantOfY = utils_1.every(prodRanges, function (maybeAnotherParent) {\n            var isParentOfX = maybeAnotherParent.range.strictlyContainsRange(x.range);\n            var isChildOfY = maybeAnotherParent.range.isStrictlyContainedInRange(y);\n            return !(isParentOfX && isChildOfY);\n        });\n        return isXDescendantOfY && xDoesNotHaveAnyAncestorWhichIsDecendantOfY;\n    });\n}\nexports.getDirectlyContainedRanges = getDirectlyContainedRanges;\nvar singleLineCommentRegEx = /\\/\\/.*/g;\nvar multiLineCommentRegEx = /\\/\\*([^*]|[\\r\\n]|(\\*+([^*/]|[\\r\\n])))*\\*+\\//g;\nvar doubleQuoteStringLiteralRegEx = /\"([^\\\\\"]+|\\\\([bfnrtv\"\\\\/]|u[0-9a-fA-F]{4}))*\"/g;\nvar singleQuoteStringLiteralRegEx = /'([^\\\\']+|\\\\([bfnrtv'\\\\/]|u[0-9a-fA-F]{4}))*'/g;\nfunction removeComments(text) {\n    var noSingleLine = text.replace(singleLineCommentRegEx, \"\");\n    var noComments = noSingleLine.replace(multiLineCommentRegEx, \"\");\n    return noComments;\n}\nexports.removeComments = removeComments;\nfunction removeStringLiterals(text) {\n    var noDoubleQuotes = text.replace(doubleQuoteStringLiteralRegEx, \"\");\n    var noSingleQuotes = noDoubleQuotes.replace(singleQuoteStringLiteralRegEx, \"\");\n    return noSingleQuotes;\n}\nexports.removeStringLiterals = removeStringLiterals;\nfunction createRanges(text) {\n    var terminalRanges = createTerminalRanges(text);\n    var refsRanges = createRefsRanges(text);\n    var atLeastOneRanges = createAtLeastOneRanges(text);\n    var atLeastOneSepRanges = createAtLeastOneSepRanges(text);\n    var manyRanges = createManyRanges(text);\n    var manySepRanges = createManySepRanges(text);\n    var optionRanges = createOptionRanges(text);\n    var orRanges = createOrRanges(text);\n    return [].concat(terminalRanges, refsRanges, atLeastOneRanges, atLeastOneSepRanges, manyRanges, manySepRanges, optionRanges, orRanges);\n}\nexports.createRanges = createRanges;\nfunction createTerminalRanges(text) {\n    return createRefOrTerminalProdRangeInternal(text, ProdType.TERMINAL, terminalRegGlobal);\n}\nexports.createTerminalRanges = createTerminalRanges;\nfunction createRefsRanges(text) {\n    return createRefOrTerminalProdRangeInternal(text, ProdType.REF, refRegExGlobal);\n}\nexports.createRefsRanges = createRefsRanges;\nfunction createAtLeastOneRanges(text) {\n    return createOperatorProdRangeParenthesis(text, ProdType.AT_LEAST_ONE, atLeastOneRegExGlobal);\n}\nexports.createAtLeastOneRanges = createAtLeastOneRanges;\nfunction createAtLeastOneSepRanges(text) {\n    return createOperatorProdRangeParenthesis(text, ProdType.AT_LEAST_ONE_SEP, atLeastOneWithSeparatorRegExGlobal);\n}\nexports.createAtLeastOneSepRanges = createAtLeastOneSepRanges;\nfunction createManyRanges(text) {\n    return createOperatorProdRangeParenthesis(text, ProdType.MANY, manyRegExGlobal);\n}\nexports.createManyRanges = createManyRanges;\nfunction createManySepRanges(text) {\n    return createOperatorProdRangeParenthesis(text, ProdType.MANY_SEP, manyWithSeparatorRegExGlobal);\n}\nexports.createManySepRanges = createManySepRanges;\nfunction createOptionRanges(text) {\n    return createOperatorProdRangeParenthesis(text, ProdType.OPTION, optionRegExGlobal);\n}\nexports.createOptionRanges = createOptionRanges;\nfunction createOrRanges(text) {\n    var orRanges = createOperatorProdRangeParenthesis(text, ProdType.OR, orRegExGlobal);\n    // have to split up the OR cases into separate FLAT productions\n    // (A |BB | CDE) ==> or.def[0] --> FLAT(A) , or.def[1] --> FLAT(BB) , or.def[2] --> FLAT(CCDE)\n    var orSubPartsRanges = createOrPartRanges(orRanges);\n    return orRanges.concat(orSubPartsRanges);\n}\nexports.createOrRanges = createOrRanges;\nvar findClosingCurly = utils_1.partial(findClosingOffset, \"{\", \"}\");\nvar findClosingParen = utils_1.partial(findClosingOffset, \"(\", \")\");\nfunction createOrPartRanges(orRanges) {\n    var orPartRanges = [];\n    utils_1.forEach(orRanges, function (orRange) {\n        var currOrParts = createOperatorProdRangeInternal(orRange.text, ProdType.FLAT, orPartRegEx, findClosingCurly);\n        var currOrRangeStart = orRange.range.start;\n        // fix offsets as we are working on a subset of the text\n        utils_1.forEach(currOrParts, function (orPart) {\n            orPart.range.start += currOrRangeStart;\n            orPart.range.end += currOrRangeStart;\n        });\n        orPartRanges = orPartRanges.concat(currOrParts);\n    });\n    var uniqueOrPartRanges = utils_1.uniq(orPartRanges, function (prodRange) {\n        // using \"~\" as a separator for the identify function as its not a valid char in javascript\n        return prodRange.type + \"~\" + prodRange.range.start + \"~\" + prodRange.range.end + \"~\" + prodRange.text;\n    });\n    return uniqueOrPartRanges;\n}\nexports.createOrPartRanges = createOrPartRanges;\nfunction createRefOrTerminalProdRangeInternal(text, prodType, pattern) {\n    var prodRanges = [];\n    var matched;\n    while (matched = pattern.exec(text)) {\n        var start = matched.index;\n        var stop = pattern.lastIndex;\n        var currRange = new range_1.Range(start, stop);\n        var currText = matched[0];\n        prodRanges.push({ range: currRange, text: currText, type: prodType });\n    }\n    return prodRanges;\n}\nfunction createOperatorProdRangeParenthesis(text, prodType, pattern) {\n    return createOperatorProdRangeInternal(text, prodType, pattern, findClosingParen);\n}\nfunction createOperatorProdRangeInternal(text, prodType, pattern, findTerminatorOffSet) {\n    var operatorRanges = [];\n    var matched;\n    while (matched = pattern.exec(text)) {\n        var start = matched.index;\n        // note that (start + matched[0].length) is the first character AFTER the match\n        var stop = findTerminatorOffSet(start + matched[0].length, text);\n        var currRange = new range_1.Range(start, stop);\n        var currText = text.substr(start, stop - start + 1);\n        operatorRanges.push({ range: currRange, text: currText, type: prodType });\n    }\n    return operatorRanges;\n}\nfunction findClosingOffset(opening, closing, start, text) {\n    var parenthesisStack = [1];\n    var i = -1;\n    while (!(utils_1.isEmpty(parenthesisStack)) && i + start < text.length) {\n        i++;\n        var nextChar = text.charAt(start + i);\n        if (nextChar === opening) {\n            parenthesisStack.push(1);\n        }\n        else if (nextChar === closing) {\n            parenthesisStack.pop();\n        }\n    }\n    // valid termination of the search loop\n    if (utils_1.isEmpty(parenthesisStack)) {\n        return i + start;\n    }\n    else {\n        throw new Error(\"INVALID INPUT TEXT, UNTERMINATED PARENTHESIS\");\n    }\n}\nexports.findClosingOffset = findClosingOffset;\n//# sourceMappingURL=gast_builder.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/gast_builder.js\n// module id = 20\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\nvar utils = require(\"../../utils/utils\");\nvar utils_1 = require(\"../../utils/utils\");\nvar parser_public_1 = require(\"../parser_public\");\nvar gast_public_1 = require(\"./gast_public\");\nvar gast_1 = require(\"./gast\");\nvar tokens_public_1 = require(\"../../scan/tokens_public\");\nvar first_1 = require(\"./first\");\nvar lookahead_1 = require(\"./lookahead\");\nvar version_1 = require(\"../../version\");\nvar utils_2 = require(\"../../utils/utils\");\nvar utils_3 = require(\"../../utils/utils\");\nfunction validateGrammar(topLevels, maxLookahead, ignoredIssues) {\n    var duplicateErrors = utils.map(topLevels, validateDuplicateProductions);\n    var leftRecursionErrors = utils.map(topLevels, function (currTopRule) { return validateNoLeftRecursion(currTopRule, currTopRule); });\n    var emptyAltErrors = [];\n    var ambiguousAltsErrors = [];\n    // left recursion could cause infinite loops in the following validations.\n    // It is safest to first have the user fix the left recursion errors first and only then examine farther issues.\n    if (utils_3.every(leftRecursionErrors, utils_2.isEmpty)) {\n        emptyAltErrors = utils_1.map(topLevels, validateEmptyOrAlternative);\n        ambiguousAltsErrors = utils_1.map(topLevels, function (currTopRule) {\n            return validateAmbiguousAlternationAlternatives(currTopRule, maxLookahead, ignoredIssues);\n        });\n    }\n    return utils.flatten(duplicateErrors.concat(leftRecursionErrors, emptyAltErrors, ambiguousAltsErrors));\n}\nexports.validateGrammar = validateGrammar;\nfunction validateDuplicateProductions(topLevelRule) {\n    var collectorVisitor = new OccurrenceValidationCollector();\n    topLevelRule.accept(collectorVisitor);\n    var allRuleProductions = collectorVisitor.allProductions;\n    var productionGroups = utils.groupBy(allRuleProductions, identifyProductionForDuplicates);\n    var duplicates = utils.pick(productionGroups, function (currGroup) {\n        return currGroup.length > 1;\n    });\n    var errors = utils.map(utils.values(duplicates), function (currDuplicates) {\n        var firstProd = utils.first(currDuplicates);\n        var msg = createDuplicatesErrorMessage(currDuplicates, topLevelRule.name);\n        var dslName = gast_1.getProductionDslName(firstProd);\n        var defError = {\n            message: msg,\n            type: parser_public_1.ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n            ruleName: topLevelRule.name,\n            dslName: dslName,\n            occurrence: firstProd.occurrenceInParent\n        };\n        var param = getExtraProductionArgument(firstProd);\n        if (param) {\n            defError.parameter = param;\n        }\n        return defError;\n    });\n    return errors;\n}\nfunction createDuplicatesErrorMessage(duplicateProds, topLevelName) {\n    var firstProd = utils.first(duplicateProds);\n    var index = firstProd.occurrenceInParent;\n    var dslName = gast_1.getProductionDslName(firstProd);\n    var extraArgument = getExtraProductionArgument(firstProd);\n    var msg = \"->\" + dslName + \"<- with occurrence index: ->\" + index + \"<-\\n                  \" + (extraArgument ? \"and argument: \" + extraArgument : \"\") + \"\\n                  appears more than once (\" + duplicateProds.length + \" times) in the top level rule: \" + topLevelName + \".\\n                  \" + (index === 1 ? \"note that \" + dslName + \" and \" + dslName + \"1 both have the same occurrence index 1}\" : \"\") + \"}\\n                  to fix this make sure each usage of \" + dslName + \" \" + (extraArgument ? \"with the argument: \" + extraArgument : \"\") + \"\\n                  in the rule \" + topLevelName + \" has a different occurrence index (1-5), as that combination acts as a unique\\n                  position key in the grammar, which is needed by the parsing engine.\";\n    // white space trimming time! better to trim afterwards as it allows to use WELL formatted multi line template strings...\n    msg = msg.replace(/[ \\t]+/g, \" \");\n    msg = msg.replace(/\\s\\s+/g, \"\\n\");\n    return msg;\n}\nfunction identifyProductionForDuplicates(prod) {\n    return gast_1.getProductionDslName(prod) + \"_#_\" + prod.occurrenceInParent + \"_#_\" + getExtraProductionArgument(prod);\n}\nexports.identifyProductionForDuplicates = identifyProductionForDuplicates;\nfunction getExtraProductionArgument(prod) {\n    if (prod instanceof gast_public_1.gast.Terminal) {\n        return tokens_public_1.tokenName(prod.terminalType);\n    }\n    else if (prod instanceof gast_public_1.gast.NonTerminal) {\n        return prod.nonTerminalName;\n    }\n    else {\n        return \"\";\n    }\n}\nvar OccurrenceValidationCollector = (function (_super) {\n    __extends(OccurrenceValidationCollector, _super);\n    function OccurrenceValidationCollector() {\n        var _this = _super.apply(this, arguments) /* istanbul ignore next */ || this;\n        _this.allProductions = [];\n        return _this;\n    }\n    OccurrenceValidationCollector.prototype.visitNonTerminal = function (subrule) {\n        this.allProductions.push(subrule);\n    };\n    OccurrenceValidationCollector.prototype.visitOption = function (option) {\n        this.allProductions.push(option);\n    };\n    OccurrenceValidationCollector.prototype.visitRepetitionWithSeparator = function (manySep) {\n        this.allProductions.push(manySep);\n    };\n    OccurrenceValidationCollector.prototype.visitRepetitionMandatory = function (atLeastOne) {\n        this.allProductions.push(atLeastOne);\n    };\n    OccurrenceValidationCollector.prototype.visitRepetitionMandatoryWithSeparator = function (atLeastOneSep) {\n        this.allProductions.push(atLeastOneSep);\n    };\n    OccurrenceValidationCollector.prototype.visitRepetition = function (many) {\n        this.allProductions.push(many);\n    };\n    OccurrenceValidationCollector.prototype.visitAlternation = function (or) {\n        this.allProductions.push(or);\n    };\n    OccurrenceValidationCollector.prototype.visitTerminal = function (terminal) {\n        this.allProductions.push(terminal);\n    };\n    return OccurrenceValidationCollector;\n}(gast_public_1.gast.GAstVisitor));\nexports.OccurrenceValidationCollector = OccurrenceValidationCollector;\nvar ruleNamePattern = /^[a-zA-Z_]\\w*$/;\nfunction validateRuleName(ruleName, className) {\n    var errors = [];\n    var errMsg;\n    if (!ruleName.match(ruleNamePattern)) {\n        errMsg = \"Invalid Grammar rule name: ->\" + ruleName + \"<- it must match the pattern: ->\" + ruleNamePattern.toString() + \"<-\";\n        errors.push({\n            message: errMsg,\n            type: parser_public_1.ParserDefinitionErrorType.INVALID_RULE_NAME,\n            ruleName: ruleName\n        });\n    }\n    return errors;\n}\nexports.validateRuleName = validateRuleName;\nfunction validateRuleDoesNotAlreadyExist(ruleName, definedRulesNames, className) {\n    var errors = [];\n    var errMsg;\n    if ((utils.contains(definedRulesNames, ruleName))) {\n        errMsg = \"Duplicate definition, rule: ->\" + ruleName + \"<- is already defined in the grammar: ->\" + className + \"<-\";\n        errors.push({\n            message: errMsg,\n            type: parser_public_1.ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n            ruleName: ruleName\n        });\n    }\n    return errors;\n}\nexports.validateRuleDoesNotAlreadyExist = validateRuleDoesNotAlreadyExist;\n// TODO: is there anyway to get only the rule names of rules inherited from the super grammars?\nfunction validateRuleIsOverridden(ruleName, definedRulesNames, className) {\n    var errors = [];\n    var errMsg;\n    if (!(utils.contains(definedRulesNames, ruleName))) {\n        errMsg = \"Invalid rule override, rule: ->\" + ruleName + \"<- cannot be overridden in the grammar: ->\" + className + \"<-\" +\n            \"as it is not defined in any of the super grammars \";\n        errors.push({\n            message: errMsg,\n            type: parser_public_1.ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n            ruleName: ruleName\n        });\n    }\n    return errors;\n}\nexports.validateRuleIsOverridden = validateRuleIsOverridden;\nfunction validateNoLeftRecursion(topRule, currRule, path) {\n    if (path === void 0) { path = []; }\n    var errors = [];\n    var nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n    if (utils.isEmpty(nextNonTerminals)) {\n        return [];\n    }\n    else {\n        var ruleName = topRule.name;\n        var foundLeftRecursion = utils.contains(nextNonTerminals, topRule);\n        var pathNames = utils.map(path, function (currRule) { return currRule.name; });\n        var leftRecursivePath = ruleName + \" --> \" + pathNames.concat([ruleName]).join(\" --> \");\n        if (foundLeftRecursion) {\n            var errMsg = \"Left Recursion found in grammar.\\n\" +\n                (\"rule: <\" + ruleName + \"> can be invoked from itself (directly or indirectly)\\n\") +\n                (\"without consuming any Tokens. The grammar path that causes this is: \\n \" + leftRecursivePath + \"\\n\") +\n                \" To fix this refactor your grammar to remove the left recursion.\\n\" +\n                \"see: https://en.wikipedia.org/wiki/LL_parser#Left_Factoring.\";\n            errors.push({\n                message: errMsg,\n                type: parser_public_1.ParserDefinitionErrorType.LEFT_RECURSION,\n                ruleName: ruleName\n            });\n        }\n        // we are only looking for cyclic paths leading back to the specific topRule\n        // other cyclic paths are ignored, we still need this difference to avoid infinite loops...\n        var validNextSteps = utils.difference(nextNonTerminals, path.concat([topRule]));\n        var errorsFromNextSteps = utils.map(validNextSteps, function (currRefRule) {\n            var newPath = utils.cloneArr(path);\n            newPath.push(currRefRule);\n            return validateNoLeftRecursion(topRule, currRefRule, newPath);\n        });\n        return errors.concat(utils.flatten(errorsFromNextSteps));\n    }\n}\nexports.validateNoLeftRecursion = validateNoLeftRecursion;\nfunction getFirstNoneTerminal(definition) {\n    var result = [];\n    if (utils.isEmpty(definition)) {\n        return result;\n    }\n    var firstProd = utils.first(definition);\n    if (firstProd instanceof gast_public_1.gast.NonTerminal) {\n        result.push(firstProd.referencedRule);\n    }\n    else if (firstProd instanceof gast_public_1.gast.Flat ||\n        firstProd instanceof gast_public_1.gast.Option ||\n        firstProd instanceof gast_public_1.gast.RepetitionMandatory ||\n        firstProd instanceof gast_public_1.gast.RepetitionMandatoryWithSeparator ||\n        firstProd instanceof gast_public_1.gast.RepetitionWithSeparator ||\n        firstProd instanceof gast_public_1.gast.Repetition) {\n        result = result.concat(getFirstNoneTerminal(firstProd.definition));\n    }\n    else if (firstProd instanceof gast_public_1.gast.Alternation) {\n        // each sub definition in alternation is a FLAT\n        result = utils.flatten(utils.map(firstProd.definition, function (currSubDef) { return getFirstNoneTerminal(currSubDef.definition); }));\n    }/* istanbul ignore else */ \n    else if (firstProd instanceof gast_public_1.gast.Terminal) {\n    }\n    else {\n        /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n    }\n    var isFirstOptional = gast_1.isOptionalProd(firstProd);\n    var hasMore = definition.length > 1;\n    if (isFirstOptional && hasMore) {\n        var rest = utils.drop(definition);\n        return result.concat(getFirstNoneTerminal(rest));\n    }\n    else {\n        return result;\n    }\n}\nexports.getFirstNoneTerminal = getFirstNoneTerminal;\nvar OrCollector = (function (_super) {\n    __extends(OrCollector, _super);\n    function OrCollector() {\n        var _this = _super.apply(this, arguments) /* istanbul ignore next */ || this;\n        _this.alternations = [];\n        return _this;\n    }\n    OrCollector.prototype.visitAlternation = function (node) {\n        this.alternations.push(node);\n    };\n    return OrCollector;\n}(gast_public_1.gast.GAstVisitor));\nfunction validateEmptyOrAlternative(topLevelRule) {\n    var orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    var ors = orCollector.alternations;\n    var errors = utils.reduce(ors, function (errors, currOr) {\n        var exceptLast = utils.dropRight(currOr.definition);\n        var currErrors = utils.map(exceptLast, function (currAlternative, currAltIdx) {\n            if (utils.isEmpty(first_1.first(currAlternative))) {\n                return {\n                    message: \"Ambiguous empty alternative: <\" + (currAltIdx + 1) + \">\" +\n                        (\" in <OR\" + currOr.occurrenceInParent + \"> inside <\" + topLevelRule.name + \"> Rule.\\n\") +\n                        \"Only the last alternative may be an empty alternative.\",\n                    type: parser_public_1.ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n                    ruleName: topLevelRule.name,\n                    occurrence: currOr.occurrenceInParent,\n                    alternative: currAltIdx + 1\n                };\n            }\n            else {\n                return null;\n            }\n        });\n        return errors.concat(utils.compact(currErrors));\n    }, []);\n    return errors;\n}\nexports.validateEmptyOrAlternative = validateEmptyOrAlternative;\nfunction validateAmbiguousAlternationAlternatives(topLevelRule, maxLookahead, ignoredIssues) {\n    var orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    var ors = orCollector.alternations;\n    var ignoredIssuesForCurrentRule = ignoredIssues[topLevelRule.name];\n    if (ignoredIssuesForCurrentRule) {\n        ors = utils_1.reject(ors, function (currOr) { return ignoredIssuesForCurrentRule[gast_1.getProductionDslName(currOr) + currOr.occurrenceInParent]; });\n    }\n    var errors = utils.reduce(ors, function (result, currOr) {\n        var currOccurrence = currOr.occurrenceInParent;\n        var alternatives = lookahead_1.getLookaheadPathsForOr(currOccurrence, topLevelRule, maxLookahead);\n        var altsAmbiguityErrors = checkAlternativesAmbiguities(alternatives);\n        var currErrors = utils.map(altsAmbiguityErrors, function (currAmbDescriptor) {\n            var ambgIndices = utils_1.map(currAmbDescriptor.alts, function (currAltIdx) { return currAltIdx + 1; });\n            var pathMsg = utils_1.map(currAmbDescriptor.path, function (currtok) { return tokens_public_1.tokenLabel(currtok); }).join(\", \");\n            var currMessage = \"Ambiguous alternatives: <\" + ambgIndices.join(\" ,\") + \"> in <OR\" + currOccurrence + \">\" +\n                (\" inside <\" + topLevelRule.name + \"> Rule,\\n\") +\n                (\"<\" + pathMsg + \"> may appears as a prefix path in all these alternatives.\\n\");\n            var docs_version = version_1.VERSION.replace(/\\./g, \"_\");\n            // Should this information be on the error message or in some common errors docs?\n            currMessage = currMessage + \"To Resolve this, try one of of the following: \\n\" +\n                \"1. Refactor your grammar to be LL(K) for the current value of k (by default k=5)\\n\" +\n                \"2. Increase the value of K for your grammar by providing a larger 'maxLookahead' value in the parser's config\\n\" +\n                \"3. This issue can be ignored (if you know what you are doing...), see\" +\n                \" http://sap.github.io/chevrotain/documentation/\" + docs_version + \"/interfaces/iparserconfig.html#ignoredissues for more\" +\n                \" details\\n\";\n            return {\n                message: currMessage,\n                type: parser_public_1.ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n                ruleName: topLevelRule.name,\n                occurrence: currOr.occurrenceInParent,\n                alternatives: [currAmbDescriptor.alts]\n            };\n        });\n        return result.concat(currErrors);\n    }, []);\n    return errors;\n}\nexports.validateAmbiguousAlternationAlternatives = validateAmbiguousAlternationAlternatives;\nfunction checkAlternativesAmbiguities(alternatives) {\n    var foundAmbiguousPaths = [];\n    var identicalAmbiguities = utils_1.reduce(alternatives, function (result, currAlt, currAltIdx) {\n        utils_1.forEach(currAlt, function (currPath) {\n            var altsCurrPathAppearsIn = [currAltIdx];\n            utils_1.forEach(alternatives, function (currOtherAlt, currOtherAltIdx) {\n                if (currAltIdx !== currOtherAltIdx && lookahead_1.containsPath(currOtherAlt, currPath)) {\n                    altsCurrPathAppearsIn.push(currOtherAltIdx);\n                }\n            });\n            if (altsCurrPathAppearsIn.length > 1 && !lookahead_1.containsPath(foundAmbiguousPaths, currPath)) {\n                foundAmbiguousPaths.push(currPath);\n                result.push({\n                    alts: altsCurrPathAppearsIn,\n                    path: currPath\n                });\n            }\n        });\n        return result;\n    }, []);\n    return identicalAmbiguities;\n}\n//# sourceMappingURL=checks.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/checks.js\n// module id = 21\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\nvar rest_1 = require(\"./rest\");\nvar lang_extensions_1 = require(\"../../lang/lang_extensions\");\nvar gast_public_1 = require(\"./gast_public\");\nvar first_1 = require(\"./first\");\nvar utils_1 = require(\"../../utils/utils\");\nvar constants_1 = require(\"../constants\");\nvar tokens_public_1 = require(\"../../scan/tokens_public\");\n// This ResyncFollowsWalker computes all of the follows required for RESYNC\n// (skipping reference production).\nvar ResyncFollowsWalker = (function (_super) {\n    __extends(ResyncFollowsWalker, _super);\n    function ResyncFollowsWalker(topProd) {\n        var _this = _super.call(this) || this;\n        _this.topProd = topProd;\n        _this.follows = new lang_extensions_1.HashTable();\n        return _this;\n    }\n    ResyncFollowsWalker.prototype.startWalking = function () {\n        this.walk(this.topProd);\n        return this.follows;\n    };\n    ResyncFollowsWalker.prototype.walkTerminal = function (terminal, currRest, prevRest) {\n        // do nothing! just like in the public sector after 13:00\n    };\n    ResyncFollowsWalker.prototype.walkProdRef = function (refProd, currRest, prevRest) {\n        var followName = buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.occurrenceInParent) + this.topProd.name;\n        var fullRest = currRest.concat(prevRest);\n        var restProd = new gast_public_1.gast.Flat(fullRest);\n        var t_in_topProd_follows = first_1.first(restProd);\n        this.follows.put(followName, t_in_topProd_follows);\n    };\n    return ResyncFollowsWalker;\n}(rest_1.RestWalker));\nexports.ResyncFollowsWalker = ResyncFollowsWalker;\nfunction computeAllProdsFollows(topProductions) {\n    var reSyncFollows = new lang_extensions_1.HashTable();\n    utils_1.forEach(topProductions, function (topProd) {\n        var currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n        reSyncFollows.putAll(currRefsFollow);\n    });\n    return reSyncFollows;\n}\nexports.computeAllProdsFollows = computeAllProdsFollows;\nfunction buildBetweenProdsFollowPrefix(inner, occurenceInParent) {\n    return inner.name + occurenceInParent + constants_1.IN;\n}\nexports.buildBetweenProdsFollowPrefix = buildBetweenProdsFollowPrefix;\nfunction buildInProdFollowPrefix(terminal) {\n    var terminalName = tokens_public_1.tokenName(terminal.terminalType);\n    return terminalName + terminal.occurrenceInParent + constants_1.IN;\n}\nexports.buildInProdFollowPrefix = buildInProdFollowPrefix;\n//# sourceMappingURL=follow.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/follow.js\n// module id = 22\n// module chunks = 0","\"use strict\";\nvar __extends = (this && this.__extends) || function (d, b) {\n    for (var p in b) /* istanbul ignore next */  if (b.hasOwnProperty(p)) d[p] = b[p];\n    function __() { this.constructor = d; }\n    /* istanbul ignore next */  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n};\nvar parser_public_1 = require(\"../parser_public\");\nvar gast_public_1 = require(\"./gast_public\");\nvar utils_1 = require(\"../../utils/utils\");\nfunction resolveGrammar(topLevels) {\n    var refResolver = new GastRefResolverVisitor(topLevels);\n    refResolver.resolveRefs();\n    return refResolver.errors;\n}\nexports.resolveGrammar = resolveGrammar;\nvar GastRefResolverVisitor = (function (_super) {\n    __extends(GastRefResolverVisitor, _super);\n    function GastRefResolverVisitor(nameToTopRule) {\n        var _this = _super.call(this) || this;\n        _this.nameToTopRule = nameToTopRule;\n        _this.errors = [];\n        return _this;\n    }\n    GastRefResolverVisitor.prototype.resolveRefs = function () {\n        var _this = this;\n        utils_1.forEach(this.nameToTopRule.values(), function (prod) {\n            _this.currTopLevel = prod;\n            prod.accept(_this);\n        });\n    };\n    GastRefResolverVisitor.prototype.visitNonTerminal = function (node) {\n        var ref = this.nameToTopRule.get(node.nonTerminalName);\n        if (!ref) {\n            var msg = \"Invalid grammar, reference to a rule which is not defined: ->\" + node.nonTerminalName + \"<-\\n\" +\n                \"inside top level rule: ->\" + this.currTopLevel.name + \"<-\";\n            this.errors.push({\n                message: msg,\n                type: parser_public_1.ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n                ruleName: this.currTopLevel.name,\n                unresolvedRefName: node.nonTerminalName\n            });\n        }\n        else {\n            node.referencedRule = ref;\n        }\n    };\n    return GastRefResolverVisitor;\n}(gast_public_1.gast.GAstVisitor));\nexports.GastRefResolverVisitor = GastRefResolverVisitor;\n//# sourceMappingURL=resolver.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/parse/grammar/resolver.js\n// module id = 23\n// module chunks = 0","\"use strict\";\nvar tokens_public_1 = require(\"./tokens_public\");\nvar lexer_public_1 = require(\"./lexer_public\");\nvar utils_1 = require(\"../utils/utils\");\nvar tokens_1 = require(\"./tokens\");\nvar PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nvar CONTAINS_LINE_TERMINATOR = \"containsLineTerminator\";\nfunction analyzeTokenClasses(tokenClasses) {\n    var onlyRelevantClasses = utils_1.reject(tokenClasses, function (currClass) {\n        return currClass[PATTERN] === lexer_public_1.Lexer.NA;\n    });\n    var allTransformedPatterns = utils_1.map(onlyRelevantClasses, function (currClass) {\n        var currPattern = currClass[PATTERN];\n        if (utils_1.isRegExp(currPattern)) {\n            return addStartOfInput(currPattern);\n        }\n        else if (utils_1.isFunction(currPattern)) {\n            return { exec: currPattern };\n        }/* istanbul ignore else */ \n        else if (utils_1.has(currPattern, \"exec\")) {\n            return currPattern;\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n    });\n    var patternIdxToClass = onlyRelevantClasses;\n    var patternIdxToGroup = utils_1.map(onlyRelevantClasses, function (clazz) {\n        var groupName = clazz.GROUP;\n        if (groupName === lexer_public_1.Lexer.SKIPPED) {\n            return undefined;\n        }\n        else if (utils_1.isString(groupName)) {\n            return groupName;\n        }/* istanbul ignore else */ \n        else if (utils_1.isUndefined(groupName)) {\n            return \"default\";\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n    });\n    var patternIdxToLongerAltIdx = utils_1.map(onlyRelevantClasses, function (clazz) {\n        var longerAltClass = clazz.LONGER_ALT;\n        if (longerAltClass) {\n            var longerAltIdx = utils_1.indexOf(onlyRelevantClasses, longerAltClass);\n            return longerAltIdx;\n        }\n    });\n    var patternIdxToPushMode = utils_1.map(onlyRelevantClasses, function (clazz) { return clazz.PUSH_MODE; });\n    var patternIdxToPopMode = utils_1.map(onlyRelevantClasses, function (clazz) { return utils_1.has(clazz, \"POP_MODE\"); });\n    var patternIdxToCanLineTerminator = utils_1.map(allTransformedPatterns, function (pattern) {\n        if (utils_1.isRegExp(pattern)) {\n            // TODO: unicode escapes of line terminators too?\n            return /\\\\n|\\\\r|\\\\s/g.test(pattern.source);\n        }\n        else {\n            if (utils_1.has(pattern, CONTAINS_LINE_TERMINATOR)) {\n                return pattern[CONTAINS_LINE_TERMINATOR];\n            }\n            return false;\n        }\n    });\n    var emptyGroups = utils_1.reduce(onlyRelevantClasses, function (acc, clazz) {\n        var groupName = clazz.GROUP;\n        if (utils_1.isString(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n            acc[groupName] = [];\n        }\n        return acc;\n    }, {});\n    return {\n        allPatterns: allTransformedPatterns,\n        patternIdxToClass: patternIdxToClass,\n        patternIdxToGroup: patternIdxToGroup,\n        patternIdxToLongerAltIdx: patternIdxToLongerAltIdx,\n        patternIdxToCanLineTerminator: patternIdxToCanLineTerminator,\n        patternIdxToPushMode: patternIdxToPushMode,\n        patternIdxToPopMode: patternIdxToPopMode,\n        emptyGroups: emptyGroups\n    };\n}\nexports.analyzeTokenClasses = analyzeTokenClasses;\nfunction validatePatterns(tokenClasses, validModesNames) {\n    var errors = [];\n    var missingResult = findMissingPatterns(tokenClasses);\n    errors = errors.concat(missingResult.errors);\n    var invalidResult = findInvalidPatterns(missingResult.valid);\n    var validTokenClasses = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenClasses));\n    errors = errors.concat(findInvalidGroupType(validTokenClasses));\n    errors = errors.concat(findModesThatDoNotExist(validTokenClasses, validModesNames));\n    return errors;\n}\nexports.validatePatterns = validatePatterns;\nfunction validateRegExpPattern(tokenClasses) {\n    var errors = [];\n    var withRegExpPatterns = utils_1.filter(tokenClasses, function (currTokClass) { return utils_1.isRegExp(currTokClass[PATTERN]); });\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    return errors;\n}\nfunction findMissingPatterns(tokenClasses) {\n    var tokenClassesWithMissingPattern = utils_1.filter(tokenClasses, function (currClass) {\n        return !utils_1.has(currClass, PATTERN);\n    });\n    var errors = utils_1.map(tokenClassesWithMissingPattern, function (currClass) {\n        return {\n            message: \"Token class: ->\" + tokens_public_1.tokenName(currClass) + \"<- missing static 'PATTERN' property\",\n            type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n            tokenClasses: [currClass]\n        };\n    });\n    var valid = utils_1.difference(tokenClasses, tokenClassesWithMissingPattern);\n    return { errors: errors, valid: valid };\n}\nexports.findMissingPatterns = findMissingPatterns;\nfunction findInvalidPatterns(tokenClasses) {\n    var tokenClassesWithInvalidPattern = utils_1.filter(tokenClasses, function (currClass) {\n        var pattern = currClass[PATTERN];\n        return !utils_1.isRegExp(pattern) && !utils_1.isFunction(pattern) && !utils_1.has(pattern, \"exec\");\n    });\n    var errors = utils_1.map(tokenClassesWithInvalidPattern, function (currClass) {\n        return {\n            message: \"Token class: ->\" + tokens_public_1.tokenName(currClass) + \"<- static 'PATTERN' can only be a RegExp, a\" +\n                \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n            tokenClasses: [currClass]\n        };\n    });\n    var valid = utils_1.difference(tokenClasses, tokenClassesWithInvalidPattern);\n    return { errors: errors, valid: valid };\n}\nexports.findInvalidPatterns = findInvalidPatterns;\nvar end_of_input = /[^\\\\][\\$]/;\nfunction findEndOfInputAnchor(tokenClasses) {\n    var invalidRegex = utils_1.filter(tokenClasses, function (currClass) {\n        var pattern = currClass[PATTERN];\n        return end_of_input.test(pattern.source);\n    });\n    var errors = utils_1.map(invalidRegex, function (currClass) {\n        return {\n            message: \"Token class: ->\" + tokens_public_1.tokenName(currClass) + \"<- static 'PATTERN' cannot contain end of input anchor '$'\",\n            type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n            tokenClasses: [currClass]\n        };\n    });\n    return errors;\n}\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\nfunction findUnsupportedFlags(tokenClasses) {\n    var invalidFlags = utils_1.filter(tokenClasses, function (currClass) {\n        var pattern = currClass[PATTERN];\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    var errors = utils_1.map(invalidFlags, function (currClass) {\n        return {\n            message: \"Token class: ->\" + tokens_public_1.tokenName(currClass) +\n                \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n            type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n            tokenClasses: [currClass]\n        };\n    });\n    return errors;\n}\nexports.findUnsupportedFlags = findUnsupportedFlags;\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nfunction findDuplicatePatterns(tokenClasses) {\n    var found = [];\n    var identicalPatterns = utils_1.map(tokenClasses, function (outerClass) {\n        return utils_1.reduce(tokenClasses, function (result, innerClass) {\n            if ((outerClass.PATTERN.source === innerClass.PATTERN.source) && !utils_1.contains(found, innerClass) &&\n                innerClass.PATTERN !== lexer_public_1.Lexer.NA) {\n                // this avoids duplicates in the result, each class may only appear in one \"set\"\n                // in essence we are creating Equivalence classes on equality relation.\n                found.push(innerClass);\n                result.push(innerClass);\n                return result;\n            }\n            return result;\n        }, []);\n    });\n    identicalPatterns = utils_1.compact(identicalPatterns);\n    var duplicatePatterns = utils_1.filter(identicalPatterns, function (currIdenticalSet) {\n        return currIdenticalSet.length > 1;\n    });\n    var errors = utils_1.map(duplicatePatterns, function (setOfIdentical) {\n        var classNames = utils_1.map(setOfIdentical, function (currClass) {\n            return tokens_public_1.tokenName(currClass);\n        });\n        var dupPatternSrc = utils_1.first(setOfIdentical).PATTERN;\n        return {\n            message: \"The same RegExp pattern ->\" + dupPatternSrc + \"<-\" +\n                (\"has been used in all the following classes: \" + classNames.join(\", \") + \" <-\"),\n            type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n            tokenClasses: setOfIdentical\n        };\n    });\n    return errors;\n}\nexports.findDuplicatePatterns = findDuplicatePatterns;\nfunction findInvalidGroupType(tokenClasses) {\n    var invalidTypes = utils_1.filter(tokenClasses, function (clazz) {\n        if (!utils_1.has(clazz, \"GROUP\")) {\n            return false;\n        }\n        var group = clazz.GROUP;\n        return group !== lexer_public_1.Lexer.SKIPPED &&\n            group !== lexer_public_1.Lexer.NA && !utils_1.isString(group);\n    });\n    var errors = utils_1.map(invalidTypes, function (currClass) {\n        return {\n            message: \"Token class: ->\" + tokens_public_1.tokenName(currClass) + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n            tokenClasses: [currClass]\n        };\n    });\n    return errors;\n}\nexports.findInvalidGroupType = findInvalidGroupType;\nfunction findModesThatDoNotExist(tokenClasses, validModes) {\n    var invalidModes = utils_1.filter(tokenClasses, function (clazz) {\n        return clazz.PUSH_MODE !== undefined && !utils_1.contains(validModes, clazz.PUSH_MODE);\n    });\n    var errors = utils_1.map(invalidModes, function (clazz) {\n        var msg = \"Token class: ->\" + tokens_public_1.tokenName(clazz) + \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\" + clazz.PUSH_MODE + \"<-\" +\n            \"which does not exist\";\n        return {\n            message: msg,\n            type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n            tokenClasses: [clazz]\n        };\n    });\n    return errors;\n}\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\nfunction addStartOfInput(pattern) {\n    var flags = pattern.ignoreCase ?\n        \"i\" :\n        \"\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(\"^(?:\" + pattern.source + \")\", flags);\n}\nexports.addStartOfInput = addStartOfInput;\nfunction countLineTerminators(text) {\n    var lineTerminators = 0;\n    var currOffset = 0;\n    while (currOffset < text.length) {\n        var c = text.charCodeAt(currOffset);\n        if (c === 10) {\n            lineTerminators++;\n        }\n        else if (c === 13) {\n            if (currOffset !== text.length - 1 &&\n                text.charCodeAt(currOffset + 1) === 10) {\n            }\n            else {\n                lineTerminators++;\n            }\n        }\n        currOffset++;\n    }\n    return lineTerminators;\n}\nexports.countLineTerminators = countLineTerminators;\nfunction performRuntimeChecks(lexerDefinition) {\n    var errors = [];\n    // some run time checks to help the end users.\n    if (!utils_1.has(lexerDefinition, exports.DEFAULT_MODE)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.DEFAULT_MODE + \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n        });\n    }\n    if (!utils_1.has(lexerDefinition, exports.MODES)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.MODES + \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n        });\n    }\n    if (utils_1.has(lexerDefinition, exports.MODES) &&\n        utils_1.has(lexerDefinition, exports.DEFAULT_MODE) && !utils_1.has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized with a \" + exports.DEFAULT_MODE + \": <\" + lexerDefinition.defaultMode + \">\"\n                + \"which does not exist\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n        });\n    }\n    if (utils_1.has(lexerDefinition, exports.MODES)) {\n        utils_1.forEach(lexerDefinition.modes, function (currModeValue, currModeName) {\n            utils_1.forEach(currModeValue, function (currTokClass, currIdx) {\n                if (utils_1.isUndefined(currTokClass)) {\n                    errors.push({\n                        message: \"A Lexer cannot be initialized using an undefined Token Class. Mode:\" +\n                            (\"<\" + currModeName + \"> at index: <\" + currIdx + \">\\n\"),\n                        type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n                    });\n                }\n            });\n        });\n    }\n    return errors;\n}\nexports.performRuntimeChecks = performRuntimeChecks;\nfunction checkLazyMode(allTokenTypes) {\n    var errors = [];\n    var allTokensTypeSet = utils_1.uniq(allTokenTypes, function (currTokType) { return tokens_public_1.tokenName(currTokType); });\n    var areAllLazy = utils_1.every(allTokensTypeSet, function (currTokType) { return tokens_1.isLazyTokenType(currTokType); });\n    // TODO: why is this second check required?\n    var areAllNotLazy = utils_1.every(allTokensTypeSet, function (currTokType) { return !tokens_1.isLazyTokenType(currTokType); });\n    if (!areAllLazy && !areAllNotLazy) {\n        var lazyTokens = utils_1.filter(allTokensTypeSet, function (currTokType) { return tokens_1.isLazyTokenType(currTokType); });\n        var lazyTokensNames = utils_1.map(lazyTokens, tokens_public_1.tokenName);\n        var lazyTokensString = lazyTokensNames.join(\"\\n\\t\");\n        var notLazyTokens = utils_1.filter(allTokensTypeSet, function (currTokType) { return !tokens_1.isLazyTokenType(currTokType); });\n        var notLazyTokensNames = utils_1.map(notLazyTokens, tokens_public_1.tokenName);\n        var notLazyTokensString = notLazyTokensNames.join(\"\\n\\t\");\n        errors.push({\n            message: \"A Lexer cannot be defined using a mix of both Lazy and Non-Lazy Tokens:\\n\" +\n                \"Lazy Tokens:\\n\\t\" +\n                lazyTokensString +\n                \"\\nNon-Lazy Tokens:\\n\\t\" +\n                notLazyTokensString,\n            type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_MIX_LAZY_AND_NOT_LAZY\n        });\n    }\n    return {\n        isLazy: areAllLazy,\n        errors: errors\n    };\n}\nexports.checkLazyMode = checkLazyMode;\nfunction checkSimpleMode(allTokenTypes) {\n    var errors = [];\n    var allTokensTypeSet = utils_1.uniq(allTokenTypes, function (currTokType) { return tokens_public_1.tokenName(currTokType); });\n    var areAllSimple = utils_1.every(allTokensTypeSet, function (currTokType) { return tokens_1.isSimpleTokenType(currTokType); });\n    // TODO: why is the second check required?\n    var areAllNotSimple = utils_1.every(allTokensTypeSet, function (currTokType) { return !tokens_1.isSimpleTokenType(currTokType); });\n    if (!areAllSimple && !areAllNotSimple) {\n        var simpleTokens = utils_1.filter(allTokensTypeSet, function (currTokType) { return tokens_1.isSimpleTokenType(currTokType); });\n        var simpleTokensNames = utils_1.map(simpleTokens, tokens_public_1.tokenName);\n        var simpleTokensString = simpleTokensNames.join(\"\\n\\t\");\n        var notSimpleTokens = utils_1.filter(allTokensTypeSet, function (currTokType) { return !tokens_1.isSimpleTokenType(currTokType); });\n        var notSimpleTokensNames = utils_1.map(notSimpleTokens, tokens_public_1.tokenName);\n        var notSimpleTokensString = notSimpleTokensNames.join(\"\\n\\t\");\n        errors.push({\n            message: \"A Lexer cannot be defined using a mix of both Simple and Non-Simple Tokens:\\n\" +\n                \"Simple Tokens:\\n\\t\" +\n                simpleTokensString +\n                \"\\nNon-Simple Tokens:\\n\\t\" +\n                notSimpleTokensString,\n            type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_MIX_SIMPLE_AND_NOT_SIMPLE\n        });\n    }\n    return {\n        isSimple: areAllSimple,\n        errors: errors\n    };\n}\nexports.checkSimpleMode = checkSimpleMode;\nfunction cloneEmptyGroups(emptyGroups) {\n    var clonedResult = {};\n    var groupKeys = utils_1.keys(emptyGroups);\n    utils_1.forEach(groupKeys, function (currKey) {\n        var currGroupValue = emptyGroups[currKey];\n        /* istanbul ignore else */\n        if (utils_1.isArray(currGroupValue)) {\n            clonedResult[currKey] = [];\n        }\n        else {\n            /* istanbul ignore next */ throw Error(\"non exhaustive match\");\n        }\n    });\n    return clonedResult;\n}\nexports.cloneEmptyGroups = cloneEmptyGroups;\n//# sourceMappingURL=lexer.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/scan/lexer.js\n// module id = 24\n// module chunks = 0","\"use strict\";\nvar Range = (function () {\n    function Range(start, end) {\n        this.start = start;\n        this.end = end;\n        if (!isValidRange(start, end)) {\n            throw new Error(\"INVALID RANGE\");\n        }\n    }\n    Range.prototype.contains = function (num) {\n        return this.start <= num && this.end >= num;\n    };\n    Range.prototype.containsRange = function (other) {\n        return this.start <= other.start && this.end >= other.end;\n    };\n    Range.prototype.isContainedInRange = function (other) {\n        return other.containsRange(this);\n    };\n    Range.prototype.strictlyContainsRange = function (other) {\n        return this.start < other.start && this.end > other.end;\n    };\n    Range.prototype.isStrictlyContainedInRange = function (other) {\n        return other.strictlyContainsRange(this);\n    };\n    return Range;\n}());\nexports.Range = Range;\nfunction isValidRange(start, end) {\n    return !(start < 0 || end < start);\n}\nexports.isValidRange = isValidRange;\n//# sourceMappingURL=range.js.map\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/chevrotain/lib/src/text/range.js\n// module id = 25\n// module chunks = 0","import calculator from \"./calculator\";\n\nconsole.log(calculator(\"2 + 2\"));\n\n\n\n// WEBPACK FOOTER //\n// ./app.js"],"sourceRoot":""}